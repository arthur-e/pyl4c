<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>pyl4c.lib.netcdf API documentation</title>
<meta name="description" content="Utilities for working with NetCDF files." />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
<style>.homelink{display:block;font-size:2em;font-weight:bold;color:#555;padding-bottom:.5em;border-bottom:1px solid silver}.homelink:hover{color:inherit}.homelink img{max-width:35%;max-height:5em;margin:auto;margin-bottom:.3em}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>pyl4c.lib.netcdf</code></h1>
</header>
<section id="section-intro">
<p>Utilities for working with NetCDF files.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#39;&#39;&#39;
Utilities for working with NetCDF files.
&#39;&#39;&#39;

import calendar
import datetime
import re
import numpy as np
import netCDF4
from osgeo import osr
from osgeo import gdal
from osgeo import gdalconst
from bisect import bisect_left
from scipy.io import netcdf_file
from pyl4c.epsg import EPSG
from pyl4c.spatial import EASE2_GRID_PARAMS, array_to_raster, dump_raster
from pyl4c.utils import get_slice_idx_by_bbox

TIME_RX = re.compile(r&#39;^(?P&lt;interval&gt;seconds|hours|days|months|years) since (?P&lt;epoch&gt;[\d\-]+(?:\s{1}?(?:\d{2}\:\d{2}))?(?:\:\d{2})?)&#39;)
NDAYS_RX = re.compile(r&#39;(\d+)\_day&#39;)

def nc_dim(variable):
    &#39;&#39;&#39;
    Returns the dimensions of a netCDF variable.

    Parameters
    ----------
    variable : scipy.io.netcdf.netcdf_variable

    Returns
    -------
    int
    &#39;&#39;&#39;
    if hasattr(variable, &#39;ndim&#39;):
        return variable.ndim
    if hasattr(variable, &#39;dimensions&#39;):
        return len(variable.dimensions)


def netcdf_array(nc, keys, cell_size = None, time_idx = 0, x_offset = -180):
    &#39;&#39;&#39;
    Extracts an equirectangular NetCDF data array as a NumPy array, with
    spatial reference system (SRS) information. NOTE: Both `cell_size` elements
    should be positive numbers.

    Parameters
    ----------
    nc : netCDF4.Dataset
        The NetCDF file (opened)
    keys : tuple
        A tuple of (variable, x_coords, y_coords) where variable is the
        variable name, x_coords the name of the X-coordinate array variable,
        y_coords the name of the Y-coordinate array variable
    cell_size : tuple or None
        (Optional) Tuple of the the cell size in both directions in degrees,
        e.g., (1, 1); will attempt to infer the cell size if not provided
    time_idx : int
        (Optional) Index of the &#34;time&#34; axis to extract as a raster
        (Default: 0)
    x_offset : int or float
        (Optional) Because of the absurd X-coordinates convention used in some
        NetCDF arrays, it may be necessary to &#34;offset&#34; the X coordinates; this
        is only used if it is detected that the maximum X coordinate value is
        &gt;/= 180 degrees E (Default: -180);

    Returns
    -------
    tuple
        Tuple of `(array, gt, wkt)`
    &#39;&#39;&#39;
    def infer_cell_size(x_coords, y_coords):
        assert x_coords.ndim == 1,\
            &#34;Can&#39;t infer cell size from coordinate arrays with more than one axis&#34;
        # NOTE: Rounding coordinate arrays to 5 decimal places for comparison
        x_diff = np.round(np.array(x_coords)[1:] - np.array(x_coords)[0:-1], 4)
        y_diff = np.round(np.array(y_coords)[1:] - np.array(y_coords)[0:-1], 4)
        assert np.median(x_diff) == x_diff[0] and np.median(y_diff) == y_diff[0],\
            &#34;Array cell size is not equal in both directions!&#34;
        return (np.abs(np.median(x_diff)), np.abs(np.median(y_diff)))

    # Original (equirectangular) spatial reference system
    wkt0 = osr.SpatialReference()
    wkt0.ImportFromEPSG(4326)
    if cell_size is not None:
        x_res, y_res = cell_size
        assert x_res &gt; 0 and y_res &gt; 0, &#39;Argument cell_size must be greater than zero&#39;
    else:
        x_res, y_res = infer_cell_size(
            np.array(nc.variables[keys[1]][:]),
            np.array(nc.variables[keys[2]][:]))

    x0 = np.array(nc.variables[keys[1]][:]).min()
    y0 = np.array(nc.variables[keys[2]][:]).max()
    # Geotransform params: (x_min, pixel_width, 0, y_max, 0, -pixel_height)
    gt0 = (x0, x_res, 0, y0, 0, -y_res)

    # NOTE: Because some NetCDF files have a &#34;degrees east&#34; convention with
    #   longitude increasing monotonically from 0 to 360, we must apply an
    #   offset to the X coordinates
    start_idx = None
    if np.array(nc.variables[keys[1]][:]).max() &gt; 180:
        # Update affine transformation
        gt0 = (x0 + x_offset, x_res, 0, y0, 0, -y_res)
        # Transform to proper longitudes
        x_coords = (nc.variables[keys[1]][:] + x_offset)

        # Get X-coordinate origin, or index of east longitude closest to zero,
        #   unless all coordinates are in a single hemisphere
        test = np.logical_and(
            x_coords &gt; 0, x_coords &lt;= np.abs(x_coords).min())
        if np.any(test):
            idx = np.arange(0, x_coords.shape[0])
            start_idx = int(idx[x_coords == x_coords[test]])

    # Extract a NumPy array
    if hasattr(time_idx, &#39;index&#39;):
        a, b = (min(time_idx), max(time_idx))
        arr = np.array(nc.variables[keys[0]][a:(b+1),...])
    else:
        # Make sure a single time slice as a band axis
        if nc_dim(nc.variables[keys[0]]) &gt; 2:
            arr = np.array(nc.variables[keys[0]][time_idx,...])[np.newaxis,...]
        else:
            # Some netCDF variables may have no time/ band axis (i.e., static)
            arr = np.array(nc.variables[keys[0]][:])[np.newaxis,...]

    # If Y coordinates are in ascending order, flip the array
    lats = nc.variables[keys[2]][:].tolist()
    if lats.index(max(lats)) &gt; lats.index(min(lats)):
        arr = np.flip(arr, axis = 1)

    # If necessary, re-sort data so west-most longitude is the first column
    if start_idx is not None:
        arr = np.concatenate((arr[...,start_idx:], arr[...,:start_idx]), axis = 2)

    scale = 1
    if hasattr(nc.variables[keys[0]], &#39;scale_factor&#39;):
        scale = nc.variables[keys[0]].scale_factor

    offset = 0
    if hasattr(nc.variables[keys[0]], &#39;add_offset&#39;):
        offset = nc.variables[keys[0]].add_offset

    return ((arr * scale) + offset, gt0, wkt0.ExportToWkt())


def netcdf_raster(
        nc, keys, cell_size = None, time_idx = 0, subset_bbox = None,
        in_nodata = None, out_nodata = -9999):
    &#39;&#39;&#39;
    Dumps a NetCDF variable to a GeoTIFF file. NOTE: Both `cell_size` elements
    should be positive numbers.

    Parameters
    ----------
    nc : netCDF4.Dataset
        The NetCDF file (opened)
    keys : tuple
        A tuple of (variable, x_coords, y_coords) where variable is the
        variable name, x_coords the name of the X-coordinate array variable,
        y_coords the name of the Y-coordinate array variable
    cell_size : tuple or None
        (Optional) Tuple of the the cell size in both directions in degrees,
        e.g., (1, 1); will attempt to infer the cell size if not provided
    time_idx : int
        (Optional) Index of the &#34;time&#34; axis to extract as a raster
        (Default: 0)
    subset_bbox : tuple or None
        (Optional) Subset bounding box
    in_nodata : int or float or None
        (Optional) The NoData value to ignore in the input
    out_nodata : int or float or None
        (Optional) The NoData value to set in the output (Default: -9999)

    Returns
    -------
    gdal.Dataset
    &#39;&#39;&#39;
    arr, gt0, wkt0 = netcdf_array(nc, keys, cell_size, time_idx)
    xmin = ymin = 0
    if subset_bbox is not None:
        x_coords = nc.variables[keys[1]][:]
        y_coords = nc.variables[keys[2]][:]
        if np.array(nc.variables[keys[1]][:]).max() &gt; 180:
            # Correct for weird NetCDF easting
            x_coords = nc.variables[keys[1]][:] - 180
        x_idx, y_idx = get_slice_idx_by_bbox(
            x_coords, y_coords, subset_bbox = subset_bbox)
        xmin, xmax = x_idx
        ymin, ymax = y_idx
        if arr.ndim == 2:
            arr = arr[ymin:ymax, xmin:xmax]
        else:
            arr = arr[:, ymin:ymax, xmin:xmax]

    # Optional: Mask user-specified NoData value
    if in_nodata is not None:
        arr = np.where(arr == in_nodata, np.nan, arr)

    # Mask any NoData/ fill value defined by the dataset
    if hasattr(nc.variables[keys[0]], &#39;missing_value&#39;):
        arr = np.where(
            arr == nc.variables[keys[0]].missing_value, np.nan, arr)

    # Create a gdal.Dataset from the array
    if out_nodata is not None:
        return array_to_raster(
            np.where(
                np.isnan(arr), out_nodata, arr), gt0, str(wkt0), xmin, ymin)

    return array_to_raster(arr, gt0, str(wkt0), xmin, ymin)


def parse_time_units(netcdf_time_axis):
    &#39;&#39;&#39;
    Returns the time interval size (e.g., &#34;days&#34;) and the epoch
    (e.g., &#34;1970-01-01&#34;) from a given netCDF units declaration for the time
    axis (e.g., &#34;days since 1970-01-01&#34;).

    Parameters
    ----------
    netcdf_time_axis : netCDF4._netCDF4.Variable
        Variable that describes the time axis

    Returns
    -------
    tuple
        Tuple of (str, datetime.datetime)
    &#39;&#39;&#39;
    units_string = netcdf_time_axis.units
    if isinstance(units_string, bytes):
        units_string = bytes(units_string).decode()

    interval, epoch_str = TIME_RX.match(units_string).groups()
    epoch_str = epoch_str.replace(&#39;-1-1&#39;, &#39;-01-01&#39;)
    if epoch_str.rfind(&#39;00:00:00&#39;) &gt; 0:
        epoch = datetime.datetime.strptime(epoch_str, &#39;%Y-%m-%d %H:%M:%S&#39;)
    elif epoch_str.rfind(&#39;00:00&#39;) &gt; 0:
        epoch = datetime.datetime.strptime(epoch_str, &#39;%Y-%m-%d %H:%M&#39;)
    else:
        epoch = datetime.datetime.strptime(epoch_str, &#39;%Y-%m-%d&#39;)
    return (interval, epoch)


def spatial_average(
        nc, keys, reducer, t_labels = None, subset_bbox = None, nodata = -9999):
    &#39;&#39;&#39;
    Calculates a spatial average across a NetCDF time series variable.

    Parameters
    ----------
    nc : netCDF4.Dataset
        The NetCDF file (opened)
    keys : tuple
        A tuple of (variable, x_coords, y_coords) where variable is the
        variable name, x_coords the name of the X-coordinate array variable,
        y_coords the name of the Y-coordinate array variable
    reducer : function
        A vectorized function that returns a scalar for an input vector of
        values; should ignore np.nan values
    t_labels : tuple or list
        (Optional) A vector of time index labels
    subset_bbox : tuple
        (Optional) To specify a subset area for the spatial average (i.e.,
        instead of averaging over the entire NetCDF array domain), pass a
        bounding box argument
    nodata : int or float
        The NoData value to ignore (Default: -9999)

    Returns
    -------
    list
        Of the form `[(index, value), ...]` for each time step
    &#39;&#39;&#39;
    if subset_bbox is not None:
        x_coords = nc.variables[keys[1]][:]
        y_coords = nc.variables[keys[2]][:]
        if np.array(nc.variables[keys[1]][:]).max() &gt; 180:
            # Correct for weird NetCDF easting
            x_coords = nc.variables[keys[1]][:] - 180
        x_idx, y_idx = get_slice_idx_by_bbox(
            x_coords, y_coords, subset_bbox = subset_bbox)
        xmin, xmax = x_idx
        ymin, ymax = y_idx

    scale = 1
    if hasattr(nc.variables[keys[0]], &#39;scale_factor&#39;):
        scale = nc.variables[keys[0]].scale_factor

    offset = 0
    if hasattr(nc.variables[keys[0]], &#39;add_offset&#39;):
        offset = nc.variables[keys[0]].add_offset

    num_epochs = nc.variables[keys[0]].shape[0]
    time_series = []
    for i, t in enumerate(range(0, num_epochs)):
        if subset_bbox is not None:
            arr = nc.variables[keys[0]][:][t, ymin:ymax, xmin:xmax]

        else:
            arr = nc.variables[keys[0]][:][t,...]

        index = t
        if t_labels is not None:
            index = t_labels[i]

        time_series.append((
            # Filter out NoData; use summary function that ignores NaNs
            index, reducer( # Multiply by scale, add offset
                np.where(arr == nodata, np.nan, (arr * scale) + offset))
        ))

    return time_series


def time_series(netcdf_time_axis, has_leap = None):
    &#39;&#39;&#39;
    Constructs a series of datetime.datetime elements based on a netCDF
    time axis; assumes that time steps are evenly spaced (except in leap
    years) and ignores fractional time steps.

    NOTE: This is EXTREMELY difficult to get right because of awful
    implementation of time axes in the typical netCDF dataset. Among other
    challenges... Apparently, netCDF time axes use the convention that if the
    epoch starts at midnight, the first day is the &#34;zeroth&#34; day; e.g., CLM5.0
    states its time axis is &#34;days since 1700-01-01 00:00:00&#34; but the first
    time step is 31.0; it seems highly unlike this monthly time series would
    start in February (Jan. 1 + 31 days == Feb. 1), so they must be using the
    *last day* of each month (e.g., Jan 0 + 31 days == Jan. 31).

    Parameters
    ----------
    netcdf_time_axis : netCDF4._netCDF4.Variable
        Variable that describes the time axis
    has_leap : bool or None
        Set True to force recognition of leap years; if None, will attempt
        to automatically determine whether leap years should be recognized
        based on the field metadata (Default: None)

    Returns
    -------
    list
        `[*datetime.date|datetime.datetime]`
    &#39;&#39;&#39;
    steps = netcdf_time_axis[:]
    interval, epoch = parse_time_units(netcdf_time_axis)
    convention = getattr(netcdf_time_axis, &#39;calendar&#39;, &#39;&#39;)
    if hasattr(convention, &#39;decode&#39;):
        convention = convention.decode(&#39;utf-8&#39;)

    # Attempt to determine leap year recognition
    if has_leap is None:
        has_leap = convention in (&#39;&#39;, &#39;standard&#39;, &#39;gregorian&#39;)

    first_step = steps[1] - steps[0]
    # Basically, we can tolerate different step sizes for intervals that
    #   can be passed to datetime.timedelta, which assumes leap years;
    #   in all other cases, we can&#39;t calculate time steps correctly
    if not has_leap:
        if not np.all(np.array(steps[1:]) - np.array(steps[:-1]) == first_step):
            assert interval in (&#39;seconds&#39;, &#39;hours&#39;, &#39;days&#39;),\
                &#39;Time series is not evenly spaced and leap years do not explain this discrepancy&#39;

    ldays = 1 if has_leap else 0
    ndays = 365
    if NDAYS_RX.match(convention) is not None:
        # Some datasets oddly have, e.g., &#34;360_day&#34; conventions
        ndays = int(NDAYS_RX.match(convention).groups()[0])

    # Because timedelta can&#39;t process intervals higher than &#34;days&#34;...
    if interval == &#39;years&#39;:
        # Simple years series starting January 1 if units are years
        years = np.arange(epoch.year, epoch.year + steps[-1] + 1)
        time_axis = [datetime.date(int(y), 1, 1) for y in years]
    elif interval == &#39;months&#39;:
        time_axis = []
        m_range = (np.arange(0, len(steps)) + epoch.month) % 12
        m_range = np.where(m_range == 0, 12, m_range)
        for t, t_value in enumerate(steps):
            m = m_range[t]
            y = epoch.year + np.floor(t_value / 12)
            time_axis.append(datetime.date(int(y), int(m), epoch.day))
    # But if time intervals are in &#34;seconds,&#34; &#34;hours,&#34; or &#34;days&#34;
    elif interval in (&#39;seconds&#39;, &#39;hours&#39;, &#39;days&#39;) and has_leap:
        time_axis = [
            epoch +
                datetime.timedelta(**{interval: int(t)}) for t in steps
        ]
    # But timedelta assumes leap years are in use, so if the time series
    #   doesn&#39;t use leap years, we must construct it manually
    else:
        time_axis = []
        this_year = epoch.year
        mdays = np.cumsum(calendar.mdays)
        for t in steps:
            if interval == &#39;seconds&#39;:
                y = epoch.year + (t / (ndays * 24 * 60 * 60))
            if interval == &#39;hours&#39;:
                y = epoch.year + (t / (ndays * 24))
            if interval in (&#39;seconds&#39;, &#39;hours&#39;):
                m = bisect_left(mdays, ((y - epoch.year) * ndays) % ndays)
                d = (((y - epoch.year) * ndays) % ndays) - mdays[m - 1]
            if interval == &#39;days&#39;:
                y = epoch.year + (t / ndays) # e.g., t / 365
                # Incidentally, the left &#34;sorting index&#34; is the month number
                m = bisect_left(mdays, t % ndays)
                m += 1 if m == 0 else 0
                d = (t % ndays) - mdays[m - 1] # And days are what is left over
                d += 1 if d == 0 else 0
            time_axis.append(datetime.datetime(int(y), int(m), int(d)))
    return time_axis</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="pyl4c.lib.netcdf.nc_dim"><code class="name flex">
<span>def <span class="ident">nc_dim</span></span>(<span>variable)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns the dimensions of a netCDF variable.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>variable</code></strong> :&ensp;<code>scipy.io.netcdf.netcdf_variable</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>int</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def nc_dim(variable):
    &#39;&#39;&#39;
    Returns the dimensions of a netCDF variable.

    Parameters
    ----------
    variable : scipy.io.netcdf.netcdf_variable

    Returns
    -------
    int
    &#39;&#39;&#39;
    if hasattr(variable, &#39;ndim&#39;):
        return variable.ndim
    if hasattr(variable, &#39;dimensions&#39;):
        return len(variable.dimensions)</code></pre>
</details>
</dd>
<dt id="pyl4c.lib.netcdf.netcdf_array"><code class="name flex">
<span>def <span class="ident">netcdf_array</span></span>(<span>nc, keys, cell_size=None, time_idx=0, x_offset=-180)</span>
</code></dt>
<dd>
<div class="desc"><p>Extracts an equirectangular NetCDF data array as a NumPy array, with
spatial reference system (SRS) information. NOTE: Both <code>cell_size</code> elements
should be positive numbers.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>nc</code></strong> :&ensp;<code>netCDF4.Dataset</code></dt>
<dd>The NetCDF file (opened)</dd>
<dt><strong><code>keys</code></strong> :&ensp;<code>tuple</code></dt>
<dd>A tuple of (variable, x_coords, y_coords) where variable is the
variable name, x_coords the name of the X-coordinate array variable,
y_coords the name of the Y-coordinate array variable</dd>
<dt><strong><code>cell_size</code></strong> :&ensp;<code>tuple</code> or <code>None</code></dt>
<dd>(Optional) Tuple of the the cell size in both directions in degrees,
e.g., (1, 1); will attempt to infer the cell size if not provided</dd>
<dt><strong><code>time_idx</code></strong> :&ensp;<code>int</code></dt>
<dd>(Optional) Index of the "time" axis to extract as a raster
(Default: 0)</dd>
<dt><strong><code>x_offset</code></strong> :&ensp;<code>int</code> or <code>float</code></dt>
<dd>(Optional) Because of the absurd X-coordinates convention used in some
NetCDF arrays, it may be necessary to "offset" the X coordinates; this
is only used if it is detected that the maximum X coordinate value is<blockquote>
<p>/= 180 degrees E (Default: -180);</p>
</blockquote>
</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tuple</code></dt>
<dd>Tuple of <code>(array, gt, wkt)</code></dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def netcdf_array(nc, keys, cell_size = None, time_idx = 0, x_offset = -180):
    &#39;&#39;&#39;
    Extracts an equirectangular NetCDF data array as a NumPy array, with
    spatial reference system (SRS) information. NOTE: Both `cell_size` elements
    should be positive numbers.

    Parameters
    ----------
    nc : netCDF4.Dataset
        The NetCDF file (opened)
    keys : tuple
        A tuple of (variable, x_coords, y_coords) where variable is the
        variable name, x_coords the name of the X-coordinate array variable,
        y_coords the name of the Y-coordinate array variable
    cell_size : tuple or None
        (Optional) Tuple of the the cell size in both directions in degrees,
        e.g., (1, 1); will attempt to infer the cell size if not provided
    time_idx : int
        (Optional) Index of the &#34;time&#34; axis to extract as a raster
        (Default: 0)
    x_offset : int or float
        (Optional) Because of the absurd X-coordinates convention used in some
        NetCDF arrays, it may be necessary to &#34;offset&#34; the X coordinates; this
        is only used if it is detected that the maximum X coordinate value is
        &gt;/= 180 degrees E (Default: -180);

    Returns
    -------
    tuple
        Tuple of `(array, gt, wkt)`
    &#39;&#39;&#39;
    def infer_cell_size(x_coords, y_coords):
        assert x_coords.ndim == 1,\
            &#34;Can&#39;t infer cell size from coordinate arrays with more than one axis&#34;
        # NOTE: Rounding coordinate arrays to 5 decimal places for comparison
        x_diff = np.round(np.array(x_coords)[1:] - np.array(x_coords)[0:-1], 4)
        y_diff = np.round(np.array(y_coords)[1:] - np.array(y_coords)[0:-1], 4)
        assert np.median(x_diff) == x_diff[0] and np.median(y_diff) == y_diff[0],\
            &#34;Array cell size is not equal in both directions!&#34;
        return (np.abs(np.median(x_diff)), np.abs(np.median(y_diff)))

    # Original (equirectangular) spatial reference system
    wkt0 = osr.SpatialReference()
    wkt0.ImportFromEPSG(4326)
    if cell_size is not None:
        x_res, y_res = cell_size
        assert x_res &gt; 0 and y_res &gt; 0, &#39;Argument cell_size must be greater than zero&#39;
    else:
        x_res, y_res = infer_cell_size(
            np.array(nc.variables[keys[1]][:]),
            np.array(nc.variables[keys[2]][:]))

    x0 = np.array(nc.variables[keys[1]][:]).min()
    y0 = np.array(nc.variables[keys[2]][:]).max()
    # Geotransform params: (x_min, pixel_width, 0, y_max, 0, -pixel_height)
    gt0 = (x0, x_res, 0, y0, 0, -y_res)

    # NOTE: Because some NetCDF files have a &#34;degrees east&#34; convention with
    #   longitude increasing monotonically from 0 to 360, we must apply an
    #   offset to the X coordinates
    start_idx = None
    if np.array(nc.variables[keys[1]][:]).max() &gt; 180:
        # Update affine transformation
        gt0 = (x0 + x_offset, x_res, 0, y0, 0, -y_res)
        # Transform to proper longitudes
        x_coords = (nc.variables[keys[1]][:] + x_offset)

        # Get X-coordinate origin, or index of east longitude closest to zero,
        #   unless all coordinates are in a single hemisphere
        test = np.logical_and(
            x_coords &gt; 0, x_coords &lt;= np.abs(x_coords).min())
        if np.any(test):
            idx = np.arange(0, x_coords.shape[0])
            start_idx = int(idx[x_coords == x_coords[test]])

    # Extract a NumPy array
    if hasattr(time_idx, &#39;index&#39;):
        a, b = (min(time_idx), max(time_idx))
        arr = np.array(nc.variables[keys[0]][a:(b+1),...])
    else:
        # Make sure a single time slice as a band axis
        if nc_dim(nc.variables[keys[0]]) &gt; 2:
            arr = np.array(nc.variables[keys[0]][time_idx,...])[np.newaxis,...]
        else:
            # Some netCDF variables may have no time/ band axis (i.e., static)
            arr = np.array(nc.variables[keys[0]][:])[np.newaxis,...]

    # If Y coordinates are in ascending order, flip the array
    lats = nc.variables[keys[2]][:].tolist()
    if lats.index(max(lats)) &gt; lats.index(min(lats)):
        arr = np.flip(arr, axis = 1)

    # If necessary, re-sort data so west-most longitude is the first column
    if start_idx is not None:
        arr = np.concatenate((arr[...,start_idx:], arr[...,:start_idx]), axis = 2)

    scale = 1
    if hasattr(nc.variables[keys[0]], &#39;scale_factor&#39;):
        scale = nc.variables[keys[0]].scale_factor

    offset = 0
    if hasattr(nc.variables[keys[0]], &#39;add_offset&#39;):
        offset = nc.variables[keys[0]].add_offset

    return ((arr * scale) + offset, gt0, wkt0.ExportToWkt())</code></pre>
</details>
</dd>
<dt id="pyl4c.lib.netcdf.netcdf_raster"><code class="name flex">
<span>def <span class="ident">netcdf_raster</span></span>(<span>nc, keys, cell_size=None, time_idx=0, subset_bbox=None, in_nodata=None, out_nodata=-9999)</span>
</code></dt>
<dd>
<div class="desc"><p>Dumps a NetCDF variable to a GeoTIFF file. NOTE: Both <code>cell_size</code> elements
should be positive numbers.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>nc</code></strong> :&ensp;<code>netCDF4.Dataset</code></dt>
<dd>The NetCDF file (opened)</dd>
<dt><strong><code>keys</code></strong> :&ensp;<code>tuple</code></dt>
<dd>A tuple of (variable, x_coords, y_coords) where variable is the
variable name, x_coords the name of the X-coordinate array variable,
y_coords the name of the Y-coordinate array variable</dd>
<dt><strong><code>cell_size</code></strong> :&ensp;<code>tuple</code> or <code>None</code></dt>
<dd>(Optional) Tuple of the the cell size in both directions in degrees,
e.g., (1, 1); will attempt to infer the cell size if not provided</dd>
<dt><strong><code>time_idx</code></strong> :&ensp;<code>int</code></dt>
<dd>(Optional) Index of the "time" axis to extract as a raster
(Default: 0)</dd>
<dt><strong><code>subset_bbox</code></strong> :&ensp;<code>tuple</code> or <code>None</code></dt>
<dd>(Optional) Subset bounding box</dd>
<dt><strong><code>in_nodata</code></strong> :&ensp;<code>int</code> or <code>float</code> or <code>None</code></dt>
<dd>(Optional) The NoData value to ignore in the input</dd>
<dt><strong><code>out_nodata</code></strong> :&ensp;<code>int</code> or <code>float</code> or <code>None</code></dt>
<dd>(Optional) The NoData value to set in the output (Default: -9999)</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>gdal.Dataset</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def netcdf_raster(
        nc, keys, cell_size = None, time_idx = 0, subset_bbox = None,
        in_nodata = None, out_nodata = -9999):
    &#39;&#39;&#39;
    Dumps a NetCDF variable to a GeoTIFF file. NOTE: Both `cell_size` elements
    should be positive numbers.

    Parameters
    ----------
    nc : netCDF4.Dataset
        The NetCDF file (opened)
    keys : tuple
        A tuple of (variable, x_coords, y_coords) where variable is the
        variable name, x_coords the name of the X-coordinate array variable,
        y_coords the name of the Y-coordinate array variable
    cell_size : tuple or None
        (Optional) Tuple of the the cell size in both directions in degrees,
        e.g., (1, 1); will attempt to infer the cell size if not provided
    time_idx : int
        (Optional) Index of the &#34;time&#34; axis to extract as a raster
        (Default: 0)
    subset_bbox : tuple or None
        (Optional) Subset bounding box
    in_nodata : int or float or None
        (Optional) The NoData value to ignore in the input
    out_nodata : int or float or None
        (Optional) The NoData value to set in the output (Default: -9999)

    Returns
    -------
    gdal.Dataset
    &#39;&#39;&#39;
    arr, gt0, wkt0 = netcdf_array(nc, keys, cell_size, time_idx)
    xmin = ymin = 0
    if subset_bbox is not None:
        x_coords = nc.variables[keys[1]][:]
        y_coords = nc.variables[keys[2]][:]
        if np.array(nc.variables[keys[1]][:]).max() &gt; 180:
            # Correct for weird NetCDF easting
            x_coords = nc.variables[keys[1]][:] - 180
        x_idx, y_idx = get_slice_idx_by_bbox(
            x_coords, y_coords, subset_bbox = subset_bbox)
        xmin, xmax = x_idx
        ymin, ymax = y_idx
        if arr.ndim == 2:
            arr = arr[ymin:ymax, xmin:xmax]
        else:
            arr = arr[:, ymin:ymax, xmin:xmax]

    # Optional: Mask user-specified NoData value
    if in_nodata is not None:
        arr = np.where(arr == in_nodata, np.nan, arr)

    # Mask any NoData/ fill value defined by the dataset
    if hasattr(nc.variables[keys[0]], &#39;missing_value&#39;):
        arr = np.where(
            arr == nc.variables[keys[0]].missing_value, np.nan, arr)

    # Create a gdal.Dataset from the array
    if out_nodata is not None:
        return array_to_raster(
            np.where(
                np.isnan(arr), out_nodata, arr), gt0, str(wkt0), xmin, ymin)

    return array_to_raster(arr, gt0, str(wkt0), xmin, ymin)</code></pre>
</details>
</dd>
<dt id="pyl4c.lib.netcdf.parse_time_units"><code class="name flex">
<span>def <span class="ident">parse_time_units</span></span>(<span>netcdf_time_axis)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns the time interval size (e.g., "days") and the epoch
(e.g., "1970-01-01") from a given netCDF units declaration for the time
axis (e.g., "days since 1970-01-01").</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>netcdf_time_axis</code></strong> :&ensp;<code>netCDF4._netCDF4.Variable</code></dt>
<dd>Variable that describes the time axis</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tuple</code></dt>
<dd>Tuple of (str, datetime.datetime)</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def parse_time_units(netcdf_time_axis):
    &#39;&#39;&#39;
    Returns the time interval size (e.g., &#34;days&#34;) and the epoch
    (e.g., &#34;1970-01-01&#34;) from a given netCDF units declaration for the time
    axis (e.g., &#34;days since 1970-01-01&#34;).

    Parameters
    ----------
    netcdf_time_axis : netCDF4._netCDF4.Variable
        Variable that describes the time axis

    Returns
    -------
    tuple
        Tuple of (str, datetime.datetime)
    &#39;&#39;&#39;
    units_string = netcdf_time_axis.units
    if isinstance(units_string, bytes):
        units_string = bytes(units_string).decode()

    interval, epoch_str = TIME_RX.match(units_string).groups()
    epoch_str = epoch_str.replace(&#39;-1-1&#39;, &#39;-01-01&#39;)
    if epoch_str.rfind(&#39;00:00:00&#39;) &gt; 0:
        epoch = datetime.datetime.strptime(epoch_str, &#39;%Y-%m-%d %H:%M:%S&#39;)
    elif epoch_str.rfind(&#39;00:00&#39;) &gt; 0:
        epoch = datetime.datetime.strptime(epoch_str, &#39;%Y-%m-%d %H:%M&#39;)
    else:
        epoch = datetime.datetime.strptime(epoch_str, &#39;%Y-%m-%d&#39;)
    return (interval, epoch)</code></pre>
</details>
</dd>
<dt id="pyl4c.lib.netcdf.spatial_average"><code class="name flex">
<span>def <span class="ident">spatial_average</span></span>(<span>nc, keys, reducer, t_labels=None, subset_bbox=None, nodata=-9999)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculates a spatial average across a NetCDF time series variable.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>nc</code></strong> :&ensp;<code>netCDF4.Dataset</code></dt>
<dd>The NetCDF file (opened)</dd>
<dt><strong><code>keys</code></strong> :&ensp;<code>tuple</code></dt>
<dd>A tuple of (variable, x_coords, y_coords) where variable is the
variable name, x_coords the name of the X-coordinate array variable,
y_coords the name of the Y-coordinate array variable</dd>
<dt><strong><code>reducer</code></strong> :&ensp;<code>function</code></dt>
<dd>A vectorized function that returns a scalar for an input vector of
values; should ignore np.nan values</dd>
<dt><strong><code>t_labels</code></strong> :&ensp;<code>tuple</code> or <code>list</code></dt>
<dd>(Optional) A vector of time index labels</dd>
<dt><strong><code>subset_bbox</code></strong> :&ensp;<code>tuple</code></dt>
<dd>(Optional) To specify a subset area for the spatial average (i.e.,
instead of averaging over the entire NetCDF array domain), pass a
bounding box argument</dd>
<dt><strong><code>nodata</code></strong> :&ensp;<code>int</code> or <code>float</code></dt>
<dd>The NoData value to ignore (Default: -9999)</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list</code></dt>
<dd>Of the form <code>[(index, value), &hellip;]</code> for each time step</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def spatial_average(
        nc, keys, reducer, t_labels = None, subset_bbox = None, nodata = -9999):
    &#39;&#39;&#39;
    Calculates a spatial average across a NetCDF time series variable.

    Parameters
    ----------
    nc : netCDF4.Dataset
        The NetCDF file (opened)
    keys : tuple
        A tuple of (variable, x_coords, y_coords) where variable is the
        variable name, x_coords the name of the X-coordinate array variable,
        y_coords the name of the Y-coordinate array variable
    reducer : function
        A vectorized function that returns a scalar for an input vector of
        values; should ignore np.nan values
    t_labels : tuple or list
        (Optional) A vector of time index labels
    subset_bbox : tuple
        (Optional) To specify a subset area for the spatial average (i.e.,
        instead of averaging over the entire NetCDF array domain), pass a
        bounding box argument
    nodata : int or float
        The NoData value to ignore (Default: -9999)

    Returns
    -------
    list
        Of the form `[(index, value), ...]` for each time step
    &#39;&#39;&#39;
    if subset_bbox is not None:
        x_coords = nc.variables[keys[1]][:]
        y_coords = nc.variables[keys[2]][:]
        if np.array(nc.variables[keys[1]][:]).max() &gt; 180:
            # Correct for weird NetCDF easting
            x_coords = nc.variables[keys[1]][:] - 180
        x_idx, y_idx = get_slice_idx_by_bbox(
            x_coords, y_coords, subset_bbox = subset_bbox)
        xmin, xmax = x_idx
        ymin, ymax = y_idx

    scale = 1
    if hasattr(nc.variables[keys[0]], &#39;scale_factor&#39;):
        scale = nc.variables[keys[0]].scale_factor

    offset = 0
    if hasattr(nc.variables[keys[0]], &#39;add_offset&#39;):
        offset = nc.variables[keys[0]].add_offset

    num_epochs = nc.variables[keys[0]].shape[0]
    time_series = []
    for i, t in enumerate(range(0, num_epochs)):
        if subset_bbox is not None:
            arr = nc.variables[keys[0]][:][t, ymin:ymax, xmin:xmax]

        else:
            arr = nc.variables[keys[0]][:][t,...]

        index = t
        if t_labels is not None:
            index = t_labels[i]

        time_series.append((
            # Filter out NoData; use summary function that ignores NaNs
            index, reducer( # Multiply by scale, add offset
                np.where(arr == nodata, np.nan, (arr * scale) + offset))
        ))

    return time_series</code></pre>
</details>
</dd>
<dt id="pyl4c.lib.netcdf.time_series"><code class="name flex">
<span>def <span class="ident">time_series</span></span>(<span>netcdf_time_axis, has_leap=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Constructs a series of datetime.datetime elements based on a netCDF
time axis; assumes that time steps are evenly spaced (except in leap
years) and ignores fractional time steps.</p>
<p>NOTE: This is EXTREMELY difficult to get right because of awful
implementation of time axes in the typical netCDF dataset. Among other
challenges&hellip; Apparently, netCDF time axes use the convention that if the
epoch starts at midnight, the first day is the "zeroth" day; e.g., CLM5.0
states its time axis is "days since 1700-01-01 00:00:00" but the first
time step is 31.0; it seems highly unlike this monthly time series would
start in February (Jan. 1 + 31 days == Feb. 1), so they must be using the
<em>last day</em> of each month (e.g., Jan 0 + 31 days == Jan. 31).</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>netcdf_time_axis</code></strong> :&ensp;<code>netCDF4._netCDF4.Variable</code></dt>
<dd>Variable that describes the time axis</dd>
<dt><strong><code>has_leap</code></strong> :&ensp;<code>bool</code> or <code>None</code></dt>
<dd>Set True to force recognition of leap years; if None, will attempt
to automatically determine whether leap years should be recognized
based on the field metadata (Default: None)</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list</code></dt>
<dd><code>[*datetime.date|datetime.datetime]</code></dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def time_series(netcdf_time_axis, has_leap = None):
    &#39;&#39;&#39;
    Constructs a series of datetime.datetime elements based on a netCDF
    time axis; assumes that time steps are evenly spaced (except in leap
    years) and ignores fractional time steps.

    NOTE: This is EXTREMELY difficult to get right because of awful
    implementation of time axes in the typical netCDF dataset. Among other
    challenges... Apparently, netCDF time axes use the convention that if the
    epoch starts at midnight, the first day is the &#34;zeroth&#34; day; e.g., CLM5.0
    states its time axis is &#34;days since 1700-01-01 00:00:00&#34; but the first
    time step is 31.0; it seems highly unlike this monthly time series would
    start in February (Jan. 1 + 31 days == Feb. 1), so they must be using the
    *last day* of each month (e.g., Jan 0 + 31 days == Jan. 31).

    Parameters
    ----------
    netcdf_time_axis : netCDF4._netCDF4.Variable
        Variable that describes the time axis
    has_leap : bool or None
        Set True to force recognition of leap years; if None, will attempt
        to automatically determine whether leap years should be recognized
        based on the field metadata (Default: None)

    Returns
    -------
    list
        `[*datetime.date|datetime.datetime]`
    &#39;&#39;&#39;
    steps = netcdf_time_axis[:]
    interval, epoch = parse_time_units(netcdf_time_axis)
    convention = getattr(netcdf_time_axis, &#39;calendar&#39;, &#39;&#39;)
    if hasattr(convention, &#39;decode&#39;):
        convention = convention.decode(&#39;utf-8&#39;)

    # Attempt to determine leap year recognition
    if has_leap is None:
        has_leap = convention in (&#39;&#39;, &#39;standard&#39;, &#39;gregorian&#39;)

    first_step = steps[1] - steps[0]
    # Basically, we can tolerate different step sizes for intervals that
    #   can be passed to datetime.timedelta, which assumes leap years;
    #   in all other cases, we can&#39;t calculate time steps correctly
    if not has_leap:
        if not np.all(np.array(steps[1:]) - np.array(steps[:-1]) == first_step):
            assert interval in (&#39;seconds&#39;, &#39;hours&#39;, &#39;days&#39;),\
                &#39;Time series is not evenly spaced and leap years do not explain this discrepancy&#39;

    ldays = 1 if has_leap else 0
    ndays = 365
    if NDAYS_RX.match(convention) is not None:
        # Some datasets oddly have, e.g., &#34;360_day&#34; conventions
        ndays = int(NDAYS_RX.match(convention).groups()[0])

    # Because timedelta can&#39;t process intervals higher than &#34;days&#34;...
    if interval == &#39;years&#39;:
        # Simple years series starting January 1 if units are years
        years = np.arange(epoch.year, epoch.year + steps[-1] + 1)
        time_axis = [datetime.date(int(y), 1, 1) for y in years]
    elif interval == &#39;months&#39;:
        time_axis = []
        m_range = (np.arange(0, len(steps)) + epoch.month) % 12
        m_range = np.where(m_range == 0, 12, m_range)
        for t, t_value in enumerate(steps):
            m = m_range[t]
            y = epoch.year + np.floor(t_value / 12)
            time_axis.append(datetime.date(int(y), int(m), epoch.day))
    # But if time intervals are in &#34;seconds,&#34; &#34;hours,&#34; or &#34;days&#34;
    elif interval in (&#39;seconds&#39;, &#39;hours&#39;, &#39;days&#39;) and has_leap:
        time_axis = [
            epoch +
                datetime.timedelta(**{interval: int(t)}) for t in steps
        ]
    # But timedelta assumes leap years are in use, so if the time series
    #   doesn&#39;t use leap years, we must construct it manually
    else:
        time_axis = []
        this_year = epoch.year
        mdays = np.cumsum(calendar.mdays)
        for t in steps:
            if interval == &#39;seconds&#39;:
                y = epoch.year + (t / (ndays * 24 * 60 * 60))
            if interval == &#39;hours&#39;:
                y = epoch.year + (t / (ndays * 24))
            if interval in (&#39;seconds&#39;, &#39;hours&#39;):
                m = bisect_left(mdays, ((y - epoch.year) * ndays) % ndays)
                d = (((y - epoch.year) * ndays) % ndays) - mdays[m - 1]
            if interval == &#39;days&#39;:
                y = epoch.year + (t / ndays) # e.g., t / 365
                # Incidentally, the left &#34;sorting index&#34; is the month number
                m = bisect_left(mdays, t % ndays)
                m += 1 if m == 0 else 0
                d = (t % ndays) - mdays[m - 1] # And days are what is left over
                d += 1 if d == 0 else 0
            time_axis.append(datetime.datetime(int(y), int(m), int(d)))
    return time_axis</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<header>
<a class="homelink" rel="home" title="SMAP Mission Homepage" href="https://smap.jpl.nasa.gov/">
<img src="templates/images/logo_SMAP.jpg" alt="">
</a>
</header>
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="pyl4c.lib" href="index.html">pyl4c.lib</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="two-column">
<li><code><a title="pyl4c.lib.netcdf.nc_dim" href="#pyl4c.lib.netcdf.nc_dim">nc_dim</a></code></li>
<li><code><a title="pyl4c.lib.netcdf.netcdf_array" href="#pyl4c.lib.netcdf.netcdf_array">netcdf_array</a></code></li>
<li><code><a title="pyl4c.lib.netcdf.netcdf_raster" href="#pyl4c.lib.netcdf.netcdf_raster">netcdf_raster</a></code></li>
<li><code><a title="pyl4c.lib.netcdf.parse_time_units" href="#pyl4c.lib.netcdf.parse_time_units">parse_time_units</a></code></li>
<li><code><a title="pyl4c.lib.netcdf.spatial_average" href="#pyl4c.lib.netcdf.spatial_average">spatial_average</a></code></li>
<li><code><a title="pyl4c.lib.netcdf.time_series" href="#pyl4c.lib.netcdf.time_series">time_series</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>