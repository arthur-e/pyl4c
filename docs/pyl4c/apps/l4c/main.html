<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>pyl4c.apps.l4c.main API documentation</title>
<meta name="description" content="The L4C Science model, for computing a total carbon budget for specific
geographic point locations. This is a &#34;point&#34; version, similar to the Matlab
â€¦" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>pyl4c.apps.l4c.main</code></h1>
</header>
<section id="section-intro">
<p>The L4C Science model, for computing a total carbon budget for specific
geographic point locations. This is a "point" version, similar to the Matlab
calibration code, that runs L4C for individual cells; it is NOT intended to
run L4C daily for the global domain.</p>
<p>The <code><a title="pyl4c.apps.l4c.main.L4CForwardProcessPoint" href="#pyl4c.apps.l4c.main.L4CForwardProcessPoint">L4CForwardProcessPoint</a></code> has the same model logic as the L4C operational
algorithm that is run at Goddard Space Flight Center. However, it does not
produce "bit-to-bit" identical results as L4C Ops, chiefly because of
differences in the spatial reference system (SRS) definitions used for
extracting and compiling driver data, but also because the initial soil
organic carbon (SOC) data does not match. This mismatch is hard to account
for; we've tried multiple SOC restart files but none of them match what
Goddard is using. It's possible this is also due entirely to the SRS mismatch.</p>
<p>Possible optimizations:</p>
<ul>
<li>Pre-compute the product of APAR and optimal LUE.</li>
<li>Will break with L4C MDL (Ops) code, but it's more memory efficient
to assign initial SOC pool sizes to t=0 and makes very (very) little
difference in the end.</li>
</ul>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#39;&#39;&#39;
The L4C Science model, for computing a total carbon budget for specific
geographic point locations. This is a &#34;point&#34; version, similar to the Matlab
calibration code, that runs L4C for individual cells; it is NOT intended to
run L4C daily for the global domain.

The `L4CForwardProcessPoint` has the same model logic as the L4C operational
algorithm that is run at Goddard Space Flight Center. However, it does not
produce &#34;bit-to-bit&#34; identical results as L4C Ops, chiefly because of
differences in the spatial reference system (SRS) definitions used for
extracting and compiling driver data, but also because the initial soil
organic carbon (SOC) data does not match. This mismatch is hard to account
for; we&#39;ve tried multiple SOC restart files but none of them match what
Goddard is using. It&#39;s possible this is also due entirely to the SRS mismatch.

Possible optimizations:

- Pre-compute the product of APAR and optimal LUE.
- Will break with L4C MDL (Ops) code, but it&#39;s more memory efficient
    to assign initial SOC pool sizes to t=0 and makes very (very) little
    difference in the end.
&#39;&#39;&#39;

import datetime
import numpy as np
import h5py
from pyl4c import suppress_warnings
from pyl4c.data.fixtures import restore_bplut
from pyl4c.science import arrhenius
from pyl4c.stats import linear_constraint
from pyl4c.lib.cli import ProgressBar
from pyl4c.apps.l4c import L4CConstants, L4CDrivers, L4CState, report
from pyl4c.apps.l4c.io import L4CStreamingInputDataset

class L4CForwardProcessPoint(object):
    &#39;&#39;&#39;
    Outputs of L4C include both State variables (soil organic carbon) and Flux
    variables (NEE, GPP, RH).

    NOTE: In `debug = True` mode, the Emult and Kmult diagnostic parameters
    are disaggregated and the individual environmental constraint multipliers
    are stored. Outside of debug mode, only Emult, Tmult, and Wmult are
    reported.

    Parameters
    ----------
    config : dict
        Dictionary of configuration parameters
    stream : bool
        True to use L4CStreamingInputDataset instead of reading in all driver
        data; this reduces memory use but increases I/O
    verbose : bool
        True to print all output to stdout
    debug : bool
        True to store additional diagnostic information from each time step
    &#39;&#39;&#39;
    DAYS_PER_YEAR = 365
    BOUNDS = {
        &#39;apar&#39;: [0, np.inf],
        &#39;vpd&#39;: [np.nan, np.nan],
        &#39;ft&#39;: [0, 1],
        &#39;smrz&#39;: [0, 100],
        &#39;smsf&#39;: [0, 100],
        &#39;tmin&#39;: [-200, 400],
        &#39;tsoil&#39;: [-200, 400],
        &#39;tsurf&#39;: [-200, 400],
    }
    CONSTANTS = {
        &#39;tsoil_beta1&#39;: 66.02,
        &#39;tsoil_beta2&#39;: 227.13,
        &#39;tsurf_freeze-thaw_threshold_kelvin&#39;: 273.15
    }
    CONSTANTS_INDEX = (
        &#39;CUE&#39;, &#39;LUE&#39;, &#39;f_metabolic&#39;, &#39;f_structural&#39;, &#39;decay_rates&#39;)
    # These MUST be listed in a fixed order...
    CONSTRAINTS_INDEX = ( # Constraints on GPP or RECO
        &#39;tmin&#39;, &#39;vpd&#39;, &#39;ft&#39;, &#39;smrz&#39;, &#39;tsoil&#39;, &#39;smsf&#39;)
    DIAGNOSTICS_INDEX = (
        &#39;f_tmin&#39;, &#39;f_vpd&#39;, &#39;f_ft&#39;, &#39;f_smrz&#39;, &#39;f_tsoil&#39;, &#39;f_smsf&#39;, &#39;apar&#39;)
    DRIVERS_INDEX = (&#39;apar&#39;, &#39;tmin&#39;, &#39;vpd&#39;, &#39;ft&#39;, &#39;smrz&#39;, &#39;tsoil&#39;, &#39;smsf&#39;)
    FLUX_INDEX = (&#39;gpp&#39;, &#39;rh&#39;, &#39;nee&#39;)
    STATE_INDEX = (&#39;soc1&#39;, &#39;soc2&#39;, &#39;soc3&#39;, &#39;e_mult&#39;, &#39;t_mult&#39;, &#39;w_mult&#39;)
    PFT_CODES = range(1, 10)
    REQUIRED_CONFIGURATION = (&#39;bplut&#39;, &#39;inputs_file_path&#39;, &#39;site_count&#39;)

    def __init__(
            self, config, stream = True, use_legacy_pft = False,
            verbose = True, debug = False):
        self._check_configuration(config)
        self._bplut = config[&#39;bplut&#39;]
        self._config = config
        self._constraints = dict()
        self._debug = debug
        self._multilayer = False # Single soil layer
        self._streaming = stream
        self._t0 = 0 # Starting time index
        self._t1 = config[&#39;time_steps&#39;]
        self._time_idx = -1
        self._verbose = verbose
        self._use_legacy_pft = use_legacy_pft
        self.file_path = config[&#39;inputs_file_path&#39;]
        if verbose:
            print(&#39;NOTE: Running with BPLUT version %s&#39; % self._bplut[&#39;_version&#39;])
        with h5py.File(self.file_path, &#39;r&#39;) as hdf:
            self._setup(config, hdf)

    @property
    def config(self):
        return self._config

    @property
    def constants(self):
        return self._constants

    @property
    def drivers(self):
        return self._drivers # NOTE: No setter

    @property
    def fluxes(self):
        return self._fluxes

    @fluxes.setter
    def fluxes(self, new):
        self._fluxes.data = new

    @property
    def state(self):
        return self._state

    @state.setter
    def state(self, new):
        self._state.data = new

    def _arrhenius(self, tsoil):
        &#39;The Arrhenius equation for response of enzymes to (soil) temperature&#39;
        beta1, beta2 = (self.CONSTANTS[&#39;tsoil_beta%d&#39; % i] for i in (1, 2))
        return arrhenius(tsoil, self._constraints[&#39;tsoil&#39;], beta1, beta2)

    def _load_constants(self):
        &#39;Load arrays of constants for each PFT class, to speed up computation&#39;
        for label in self.CONSTANTS_INDEX:
            self.constants.add(self._bplut[label], label)

    def _load_constraints(self, pft, drivers_constrained):
        &#39;Creates [3 x N x 81] array of lower, upper bounds for ramp functions&#39;
        # The third axis is the range (max - min), or difference between the
        #   first and second axes
        by_pft = pft.ravel()
        # Set invalid PFT codes to PFT 0
        by_pft = np.where(np.in1d(by_pft, self.PFT_CODES), by_pft, 0)
        shp = (2, self.config[&#39;site_count&#39;], 81)

        # For each driver, propagate the BPLUT coefficients by PFT class
        for driver in drivers_constrained:
            # Tsoil requires a single coefficient; not lower, upper bounds
            if driver == &#39;tsoil&#39;:
                self._constraints[&#39;tsoil&#39;] = np.apply_along_axis(
                    lambda p: self._bplut[&#39;tsoil&#39;][0,p], 0, by_pft)\
                    .reshape((shp[1], shp[2]))
                continue

            # Get lower and upper bounds by PFT class
            self._constraints[driver] = np.apply_along_axis(
                lambda p: self._bplut[driver][:,p], 0, by_pft).reshape(shp)

    def _load_drivers(self, hdf, keys):
        &#39;Load driver variables all at once from the HDF&#39;
        new_drivers = []
        for key in keys:
            if key not in (&#39;apar&#39;, &#39;ft&#39;):
                assert key in hdf[&#39;drivers&#39;].keys(),\
                    &#39;Required driver &#34;%s&#34; not found in inputs HDF5&#39; % key

            if key == &#39;apar&#39;:
                for k in (&#39;fpar&#39;, &#39;par&#39;):
                    assert k in hdf[&#39;drivers&#39;].keys(),\
                        &#39;Required driver &#34;%s&#34; not found in inputs HDF5&#39; % k
                par = hdf[&#39;drivers/par&#39;][self._t0:,...]
                par = par.reshape((*par.shape, 1)).repeat(81, axis = 2)
                # APAR is the product of fPAR and PAR
                new_drivers.append(
                    np.multiply(hdf[&#39;drivers/fpar&#39;][self._t0:,...], par))
                continue

            if key == &#39;ft&#39;:
                # Use &#34;ft&#34; or &#34;tsurf&#34; depending on what&#39;s available to obtain
                #   a freeze-thaw record
                if &#39;ft&#39; in hdf[&#39;drivers&#39;].keys():
                    self._print(&#39;Using existing freeze-thaw driver data instead of &#34;tsurf&#34;&#39;)
                    new_drivers.append(hdf[&#39;drivers/ft&#39;][self._t0:,...])
                    continue
                elif &#39;tsurf&#39; in hdf[&#39;drivers&#39;].keys():
                    k = self.CONSTANTS[&#39;tsurf_freeze-thaw_threshold_kelvin&#39;]
                    self._print(&#39;Calculating freeze-thaw condition using &#34;tsurf&#34; and cutoff of %f degrees K&#39; % k)
                    new_drivers.append( # Frozen = 0, Thawed = 1
                        np.where(
                            hdf[&#39;drivers/tsurf&#39;][self._t0:,...] &lt;= k, 0, 1))
                    continue
                else:
                    raise ValueError(&#39;No freeze-thaw driver data found&#39;)

            # In all other cases
            new_drivers.append(hdf[&#39;drivers/%s&#39; % key][self._t0:,...])

        return new_drivers

    @suppress_warnings
    def _load_state(self, hdf, keys):
        &#39;&#39;&#39;
        Load state variables (soil organic carbon) all at once from the HDF.
        An array large enough to hold model state is created (&#34;new_state&#34;),
        but also the initial state (&#34;init_state&#34;) is created.
        &#39;&#39;&#39;
        shp = (1, self.config[&#39;time_steps&#39;], self.config[&#39;site_count&#39;], 81)
        init_state = []
        new_state = []
        for p, key in enumerate(keys):
            # Create an empty state array, allocated T time steps
            new_state.append(np.full(shp, np.nan))
            if key.startswith(&#39;soc&#39;):
                arr = hdf[&#39;state/soil_organic_carbon&#39;][p,...]
                # Filter out any NoData, which (should) only correspond to
                #   1-km subgrid pixels that are outside the PFT range [1, 8]
                init_state.append(
                    np.where(arr &lt; 0, np.nan, arr).reshape((1, 1, *shp[2:])))
            else:
                if key not in self.DIAGNOSTICS_INDEX:
                    init_state.append(np.full((1, 1, *shp[2:]), np.nan))
        return (init_state, new_state)

    def _setup(self, config, hdf):
        &#39;Load point site PFTs, state data, driver data&#39;
        # Get the starting time index, if specified
        if &#39;start&#39; in config.keys():
            if config[&#39;start&#39;] is not None:
                try:
                    ts0 = datetime.datetime.strptime(
                        config[&#39;start&#39;], &#39;%Y-%m-%dT%H:%M:%S&#39;)
                except ValueError:
                    ts0 = datetime.datetime.strptime(
                        config[&#39;start&#39;], &#39;%Y-%m-%d&#39;)
                self._t0 = np.argwhere(
                    np.logical_and(np.logical_and(
                        hdf[&#39;time&#39;][:,0] == ts0.year,
                        hdf[&#39;time&#39;][:,1] == ts0.month),
                        hdf[&#39;time&#39;][:,2] == ts0.day)
                    ).flatten().tolist().pop()
        if &#39;end&#39; in config.keys():
            if config[&#39;end&#39;] is not None:
                try:
                    ts1 = datetime.datetime.strptime(
                        config[&#39;end&#39;], &#39;%Y-%m-%dT%H:%M:%S&#39;)
                except ValueError:
                    ts1 = datetime.datetime.strptime(
                        config[&#39;end&#39;], &#39;%Y-%m-%d&#39;)
                self._t1 = np.argwhere(
                    np.logical_and(np.logical_and(
                        hdf[&#39;time&#39;][:,0] == ts1.year,
                        hdf[&#39;time&#39;][:,1] == ts1.month),
                        hdf[&#39;time&#39;][:,2] == ts1.day)
                    ).flatten().tolist().pop()

        # And check that the correct number of steps were specified
        assert config[&#39;time_steps&#39;] == (hdf[&#39;time&#39;].shape[0] - self._t0)\
            or config[&#39;time_steps&#39;] == (self._t1 - self._t0),\
            &#39;Parameter &#34;time_steps&#34; does not match the number of time steps suggested by &#34;start&#34; parameter and the &#34;time&#34; field&#39;

        self._print(&#39;Accessing state and drivers data...&#39;)
        if self._use_legacy_pft:
            self._pft = hdf[&#39;legacy/lc_dom&#39;][:].swapaxes(0, 1)
        else:
            self._pft = hdf[&#39;state/PFT&#39;][:]

        # Initialize containers for various datasets
        self._setup_data_storage(config, hdf)

        # Calculate daily litterfall based on the annual NPP sum
        self.constants.add(
            hdf[&#39;state/npp_sum&#39;][:] / self.DAYS_PER_YEAR, &#39;litterfall&#39;)

        # SET STATE
        self._print(&#39;Loading state...&#39;)
        keys = list(self.STATE_INDEX)
        if self._debug:
            keys.extend(self.DIAGNOSTICS_INDEX)
        init_state, new_state = self._load_state(hdf, keys)
        if len(init_state) &gt; 0:
            self.state_initial = np.concatenate(init_state, axis = 0)
        if len(new_state) &gt; 0:
            self.state = np.concatenate(new_state, axis = 0)
        self.state.labels = keys

        # SET DRIVERS
        if not self._streaming:
            self._print(&#39;Loading drivers...&#39;)
            self._drivers = L4CDrivers(
                config[&#39;site_count&#39;],
                self._load_drivers(hdf, self.DRIVERS_INDEX),
                labels = self.DRIVERS_INDEX)

        # LOAD CONSTANTS
        self._print(&#39;Loading constants...&#39;)
        self._load_constants()

        # INITIALIZE CONSTRAINT FUNCTIONS
        self._print(&#39;Creating linear constraint functions...&#39;)
        self._load_constraints(self._pft, self.CONSTRAINTS_INDEX)

    def _setup_data_storage(self, config, hdf):
        &#39;Initialize containers for various datasets&#39;
        site_names = hdf[&#39;site_id&#39;][:].tolist()
        shp = (config[&#39;time_steps&#39;], config[&#39;site_count&#39;], 81)
        self._constants = L4CConstants(
            config[&#39;site_count&#39;], self._pft, self.PFT_CODES)
        self._drivers = None # We set this only once, below
        self._fluxes = L4CState(
            config[&#39;site_count&#39;], np.full((len(self.FLUX_INDEX), *shp), np.nan),
            self.FLUX_INDEX, axis_labels = [None, None, site_names, None])
        self._state = L4CState(config[&#39;site_count&#39;],
            axis_labels = [None, None, site_names, None])

    def _print(self, message):
        &#39;Only print to screen if in &#34;verbose&#34; mode&#39;
        if self._verbose:
            print(message)

    def _check_configuration(self, config):
        &#39;Checks for the existing of certain keys in the configuration file&#39;
        for key in self.REQUIRED_CONFIGURATION:
            assert key in config.keys(), &#39;%s not found&#39; % key

    def constrain(self, x, driver):
        &#39;&#39;&#39;
        Returns a linear interpolated multiple based on a ramp function.
        Equivalent to a vectorized version of:

            if x &gt;= xmax:
                return 1
            if x &lt;= xmin:
                return 0
            return (x - xmin) / (xmax - xmin)

        Parameters
        ----------
        x : float
            Observed value, generally an (N x 81) array or an array with an
            (N x 81) or (N x 1) sub-space (e.g., soil moisture values that
            are constant over the 1-km grid have no 81 unique values), so they
            will be broadcast over the 81-pixel sub-grid when combined with
            constraint parameter array
        driver : str
            Name of the driver

        Returns
        -------
        float
        &#39;&#39;&#39;
        if driver == &#39;tsoil&#39;:
            return self._arrhenius(x)

        coefs = self._constraints[driver]
        if driver == &#39;vpd&#39;:
            # VPD mult. declines with increasing VPD, unlike other drivers
            return linear_constraint(coefs[0], coefs[1], form = &#39;reversed&#39;)(x)

        if driver == &#39;ft&#39;:
            # FT has a binary response
            return linear_constraint(coefs[0], coefs[1], form = &#39;binary&#39;)(x)

        return linear_constraint(coefs[0], coefs[1])(x)

    def gpp(self, drivers):
        &#39;&#39;&#39;
        Calculate GPP for a single time step.

        Parameters
        ----------
        drivers : list or tuple
            Nested sequence of (driver: `numpy.ndarray`, label: `str`) pairs

        Returns
        -------
        numpy.ndarray
        &#39;&#39;&#39;
        # Extract APAR, translate other drivers into environ. constraints
        apar, f_tmin, f_vpd, f_ft, f_smrz = [
            self.constrain(driver, label) if label != &#39;apar&#39; else driver
            for driver, label in drivers
        ]
        e_mult = f_tmin * f_vpd * f_ft * f_smrz
        if self._debug:
            return (apar * self.constants.LUE * e_mult,
                (f_tmin, f_vpd, f_ft, f_smrz))
        return (apar * self.constants.LUE * e_mult, e_mult)

    def rh(self, state, drivers):
        &#39;&#39;&#39;
        Calculate RH for a single time step.

        Parameters
        ----------
        state : numpy.ndarray
            `(3 x N x M)` array of current SOC state in each pool
        drivers : list or tuple
            Nested sequence of (driver: `numpy.ndarray`, label: `str`) pairs

        Returns
        -------
        numpy.ndarray
        &#39;&#39;&#39;
        # Translate Tsoil and SMSF into environmental constraints on RH
        f_tsoil, f_smsf = [
            self.constrain(driver, label) for driver, label in drivers
        ]
        k_mult = (f_tsoil * f_smsf)[np.newaxis,...].repeat(3, axis = 0)
        # NOTE: These are true decay rates for 2nd and 3rd pools, so it
        #   is straightfoward to multiply them against SOC
        rh = k_mult * self.constants.decay_rates * state
        # &#34;the adjustment...to account for material transferred into the
        #   slow pool during humification&#34; (Jones et al. 2017 TGARS, p.5)
        rh[1,...] = rh[1,...] * (1 - self.constants.f_structural)
        # T_mult, W_mult same for each pool
        return (rh, (f_tsoil, f_smsf))

    def soc(self, rh, t = None):
        &#39;&#39;&#39;
        Calculate change in SOC for a single time step.

        Parameters
        ----------
        rh : numpy.ndarray
            `(3 x N x M)` array of RH at the current time step
        t : int
            Current time step; useful in subclasses but not used in the
            operational L4C algorithm (not used here)

        Returns
        -------
        numpy.ndarray
        &#39;&#39;&#39;
        # Change in SOC according to diff. eq. in Jones et al. (2017)
        litter = self.constants.litterfall
        dc1 = (litter * self.constants.f_metabolic) - rh[0,...]
        dc2 = (litter * (1 - self.constants.f_metabolic)) - rh[1,...]
        dc3 = (self.constants.f_structural * rh[1,...]) - rh[2,...]
        return (dc1, dc2, dc3)

    def run(self, steps = None, fields_gpp = None, fields_rh = None):
        &#39;&#39;&#39;
        A forward run in serial over multiple time steps; currently works in
        streaming mode ONLY.

        Parameters
        ----------
        steps : int
            Number of time steps to run or None to run through the end of the
            available time steps (exhaust driver data) (Default: `None`)
        fields_gpp : list or tuple or None
            (Optional) Sequence of field names that are used to drive the
            GPP model
        fields_rh : list or tuple or None
            (Optional) Sequence of field names that are used to drive the
            RH model
        &#39;&#39;&#39;
        @suppress_warnings
        def step(t, fields_gpp, fields_rh):
            &#39;Calculate fluxes, new states for the next time step t&#39;
            if t == 0:
                # Retrieve intial SOC pool sizes
                state = self.state_initial[0:3,0,...]
            else:
                # Retrieve SOC in each pool from prior step
                state = self.state.data[0:3,t-1,...]
            # Calculate fluxes, new states
            gpp, e_mult = self.gpp(
                zip(hdf.index(t + self._t0, *fields_gpp), fields_gpp))
            rh, k_mult = self.rh(
                state, zip(hdf.index(t + self._t0, *fields_rh), fields_rh))
            npp = gpp * self.constants.CUE
            d_soc = self.soc(rh, t + self._t0)
            # Record fluxes for this time step
            self.fluxes.update(&#39;gpp&#39;, t, gpp)
            self.fluxes.update(&#39;rh&#39;, t, rh.sum(axis = 0))
            self.fluxes.update(&#39;nee&#39;, t, rh.sum(axis = 0) - npp)
            # Record diagnostics at this time step
            if self._debug:
                # In debug mode, e_mult is not a single quantity but multiple;
                #   the order of e_mult_fields MUST match the order of the
                #   return signature for gpp()
                e_mult_fields = (&#39;f_tmin&#39;, &#39;f_vpd&#39;, &#39;f_ft&#39;, &#39;f_smrz&#39;)
                if all(f in self.DIAGNOSTICS_INDEX for f in e_mult_fields):
                    for e, key in enumerate(self.DIAGNOSTICS_INDEX):
                        if key in e_mult_fields:
                            idx = e_mult_fields.index(key)
                            self.state.update(key, t, e_mult[idx])
                # In debug mode, k_mult is not a single quantity but multiple;
                #   the order of k_mult_fields MUST match the order of the
                #   return signature for rh()
                k_mult_fields = (&#39;f_tsoil&#39;, &#39;f_smsf&#39;)
                if all(f in self.DIAGNOSTICS_INDEX for f in k_mult_fields):
                    for k, key in enumerate(self.DIAGNOSTICS_INDEX):
                        if key in k_mult_fields:
                            idx = k_mult_fields.index(key)
                            self.state.update(key, t, k_mult[idx])
                # IMPORTANT: Put e_mult back together again
                e_mult = e_mult[0] * e_mult[1] * e_mult[2] * e_mult[3]
                if &#39;apar&#39; in self.DIAGNOSTICS_INDEX:
                    self.state.update( # Back-calculating APAR as GPP/(Emult*LUE)
                        &#39;apar&#39;, t, np.divide(gpp,
                            np.multiply(e_mult, self.constants.LUE)))

            # Treat Kmult and Emult differently (i.e., break out the former
            #   but not the latter) because that is what L4C Ops does
            if &#39;e_mult&#39; in self.STATE_INDEX:
                self.state.update(&#39;e_mult&#39;, t, e_mult)
            if &#39;t_mult&#39; in self.STATE_INDEX:
                self.state.update(&#39;t_mult&#39;, t, k_mult[0])
            if &#39;w_mult&#39; in self.STATE_INDEX:
                self.state.update(&#39;w_mult&#39;, t, k_mult[1])
            # Update the SOC state
            for p in range(1, 4):
                if t == 0:
                    # At time t=0, we have no state to advance, so update
                    #   the state at t=0 based on the initial state
                    delta = np.add(self.state_initial[p-1,0,...], d_soc[p-1])
                    self.state.update(
                        &#39;soc%d&#39; % p, t, delta, bounds = (0, np.inf))
                else:
                    self.state.advance(
                        &#39;soc%d&#39; % p, t, d_soc[p-1], bounds = (0, np.inf))

        if fields_gpp is None:
            fields_gpp = [&#39;apar&#39;, &#39;tmin&#39;, &#39;vpd&#39;, &#39;ft&#39;, &#39;smrz&#39;]
        if fields_rh is None:
            fields_rh = [&#39;tsoil&#39;, &#39;smsf&#39;]
        with L4CStreamingInputDataset(
                self.file_path, self.CONSTANTS, self.BOUNDS) as hdf:
            num_steps = self.config[&#39;time_steps&#39;] if steps is None else steps
            with ProgressBar(num_steps, &#39;Running...&#39;) as progress:
                for t in range(self._time_idx + 1, num_steps):
                    step(t, fields_gpp, fields_rh)
                    self._time_idx += 1
                    progress.update(t)


if __name__ == &#39;__main__&#39;:
    # Report on a potential driver dataset with: python main.py data.h5
    import sys
    from pyl4c.data.fixtures import BPLUT

    # Example configuration for all 356 sites in the post-launch period
    config = {
        &#39;bplut&#39;: BPLUT,
        &#39;inputs_file_path&#39;: sys.argv[1],
        &#39;site_count&#39;: sys.argv[2],
        &#39;time_steps&#39;: sys.argv[3],
        &#39;start&#39;: None
    }

    with h5py.File(config[&#39;inputs_file_path&#39;], &#39;r&#39;) as hdf:
        report(hdf, config)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="pyl4c.apps.l4c.main.L4CForwardProcessPoint"><code class="flex name class">
<span>class <span class="ident">L4CForwardProcessPoint</span></span>
<span>(</span><span>config, stream=True, use_legacy_pft=False, verbose=True, debug=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Outputs of L4C include both State variables (soil organic carbon) and Flux
variables (NEE, GPP, RH).</p>
<p>NOTE: In <code>debug = True</code> mode, the Emult and Kmult diagnostic parameters
are disaggregated and the individual environmental constraint multipliers
are stored. Outside of debug mode, only Emult, Tmult, and Wmult are
reported.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>config</code></strong> :&ensp;<code>dict</code></dt>
<dd>Dictionary of configuration parameters</dd>
<dt><strong><code>stream</code></strong> :&ensp;<code>bool</code></dt>
<dd>True to use L4CStreamingInputDataset instead of reading in all driver
data; this reduces memory use but increases I/O</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>bool</code></dt>
<dd>True to print all output to stdout</dd>
<dt><strong><code>debug</code></strong> :&ensp;<code>bool</code></dt>
<dd>True to store additional diagnostic information from each time step</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class L4CForwardProcessPoint(object):
    &#39;&#39;&#39;
    Outputs of L4C include both State variables (soil organic carbon) and Flux
    variables (NEE, GPP, RH).

    NOTE: In `debug = True` mode, the Emult and Kmult diagnostic parameters
    are disaggregated and the individual environmental constraint multipliers
    are stored. Outside of debug mode, only Emult, Tmult, and Wmult are
    reported.

    Parameters
    ----------
    config : dict
        Dictionary of configuration parameters
    stream : bool
        True to use L4CStreamingInputDataset instead of reading in all driver
        data; this reduces memory use but increases I/O
    verbose : bool
        True to print all output to stdout
    debug : bool
        True to store additional diagnostic information from each time step
    &#39;&#39;&#39;
    DAYS_PER_YEAR = 365
    BOUNDS = {
        &#39;apar&#39;: [0, np.inf],
        &#39;vpd&#39;: [np.nan, np.nan],
        &#39;ft&#39;: [0, 1],
        &#39;smrz&#39;: [0, 100],
        &#39;smsf&#39;: [0, 100],
        &#39;tmin&#39;: [-200, 400],
        &#39;tsoil&#39;: [-200, 400],
        &#39;tsurf&#39;: [-200, 400],
    }
    CONSTANTS = {
        &#39;tsoil_beta1&#39;: 66.02,
        &#39;tsoil_beta2&#39;: 227.13,
        &#39;tsurf_freeze-thaw_threshold_kelvin&#39;: 273.15
    }
    CONSTANTS_INDEX = (
        &#39;CUE&#39;, &#39;LUE&#39;, &#39;f_metabolic&#39;, &#39;f_structural&#39;, &#39;decay_rates&#39;)
    # These MUST be listed in a fixed order...
    CONSTRAINTS_INDEX = ( # Constraints on GPP or RECO
        &#39;tmin&#39;, &#39;vpd&#39;, &#39;ft&#39;, &#39;smrz&#39;, &#39;tsoil&#39;, &#39;smsf&#39;)
    DIAGNOSTICS_INDEX = (
        &#39;f_tmin&#39;, &#39;f_vpd&#39;, &#39;f_ft&#39;, &#39;f_smrz&#39;, &#39;f_tsoil&#39;, &#39;f_smsf&#39;, &#39;apar&#39;)
    DRIVERS_INDEX = (&#39;apar&#39;, &#39;tmin&#39;, &#39;vpd&#39;, &#39;ft&#39;, &#39;smrz&#39;, &#39;tsoil&#39;, &#39;smsf&#39;)
    FLUX_INDEX = (&#39;gpp&#39;, &#39;rh&#39;, &#39;nee&#39;)
    STATE_INDEX = (&#39;soc1&#39;, &#39;soc2&#39;, &#39;soc3&#39;, &#39;e_mult&#39;, &#39;t_mult&#39;, &#39;w_mult&#39;)
    PFT_CODES = range(1, 10)
    REQUIRED_CONFIGURATION = (&#39;bplut&#39;, &#39;inputs_file_path&#39;, &#39;site_count&#39;)

    def __init__(
            self, config, stream = True, use_legacy_pft = False,
            verbose = True, debug = False):
        self._check_configuration(config)
        self._bplut = config[&#39;bplut&#39;]
        self._config = config
        self._constraints = dict()
        self._debug = debug
        self._multilayer = False # Single soil layer
        self._streaming = stream
        self._t0 = 0 # Starting time index
        self._t1 = config[&#39;time_steps&#39;]
        self._time_idx = -1
        self._verbose = verbose
        self._use_legacy_pft = use_legacy_pft
        self.file_path = config[&#39;inputs_file_path&#39;]
        if verbose:
            print(&#39;NOTE: Running with BPLUT version %s&#39; % self._bplut[&#39;_version&#39;])
        with h5py.File(self.file_path, &#39;r&#39;) as hdf:
            self._setup(config, hdf)

    @property
    def config(self):
        return self._config

    @property
    def constants(self):
        return self._constants

    @property
    def drivers(self):
        return self._drivers # NOTE: No setter

    @property
    def fluxes(self):
        return self._fluxes

    @fluxes.setter
    def fluxes(self, new):
        self._fluxes.data = new

    @property
    def state(self):
        return self._state

    @state.setter
    def state(self, new):
        self._state.data = new

    def _arrhenius(self, tsoil):
        &#39;The Arrhenius equation for response of enzymes to (soil) temperature&#39;
        beta1, beta2 = (self.CONSTANTS[&#39;tsoil_beta%d&#39; % i] for i in (1, 2))
        return arrhenius(tsoil, self._constraints[&#39;tsoil&#39;], beta1, beta2)

    def _load_constants(self):
        &#39;Load arrays of constants for each PFT class, to speed up computation&#39;
        for label in self.CONSTANTS_INDEX:
            self.constants.add(self._bplut[label], label)

    def _load_constraints(self, pft, drivers_constrained):
        &#39;Creates [3 x N x 81] array of lower, upper bounds for ramp functions&#39;
        # The third axis is the range (max - min), or difference between the
        #   first and second axes
        by_pft = pft.ravel()
        # Set invalid PFT codes to PFT 0
        by_pft = np.where(np.in1d(by_pft, self.PFT_CODES), by_pft, 0)
        shp = (2, self.config[&#39;site_count&#39;], 81)

        # For each driver, propagate the BPLUT coefficients by PFT class
        for driver in drivers_constrained:
            # Tsoil requires a single coefficient; not lower, upper bounds
            if driver == &#39;tsoil&#39;:
                self._constraints[&#39;tsoil&#39;] = np.apply_along_axis(
                    lambda p: self._bplut[&#39;tsoil&#39;][0,p], 0, by_pft)\
                    .reshape((shp[1], shp[2]))
                continue

            # Get lower and upper bounds by PFT class
            self._constraints[driver] = np.apply_along_axis(
                lambda p: self._bplut[driver][:,p], 0, by_pft).reshape(shp)

    def _load_drivers(self, hdf, keys):
        &#39;Load driver variables all at once from the HDF&#39;
        new_drivers = []
        for key in keys:
            if key not in (&#39;apar&#39;, &#39;ft&#39;):
                assert key in hdf[&#39;drivers&#39;].keys(),\
                    &#39;Required driver &#34;%s&#34; not found in inputs HDF5&#39; % key

            if key == &#39;apar&#39;:
                for k in (&#39;fpar&#39;, &#39;par&#39;):
                    assert k in hdf[&#39;drivers&#39;].keys(),\
                        &#39;Required driver &#34;%s&#34; not found in inputs HDF5&#39; % k
                par = hdf[&#39;drivers/par&#39;][self._t0:,...]
                par = par.reshape((*par.shape, 1)).repeat(81, axis = 2)
                # APAR is the product of fPAR and PAR
                new_drivers.append(
                    np.multiply(hdf[&#39;drivers/fpar&#39;][self._t0:,...], par))
                continue

            if key == &#39;ft&#39;:
                # Use &#34;ft&#34; or &#34;tsurf&#34; depending on what&#39;s available to obtain
                #   a freeze-thaw record
                if &#39;ft&#39; in hdf[&#39;drivers&#39;].keys():
                    self._print(&#39;Using existing freeze-thaw driver data instead of &#34;tsurf&#34;&#39;)
                    new_drivers.append(hdf[&#39;drivers/ft&#39;][self._t0:,...])
                    continue
                elif &#39;tsurf&#39; in hdf[&#39;drivers&#39;].keys():
                    k = self.CONSTANTS[&#39;tsurf_freeze-thaw_threshold_kelvin&#39;]
                    self._print(&#39;Calculating freeze-thaw condition using &#34;tsurf&#34; and cutoff of %f degrees K&#39; % k)
                    new_drivers.append( # Frozen = 0, Thawed = 1
                        np.where(
                            hdf[&#39;drivers/tsurf&#39;][self._t0:,...] &lt;= k, 0, 1))
                    continue
                else:
                    raise ValueError(&#39;No freeze-thaw driver data found&#39;)

            # In all other cases
            new_drivers.append(hdf[&#39;drivers/%s&#39; % key][self._t0:,...])

        return new_drivers

    @suppress_warnings
    def _load_state(self, hdf, keys):
        &#39;&#39;&#39;
        Load state variables (soil organic carbon) all at once from the HDF.
        An array large enough to hold model state is created (&#34;new_state&#34;),
        but also the initial state (&#34;init_state&#34;) is created.
        &#39;&#39;&#39;
        shp = (1, self.config[&#39;time_steps&#39;], self.config[&#39;site_count&#39;], 81)
        init_state = []
        new_state = []
        for p, key in enumerate(keys):
            # Create an empty state array, allocated T time steps
            new_state.append(np.full(shp, np.nan))
            if key.startswith(&#39;soc&#39;):
                arr = hdf[&#39;state/soil_organic_carbon&#39;][p,...]
                # Filter out any NoData, which (should) only correspond to
                #   1-km subgrid pixels that are outside the PFT range [1, 8]
                init_state.append(
                    np.where(arr &lt; 0, np.nan, arr).reshape((1, 1, *shp[2:])))
            else:
                if key not in self.DIAGNOSTICS_INDEX:
                    init_state.append(np.full((1, 1, *shp[2:]), np.nan))
        return (init_state, new_state)

    def _setup(self, config, hdf):
        &#39;Load point site PFTs, state data, driver data&#39;
        # Get the starting time index, if specified
        if &#39;start&#39; in config.keys():
            if config[&#39;start&#39;] is not None:
                try:
                    ts0 = datetime.datetime.strptime(
                        config[&#39;start&#39;], &#39;%Y-%m-%dT%H:%M:%S&#39;)
                except ValueError:
                    ts0 = datetime.datetime.strptime(
                        config[&#39;start&#39;], &#39;%Y-%m-%d&#39;)
                self._t0 = np.argwhere(
                    np.logical_and(np.logical_and(
                        hdf[&#39;time&#39;][:,0] == ts0.year,
                        hdf[&#39;time&#39;][:,1] == ts0.month),
                        hdf[&#39;time&#39;][:,2] == ts0.day)
                    ).flatten().tolist().pop()
        if &#39;end&#39; in config.keys():
            if config[&#39;end&#39;] is not None:
                try:
                    ts1 = datetime.datetime.strptime(
                        config[&#39;end&#39;], &#39;%Y-%m-%dT%H:%M:%S&#39;)
                except ValueError:
                    ts1 = datetime.datetime.strptime(
                        config[&#39;end&#39;], &#39;%Y-%m-%d&#39;)
                self._t1 = np.argwhere(
                    np.logical_and(np.logical_and(
                        hdf[&#39;time&#39;][:,0] == ts1.year,
                        hdf[&#39;time&#39;][:,1] == ts1.month),
                        hdf[&#39;time&#39;][:,2] == ts1.day)
                    ).flatten().tolist().pop()

        # And check that the correct number of steps were specified
        assert config[&#39;time_steps&#39;] == (hdf[&#39;time&#39;].shape[0] - self._t0)\
            or config[&#39;time_steps&#39;] == (self._t1 - self._t0),\
            &#39;Parameter &#34;time_steps&#34; does not match the number of time steps suggested by &#34;start&#34; parameter and the &#34;time&#34; field&#39;

        self._print(&#39;Accessing state and drivers data...&#39;)
        if self._use_legacy_pft:
            self._pft = hdf[&#39;legacy/lc_dom&#39;][:].swapaxes(0, 1)
        else:
            self._pft = hdf[&#39;state/PFT&#39;][:]

        # Initialize containers for various datasets
        self._setup_data_storage(config, hdf)

        # Calculate daily litterfall based on the annual NPP sum
        self.constants.add(
            hdf[&#39;state/npp_sum&#39;][:] / self.DAYS_PER_YEAR, &#39;litterfall&#39;)

        # SET STATE
        self._print(&#39;Loading state...&#39;)
        keys = list(self.STATE_INDEX)
        if self._debug:
            keys.extend(self.DIAGNOSTICS_INDEX)
        init_state, new_state = self._load_state(hdf, keys)
        if len(init_state) &gt; 0:
            self.state_initial = np.concatenate(init_state, axis = 0)
        if len(new_state) &gt; 0:
            self.state = np.concatenate(new_state, axis = 0)
        self.state.labels = keys

        # SET DRIVERS
        if not self._streaming:
            self._print(&#39;Loading drivers...&#39;)
            self._drivers = L4CDrivers(
                config[&#39;site_count&#39;],
                self._load_drivers(hdf, self.DRIVERS_INDEX),
                labels = self.DRIVERS_INDEX)

        # LOAD CONSTANTS
        self._print(&#39;Loading constants...&#39;)
        self._load_constants()

        # INITIALIZE CONSTRAINT FUNCTIONS
        self._print(&#39;Creating linear constraint functions...&#39;)
        self._load_constraints(self._pft, self.CONSTRAINTS_INDEX)

    def _setup_data_storage(self, config, hdf):
        &#39;Initialize containers for various datasets&#39;
        site_names = hdf[&#39;site_id&#39;][:].tolist()
        shp = (config[&#39;time_steps&#39;], config[&#39;site_count&#39;], 81)
        self._constants = L4CConstants(
            config[&#39;site_count&#39;], self._pft, self.PFT_CODES)
        self._drivers = None # We set this only once, below
        self._fluxes = L4CState(
            config[&#39;site_count&#39;], np.full((len(self.FLUX_INDEX), *shp), np.nan),
            self.FLUX_INDEX, axis_labels = [None, None, site_names, None])
        self._state = L4CState(config[&#39;site_count&#39;],
            axis_labels = [None, None, site_names, None])

    def _print(self, message):
        &#39;Only print to screen if in &#34;verbose&#34; mode&#39;
        if self._verbose:
            print(message)

    def _check_configuration(self, config):
        &#39;Checks for the existing of certain keys in the configuration file&#39;
        for key in self.REQUIRED_CONFIGURATION:
            assert key in config.keys(), &#39;%s not found&#39; % key

    def constrain(self, x, driver):
        &#39;&#39;&#39;
        Returns a linear interpolated multiple based on a ramp function.
        Equivalent to a vectorized version of:

            if x &gt;= xmax:
                return 1
            if x &lt;= xmin:
                return 0
            return (x - xmin) / (xmax - xmin)

        Parameters
        ----------
        x : float
            Observed value, generally an (N x 81) array or an array with an
            (N x 81) or (N x 1) sub-space (e.g., soil moisture values that
            are constant over the 1-km grid have no 81 unique values), so they
            will be broadcast over the 81-pixel sub-grid when combined with
            constraint parameter array
        driver : str
            Name of the driver

        Returns
        -------
        float
        &#39;&#39;&#39;
        if driver == &#39;tsoil&#39;:
            return self._arrhenius(x)

        coefs = self._constraints[driver]
        if driver == &#39;vpd&#39;:
            # VPD mult. declines with increasing VPD, unlike other drivers
            return linear_constraint(coefs[0], coefs[1], form = &#39;reversed&#39;)(x)

        if driver == &#39;ft&#39;:
            # FT has a binary response
            return linear_constraint(coefs[0], coefs[1], form = &#39;binary&#39;)(x)

        return linear_constraint(coefs[0], coefs[1])(x)

    def gpp(self, drivers):
        &#39;&#39;&#39;
        Calculate GPP for a single time step.

        Parameters
        ----------
        drivers : list or tuple
            Nested sequence of (driver: `numpy.ndarray`, label: `str`) pairs

        Returns
        -------
        numpy.ndarray
        &#39;&#39;&#39;
        # Extract APAR, translate other drivers into environ. constraints
        apar, f_tmin, f_vpd, f_ft, f_smrz = [
            self.constrain(driver, label) if label != &#39;apar&#39; else driver
            for driver, label in drivers
        ]
        e_mult = f_tmin * f_vpd * f_ft * f_smrz
        if self._debug:
            return (apar * self.constants.LUE * e_mult,
                (f_tmin, f_vpd, f_ft, f_smrz))
        return (apar * self.constants.LUE * e_mult, e_mult)

    def rh(self, state, drivers):
        &#39;&#39;&#39;
        Calculate RH for a single time step.

        Parameters
        ----------
        state : numpy.ndarray
            `(3 x N x M)` array of current SOC state in each pool
        drivers : list or tuple
            Nested sequence of (driver: `numpy.ndarray`, label: `str`) pairs

        Returns
        -------
        numpy.ndarray
        &#39;&#39;&#39;
        # Translate Tsoil and SMSF into environmental constraints on RH
        f_tsoil, f_smsf = [
            self.constrain(driver, label) for driver, label in drivers
        ]
        k_mult = (f_tsoil * f_smsf)[np.newaxis,...].repeat(3, axis = 0)
        # NOTE: These are true decay rates for 2nd and 3rd pools, so it
        #   is straightfoward to multiply them against SOC
        rh = k_mult * self.constants.decay_rates * state
        # &#34;the adjustment...to account for material transferred into the
        #   slow pool during humification&#34; (Jones et al. 2017 TGARS, p.5)
        rh[1,...] = rh[1,...] * (1 - self.constants.f_structural)
        # T_mult, W_mult same for each pool
        return (rh, (f_tsoil, f_smsf))

    def soc(self, rh, t = None):
        &#39;&#39;&#39;
        Calculate change in SOC for a single time step.

        Parameters
        ----------
        rh : numpy.ndarray
            `(3 x N x M)` array of RH at the current time step
        t : int
            Current time step; useful in subclasses but not used in the
            operational L4C algorithm (not used here)

        Returns
        -------
        numpy.ndarray
        &#39;&#39;&#39;
        # Change in SOC according to diff. eq. in Jones et al. (2017)
        litter = self.constants.litterfall
        dc1 = (litter * self.constants.f_metabolic) - rh[0,...]
        dc2 = (litter * (1 - self.constants.f_metabolic)) - rh[1,...]
        dc3 = (self.constants.f_structural * rh[1,...]) - rh[2,...]
        return (dc1, dc2, dc3)

    def run(self, steps = None, fields_gpp = None, fields_rh = None):
        &#39;&#39;&#39;
        A forward run in serial over multiple time steps; currently works in
        streaming mode ONLY.

        Parameters
        ----------
        steps : int
            Number of time steps to run or None to run through the end of the
            available time steps (exhaust driver data) (Default: `None`)
        fields_gpp : list or tuple or None
            (Optional) Sequence of field names that are used to drive the
            GPP model
        fields_rh : list or tuple or None
            (Optional) Sequence of field names that are used to drive the
            RH model
        &#39;&#39;&#39;
        @suppress_warnings
        def step(t, fields_gpp, fields_rh):
            &#39;Calculate fluxes, new states for the next time step t&#39;
            if t == 0:
                # Retrieve intial SOC pool sizes
                state = self.state_initial[0:3,0,...]
            else:
                # Retrieve SOC in each pool from prior step
                state = self.state.data[0:3,t-1,...]
            # Calculate fluxes, new states
            gpp, e_mult = self.gpp(
                zip(hdf.index(t + self._t0, *fields_gpp), fields_gpp))
            rh, k_mult = self.rh(
                state, zip(hdf.index(t + self._t0, *fields_rh), fields_rh))
            npp = gpp * self.constants.CUE
            d_soc = self.soc(rh, t + self._t0)
            # Record fluxes for this time step
            self.fluxes.update(&#39;gpp&#39;, t, gpp)
            self.fluxes.update(&#39;rh&#39;, t, rh.sum(axis = 0))
            self.fluxes.update(&#39;nee&#39;, t, rh.sum(axis = 0) - npp)
            # Record diagnostics at this time step
            if self._debug:
                # In debug mode, e_mult is not a single quantity but multiple;
                #   the order of e_mult_fields MUST match the order of the
                #   return signature for gpp()
                e_mult_fields = (&#39;f_tmin&#39;, &#39;f_vpd&#39;, &#39;f_ft&#39;, &#39;f_smrz&#39;)
                if all(f in self.DIAGNOSTICS_INDEX for f in e_mult_fields):
                    for e, key in enumerate(self.DIAGNOSTICS_INDEX):
                        if key in e_mult_fields:
                            idx = e_mult_fields.index(key)
                            self.state.update(key, t, e_mult[idx])
                # In debug mode, k_mult is not a single quantity but multiple;
                #   the order of k_mult_fields MUST match the order of the
                #   return signature for rh()
                k_mult_fields = (&#39;f_tsoil&#39;, &#39;f_smsf&#39;)
                if all(f in self.DIAGNOSTICS_INDEX for f in k_mult_fields):
                    for k, key in enumerate(self.DIAGNOSTICS_INDEX):
                        if key in k_mult_fields:
                            idx = k_mult_fields.index(key)
                            self.state.update(key, t, k_mult[idx])
                # IMPORTANT: Put e_mult back together again
                e_mult = e_mult[0] * e_mult[1] * e_mult[2] * e_mult[3]
                if &#39;apar&#39; in self.DIAGNOSTICS_INDEX:
                    self.state.update( # Back-calculating APAR as GPP/(Emult*LUE)
                        &#39;apar&#39;, t, np.divide(gpp,
                            np.multiply(e_mult, self.constants.LUE)))

            # Treat Kmult and Emult differently (i.e., break out the former
            #   but not the latter) because that is what L4C Ops does
            if &#39;e_mult&#39; in self.STATE_INDEX:
                self.state.update(&#39;e_mult&#39;, t, e_mult)
            if &#39;t_mult&#39; in self.STATE_INDEX:
                self.state.update(&#39;t_mult&#39;, t, k_mult[0])
            if &#39;w_mult&#39; in self.STATE_INDEX:
                self.state.update(&#39;w_mult&#39;, t, k_mult[1])
            # Update the SOC state
            for p in range(1, 4):
                if t == 0:
                    # At time t=0, we have no state to advance, so update
                    #   the state at t=0 based on the initial state
                    delta = np.add(self.state_initial[p-1,0,...], d_soc[p-1])
                    self.state.update(
                        &#39;soc%d&#39; % p, t, delta, bounds = (0, np.inf))
                else:
                    self.state.advance(
                        &#39;soc%d&#39; % p, t, d_soc[p-1], bounds = (0, np.inf))

        if fields_gpp is None:
            fields_gpp = [&#39;apar&#39;, &#39;tmin&#39;, &#39;vpd&#39;, &#39;ft&#39;, &#39;smrz&#39;]
        if fields_rh is None:
            fields_rh = [&#39;tsoil&#39;, &#39;smsf&#39;]
        with L4CStreamingInputDataset(
                self.file_path, self.CONSTANTS, self.BOUNDS) as hdf:
            num_steps = self.config[&#39;time_steps&#39;] if steps is None else steps
            with ProgressBar(num_steps, &#39;Running...&#39;) as progress:
                for t in range(self._time_idx + 1, num_steps):
                    step(t, fields_gpp, fields_rh)
                    self._time_idx += 1
                    progress.update(t)</code></pre>
</details>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="pyl4c.apps.l4c.extensions.cosore.L4CPrescribedGPPModel" href="extensions/cosore.html#pyl4c.apps.l4c.extensions.cosore.L4CPrescribedGPPModel">L4CPrescribedGPPModel</a></li>
<li><a title="pyl4c.apps.l4c.extensions.coupling.L4CDAMM" href="extensions/coupling.html#pyl4c.apps.l4c.extensions.coupling.L4CDAMM">L4CDAMM</a></li>
<li><a title="pyl4c.apps.l4c.extensions.hydrology.L4CStratifiedModel" href="extensions/hydrology.html#pyl4c.apps.l4c.extensions.hydrology.L4CStratifiedModel">L4CStratifiedModel</a></li>
<li><a title="pyl4c.apps.l4c.extensions.phenology.L4CPhenologyProcess" href="extensions/phenology.html#pyl4c.apps.l4c.extensions.phenology.L4CPhenologyProcess">L4CPhenologyProcess</a></li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="pyl4c.apps.l4c.main.L4CForwardProcessPoint.BOUNDS"><code class="name">var <span class="ident">BOUNDS</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyl4c.apps.l4c.main.L4CForwardProcessPoint.CONSTANTS"><code class="name">var <span class="ident">CONSTANTS</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyl4c.apps.l4c.main.L4CForwardProcessPoint.CONSTANTS_INDEX"><code class="name">var <span class="ident">CONSTANTS_INDEX</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyl4c.apps.l4c.main.L4CForwardProcessPoint.CONSTRAINTS_INDEX"><code class="name">var <span class="ident">CONSTRAINTS_INDEX</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyl4c.apps.l4c.main.L4CForwardProcessPoint.DAYS_PER_YEAR"><code class="name">var <span class="ident">DAYS_PER_YEAR</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyl4c.apps.l4c.main.L4CForwardProcessPoint.DIAGNOSTICS_INDEX"><code class="name">var <span class="ident">DIAGNOSTICS_INDEX</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyl4c.apps.l4c.main.L4CForwardProcessPoint.DRIVERS_INDEX"><code class="name">var <span class="ident">DRIVERS_INDEX</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyl4c.apps.l4c.main.L4CForwardProcessPoint.FLUX_INDEX"><code class="name">var <span class="ident">FLUX_INDEX</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyl4c.apps.l4c.main.L4CForwardProcessPoint.PFT_CODES"><code class="name">var <span class="ident">PFT_CODES</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyl4c.apps.l4c.main.L4CForwardProcessPoint.REQUIRED_CONFIGURATION"><code class="name">var <span class="ident">REQUIRED_CONFIGURATION</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pyl4c.apps.l4c.main.L4CForwardProcessPoint.STATE_INDEX"><code class="name">var <span class="ident">STATE_INDEX</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Instance variables</h3>
<dl>
<dt id="pyl4c.apps.l4c.main.L4CForwardProcessPoint.config"><code class="name">var <span class="ident">config</span></code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def config(self):
    return self._config</code></pre>
</details>
</dd>
<dt id="pyl4c.apps.l4c.main.L4CForwardProcessPoint.constants"><code class="name">var <span class="ident">constants</span></code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def constants(self):
    return self._constants</code></pre>
</details>
</dd>
<dt id="pyl4c.apps.l4c.main.L4CForwardProcessPoint.drivers"><code class="name">var <span class="ident">drivers</span></code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def drivers(self):
    return self._drivers # NOTE: No setter</code></pre>
</details>
</dd>
<dt id="pyl4c.apps.l4c.main.L4CForwardProcessPoint.fluxes"><code class="name">var <span class="ident">fluxes</span></code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def fluxes(self):
    return self._fluxes</code></pre>
</details>
</dd>
<dt id="pyl4c.apps.l4c.main.L4CForwardProcessPoint.state"><code class="name">var <span class="ident">state</span></code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def state(self):
    return self._state</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pyl4c.apps.l4c.main.L4CForwardProcessPoint.constrain"><code class="name flex">
<span>def <span class="ident">constrain</span></span>(<span>self, x, driver)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns a linear interpolated multiple based on a ramp function.
Equivalent to a vectorized version of:</p>
<pre><code>if x &gt;= xmax:
    return 1
if x &lt;= xmin:
    return 0
return (x - xmin) / (xmax - xmin)
</code></pre>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>float</code></dt>
<dd>Observed value, generally an (N x 81) array or an array with an
(N x 81) or (N x 1) sub-space (e.g., soil moisture values that
are constant over the 1-km grid have no 81 unique values), so they
will be broadcast over the 81-pixel sub-grid when combined with
constraint parameter array</dd>
<dt><strong><code>driver</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of the driver</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>float</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def constrain(self, x, driver):
    &#39;&#39;&#39;
    Returns a linear interpolated multiple based on a ramp function.
    Equivalent to a vectorized version of:

        if x &gt;= xmax:
            return 1
        if x &lt;= xmin:
            return 0
        return (x - xmin) / (xmax - xmin)

    Parameters
    ----------
    x : float
        Observed value, generally an (N x 81) array or an array with an
        (N x 81) or (N x 1) sub-space (e.g., soil moisture values that
        are constant over the 1-km grid have no 81 unique values), so they
        will be broadcast over the 81-pixel sub-grid when combined with
        constraint parameter array
    driver : str
        Name of the driver

    Returns
    -------
    float
    &#39;&#39;&#39;
    if driver == &#39;tsoil&#39;:
        return self._arrhenius(x)

    coefs = self._constraints[driver]
    if driver == &#39;vpd&#39;:
        # VPD mult. declines with increasing VPD, unlike other drivers
        return linear_constraint(coefs[0], coefs[1], form = &#39;reversed&#39;)(x)

    if driver == &#39;ft&#39;:
        # FT has a binary response
        return linear_constraint(coefs[0], coefs[1], form = &#39;binary&#39;)(x)

    return linear_constraint(coefs[0], coefs[1])(x)</code></pre>
</details>
</dd>
<dt id="pyl4c.apps.l4c.main.L4CForwardProcessPoint.gpp"><code class="name flex">
<span>def <span class="ident">gpp</span></span>(<span>self, drivers)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate GPP for a single time step.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>drivers</code></strong> :&ensp;<code>list</code> or <code>tuple</code></dt>
<dd>Nested sequence of (driver: <code>numpy.ndarray</code>, label: <code>str</code>) pairs</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>numpy.ndarray</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def gpp(self, drivers):
    &#39;&#39;&#39;
    Calculate GPP for a single time step.

    Parameters
    ----------
    drivers : list or tuple
        Nested sequence of (driver: `numpy.ndarray`, label: `str`) pairs

    Returns
    -------
    numpy.ndarray
    &#39;&#39;&#39;
    # Extract APAR, translate other drivers into environ. constraints
    apar, f_tmin, f_vpd, f_ft, f_smrz = [
        self.constrain(driver, label) if label != &#39;apar&#39; else driver
        for driver, label in drivers
    ]
    e_mult = f_tmin * f_vpd * f_ft * f_smrz
    if self._debug:
        return (apar * self.constants.LUE * e_mult,
            (f_tmin, f_vpd, f_ft, f_smrz))
    return (apar * self.constants.LUE * e_mult, e_mult)</code></pre>
</details>
</dd>
<dt id="pyl4c.apps.l4c.main.L4CForwardProcessPoint.rh"><code class="name flex">
<span>def <span class="ident">rh</span></span>(<span>self, state, drivers)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate RH for a single time step.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>state</code></strong> :&ensp;<code>numpy.ndarray</code></dt>
<dd><code>(3 x N x M)</code> array of current SOC state in each pool</dd>
<dt><strong><code>drivers</code></strong> :&ensp;<code>list</code> or <code>tuple</code></dt>
<dd>Nested sequence of (driver: <code>numpy.ndarray</code>, label: <code>str</code>) pairs</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>numpy.ndarray</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def rh(self, state, drivers):
    &#39;&#39;&#39;
    Calculate RH for a single time step.

    Parameters
    ----------
    state : numpy.ndarray
        `(3 x N x M)` array of current SOC state in each pool
    drivers : list or tuple
        Nested sequence of (driver: `numpy.ndarray`, label: `str`) pairs

    Returns
    -------
    numpy.ndarray
    &#39;&#39;&#39;
    # Translate Tsoil and SMSF into environmental constraints on RH
    f_tsoil, f_smsf = [
        self.constrain(driver, label) for driver, label in drivers
    ]
    k_mult = (f_tsoil * f_smsf)[np.newaxis,...].repeat(3, axis = 0)
    # NOTE: These are true decay rates for 2nd and 3rd pools, so it
    #   is straightfoward to multiply them against SOC
    rh = k_mult * self.constants.decay_rates * state
    # &#34;the adjustment...to account for material transferred into the
    #   slow pool during humification&#34; (Jones et al. 2017 TGARS, p.5)
    rh[1,...] = rh[1,...] * (1 - self.constants.f_structural)
    # T_mult, W_mult same for each pool
    return (rh, (f_tsoil, f_smsf))</code></pre>
</details>
</dd>
<dt id="pyl4c.apps.l4c.main.L4CForwardProcessPoint.run"><code class="name flex">
<span>def <span class="ident">run</span></span>(<span>self, steps=None, fields_gpp=None, fields_rh=None)</span>
</code></dt>
<dd>
<div class="desc"><p>A forward run in serial over multiple time steps; currently works in
streaming mode ONLY.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>steps</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of time steps to run or None to run through the end of the
available time steps (exhaust driver data) (Default: <code>None</code>)</dd>
<dt><strong><code>fields_gpp</code></strong> :&ensp;<code>list</code> or <code>tuple</code> or <code>None</code></dt>
<dd>(Optional) Sequence of field names that are used to drive the
GPP model</dd>
<dt><strong><code>fields_rh</code></strong> :&ensp;<code>list</code> or <code>tuple</code> or <code>None</code></dt>
<dd>(Optional) Sequence of field names that are used to drive the
RH model</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def run(self, steps = None, fields_gpp = None, fields_rh = None):
    &#39;&#39;&#39;
    A forward run in serial over multiple time steps; currently works in
    streaming mode ONLY.

    Parameters
    ----------
    steps : int
        Number of time steps to run or None to run through the end of the
        available time steps (exhaust driver data) (Default: `None`)
    fields_gpp : list or tuple or None
        (Optional) Sequence of field names that are used to drive the
        GPP model
    fields_rh : list or tuple or None
        (Optional) Sequence of field names that are used to drive the
        RH model
    &#39;&#39;&#39;
    @suppress_warnings
    def step(t, fields_gpp, fields_rh):
        &#39;Calculate fluxes, new states for the next time step t&#39;
        if t == 0:
            # Retrieve intial SOC pool sizes
            state = self.state_initial[0:3,0,...]
        else:
            # Retrieve SOC in each pool from prior step
            state = self.state.data[0:3,t-1,...]
        # Calculate fluxes, new states
        gpp, e_mult = self.gpp(
            zip(hdf.index(t + self._t0, *fields_gpp), fields_gpp))
        rh, k_mult = self.rh(
            state, zip(hdf.index(t + self._t0, *fields_rh), fields_rh))
        npp = gpp * self.constants.CUE
        d_soc = self.soc(rh, t + self._t0)
        # Record fluxes for this time step
        self.fluxes.update(&#39;gpp&#39;, t, gpp)
        self.fluxes.update(&#39;rh&#39;, t, rh.sum(axis = 0))
        self.fluxes.update(&#39;nee&#39;, t, rh.sum(axis = 0) - npp)
        # Record diagnostics at this time step
        if self._debug:
            # In debug mode, e_mult is not a single quantity but multiple;
            #   the order of e_mult_fields MUST match the order of the
            #   return signature for gpp()
            e_mult_fields = (&#39;f_tmin&#39;, &#39;f_vpd&#39;, &#39;f_ft&#39;, &#39;f_smrz&#39;)
            if all(f in self.DIAGNOSTICS_INDEX for f in e_mult_fields):
                for e, key in enumerate(self.DIAGNOSTICS_INDEX):
                    if key in e_mult_fields:
                        idx = e_mult_fields.index(key)
                        self.state.update(key, t, e_mult[idx])
            # In debug mode, k_mult is not a single quantity but multiple;
            #   the order of k_mult_fields MUST match the order of the
            #   return signature for rh()
            k_mult_fields = (&#39;f_tsoil&#39;, &#39;f_smsf&#39;)
            if all(f in self.DIAGNOSTICS_INDEX for f in k_mult_fields):
                for k, key in enumerate(self.DIAGNOSTICS_INDEX):
                    if key in k_mult_fields:
                        idx = k_mult_fields.index(key)
                        self.state.update(key, t, k_mult[idx])
            # IMPORTANT: Put e_mult back together again
            e_mult = e_mult[0] * e_mult[1] * e_mult[2] * e_mult[3]
            if &#39;apar&#39; in self.DIAGNOSTICS_INDEX:
                self.state.update( # Back-calculating APAR as GPP/(Emult*LUE)
                    &#39;apar&#39;, t, np.divide(gpp,
                        np.multiply(e_mult, self.constants.LUE)))

        # Treat Kmult and Emult differently (i.e., break out the former
        #   but not the latter) because that is what L4C Ops does
        if &#39;e_mult&#39; in self.STATE_INDEX:
            self.state.update(&#39;e_mult&#39;, t, e_mult)
        if &#39;t_mult&#39; in self.STATE_INDEX:
            self.state.update(&#39;t_mult&#39;, t, k_mult[0])
        if &#39;w_mult&#39; in self.STATE_INDEX:
            self.state.update(&#39;w_mult&#39;, t, k_mult[1])
        # Update the SOC state
        for p in range(1, 4):
            if t == 0:
                # At time t=0, we have no state to advance, so update
                #   the state at t=0 based on the initial state
                delta = np.add(self.state_initial[p-1,0,...], d_soc[p-1])
                self.state.update(
                    &#39;soc%d&#39; % p, t, delta, bounds = (0, np.inf))
            else:
                self.state.advance(
                    &#39;soc%d&#39; % p, t, d_soc[p-1], bounds = (0, np.inf))

    if fields_gpp is None:
        fields_gpp = [&#39;apar&#39;, &#39;tmin&#39;, &#39;vpd&#39;, &#39;ft&#39;, &#39;smrz&#39;]
    if fields_rh is None:
        fields_rh = [&#39;tsoil&#39;, &#39;smsf&#39;]
    with L4CStreamingInputDataset(
            self.file_path, self.CONSTANTS, self.BOUNDS) as hdf:
        num_steps = self.config[&#39;time_steps&#39;] if steps is None else steps
        with ProgressBar(num_steps, &#39;Running...&#39;) as progress:
            for t in range(self._time_idx + 1, num_steps):
                step(t, fields_gpp, fields_rh)
                self._time_idx += 1
                progress.update(t)</code></pre>
</details>
</dd>
<dt id="pyl4c.apps.l4c.main.L4CForwardProcessPoint.soc"><code class="name flex">
<span>def <span class="ident">soc</span></span>(<span>self, rh, t=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate change in SOC for a single time step.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>rh</code></strong> :&ensp;<code>numpy.ndarray</code></dt>
<dd><code>(3 x N x M)</code> array of RH at the current time step</dd>
<dt><strong><code>t</code></strong> :&ensp;<code>int</code></dt>
<dd>Current time step; useful in subclasses but not used in the
operational L4C algorithm (not used here)</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>numpy.ndarray</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def soc(self, rh, t = None):
    &#39;&#39;&#39;
    Calculate change in SOC for a single time step.

    Parameters
    ----------
    rh : numpy.ndarray
        `(3 x N x M)` array of RH at the current time step
    t : int
        Current time step; useful in subclasses but not used in the
        operational L4C algorithm (not used here)

    Returns
    -------
    numpy.ndarray
    &#39;&#39;&#39;
    # Change in SOC according to diff. eq. in Jones et al. (2017)
    litter = self.constants.litterfall
    dc1 = (litter * self.constants.f_metabolic) - rh[0,...]
    dc2 = (litter * (1 - self.constants.f_metabolic)) - rh[1,...]
    dc3 = (self.constants.f_structural * rh[1,...]) - rh[2,...]
    return (dc1, dc2, dc3)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="pyl4c.apps.l4c" href="index.html">pyl4c.apps.l4c</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="pyl4c.apps.l4c.main.L4CForwardProcessPoint" href="#pyl4c.apps.l4c.main.L4CForwardProcessPoint">L4CForwardProcessPoint</a></code></h4>
<ul class="">
<li><code><a title="pyl4c.apps.l4c.main.L4CForwardProcessPoint.BOUNDS" href="#pyl4c.apps.l4c.main.L4CForwardProcessPoint.BOUNDS">BOUNDS</a></code></li>
<li><code><a title="pyl4c.apps.l4c.main.L4CForwardProcessPoint.CONSTANTS" href="#pyl4c.apps.l4c.main.L4CForwardProcessPoint.CONSTANTS">CONSTANTS</a></code></li>
<li><code><a title="pyl4c.apps.l4c.main.L4CForwardProcessPoint.CONSTANTS_INDEX" href="#pyl4c.apps.l4c.main.L4CForwardProcessPoint.CONSTANTS_INDEX">CONSTANTS_INDEX</a></code></li>
<li><code><a title="pyl4c.apps.l4c.main.L4CForwardProcessPoint.CONSTRAINTS_INDEX" href="#pyl4c.apps.l4c.main.L4CForwardProcessPoint.CONSTRAINTS_INDEX">CONSTRAINTS_INDEX</a></code></li>
<li><code><a title="pyl4c.apps.l4c.main.L4CForwardProcessPoint.DAYS_PER_YEAR" href="#pyl4c.apps.l4c.main.L4CForwardProcessPoint.DAYS_PER_YEAR">DAYS_PER_YEAR</a></code></li>
<li><code><a title="pyl4c.apps.l4c.main.L4CForwardProcessPoint.DIAGNOSTICS_INDEX" href="#pyl4c.apps.l4c.main.L4CForwardProcessPoint.DIAGNOSTICS_INDEX">DIAGNOSTICS_INDEX</a></code></li>
<li><code><a title="pyl4c.apps.l4c.main.L4CForwardProcessPoint.DRIVERS_INDEX" href="#pyl4c.apps.l4c.main.L4CForwardProcessPoint.DRIVERS_INDEX">DRIVERS_INDEX</a></code></li>
<li><code><a title="pyl4c.apps.l4c.main.L4CForwardProcessPoint.FLUX_INDEX" href="#pyl4c.apps.l4c.main.L4CForwardProcessPoint.FLUX_INDEX">FLUX_INDEX</a></code></li>
<li><code><a title="pyl4c.apps.l4c.main.L4CForwardProcessPoint.PFT_CODES" href="#pyl4c.apps.l4c.main.L4CForwardProcessPoint.PFT_CODES">PFT_CODES</a></code></li>
<li><code><a title="pyl4c.apps.l4c.main.L4CForwardProcessPoint.REQUIRED_CONFIGURATION" href="#pyl4c.apps.l4c.main.L4CForwardProcessPoint.REQUIRED_CONFIGURATION">REQUIRED_CONFIGURATION</a></code></li>
<li><code><a title="pyl4c.apps.l4c.main.L4CForwardProcessPoint.STATE_INDEX" href="#pyl4c.apps.l4c.main.L4CForwardProcessPoint.STATE_INDEX">STATE_INDEX</a></code></li>
<li><code><a title="pyl4c.apps.l4c.main.L4CForwardProcessPoint.config" href="#pyl4c.apps.l4c.main.L4CForwardProcessPoint.config">config</a></code></li>
<li><code><a title="pyl4c.apps.l4c.main.L4CForwardProcessPoint.constants" href="#pyl4c.apps.l4c.main.L4CForwardProcessPoint.constants">constants</a></code></li>
<li><code><a title="pyl4c.apps.l4c.main.L4CForwardProcessPoint.constrain" href="#pyl4c.apps.l4c.main.L4CForwardProcessPoint.constrain">constrain</a></code></li>
<li><code><a title="pyl4c.apps.l4c.main.L4CForwardProcessPoint.drivers" href="#pyl4c.apps.l4c.main.L4CForwardProcessPoint.drivers">drivers</a></code></li>
<li><code><a title="pyl4c.apps.l4c.main.L4CForwardProcessPoint.fluxes" href="#pyl4c.apps.l4c.main.L4CForwardProcessPoint.fluxes">fluxes</a></code></li>
<li><code><a title="pyl4c.apps.l4c.main.L4CForwardProcessPoint.gpp" href="#pyl4c.apps.l4c.main.L4CForwardProcessPoint.gpp">gpp</a></code></li>
<li><code><a title="pyl4c.apps.l4c.main.L4CForwardProcessPoint.rh" href="#pyl4c.apps.l4c.main.L4CForwardProcessPoint.rh">rh</a></code></li>
<li><code><a title="pyl4c.apps.l4c.main.L4CForwardProcessPoint.run" href="#pyl4c.apps.l4c.main.L4CForwardProcessPoint.run">run</a></code></li>
<li><code><a title="pyl4c.apps.l4c.main.L4CForwardProcessPoint.soc" href="#pyl4c.apps.l4c.main.L4CForwardProcessPoint.soc">soc</a></code></li>
<li><code><a title="pyl4c.apps.l4c.main.L4CForwardProcessPoint.state" href="#pyl4c.apps.l4c.main.L4CForwardProcessPoint.state">state</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>