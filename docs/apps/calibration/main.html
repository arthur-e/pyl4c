<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>pyl4c.apps.calibration.main API documentation</title>
<meta name="description" content="Calibration procedure for SMAP Level-4 Carbon (L4C). For a list of all
commands, type: â€¦" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
<style>.homelink{display:block;font-size:2em;font-weight:bold;color:#555;padding-bottom:.5em;border-bottom:1px solid silver}.homelink:hover{color:inherit}.homelink img{max-width:35%;max-height:5em;margin:auto;margin-bottom:.3em}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>pyl4c.apps.calibration.main</code></h1>
</header>
<section id="section-intro">
<p>Calibration procedure for SMAP Level-4 Carbon (L4C). For a list of all
commands, type:</p>
<pre><code>python main.py
</code></pre>
<p><strong>You must create a configuration JSON file before calibrating L4C.</strong> This
file tells the calibration tool where on your file system the data files
are located. There is a template available in the directory:</p>
<pre><code>pyl4c/data/fixtures/files
</code></pre>
<p>The scratch data must be set-up before doing anything else:</p>
<pre><code>python main.py setup
</code></pre>
<p>Some commands can be chained together, for example, setting the PFT class to
calibrate is REQUIRED before most other commands; it can be set in one of
two ways:</p>
<pre><code>python main.py --pft=&lt;pft&gt; &lt;command&gt;
python main.py pft &lt;pft&gt; &lt;command&gt;
</code></pre>
<p>Generally, the workflow for calibrating a single PFT is as follows:</p>
<pre><code>python main.py setup
python main.py pft &lt;pft&gt; filter-preview gpp &lt;window_size&gt;
python main.py pft &lt;pft&gt; filter         gpp &lt;window_size&gt;
python main.py pft &lt;pft&gt; plot-gpp &lt;driver&gt;
python main.py pft &lt;pft&gt; tune-gpp
python main.py pft &lt;pft&gt; filter-preview reco &lt;window_size&gt;
python main.py pft &lt;pft&gt; filter         reco &lt;window_size&gt;
python main.py pft &lt;pft&gt; plot-reco &lt;driver&gt;
python main.py pft &lt;pft&gt; tune-reco
</code></pre>
<p>Can optionally filter flux tower data for all PFTs:</p>
<pre><code>python main.py setup --reset
python main.py filter-all gpp &lt;window_size&gt;
python main.py filter-all reco &lt;window_size&gt;
</code></pre>
<p><strong>See the docstring on the CLI in this module for more information.</strong></p>
<p>Possible improvements:</p>
<ul>
<li>Replace parameter vectors with a
<code><a title="pyl4c.apps.calibration.ModelParameters" href="index.html#pyl4c.apps.calibration.ModelParameters">ModelParameters</a></code> instance.</li>
<li>Tower HDF5 file has upper-case field names (e.g., "APAR") while
driver HDF5 file has lower-case field names (e.g., "par")</li>
</ul>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#39;&#39;&#39;
Calibration procedure for SMAP Level-4 Carbon (L4C). For a list of all
commands, type:

    python main.py

**You must create a configuration JSON file before calibrating L4C.** This
file tells the calibration tool where on your file system the data files
are located. There is a template available in the directory:

    pyl4c/data/fixtures/files

The scratch data must be set-up before doing anything else:

    python main.py setup

Some commands can be chained together, for example, setting the PFT class to
calibrate is REQUIRED before most other commands; it can be set in one of
two ways:

    python main.py --pft=&lt;pft&gt; &lt;command&gt;
    python main.py pft &lt;pft&gt; &lt;command&gt;

Generally, the workflow for calibrating a single PFT is as follows:

    python main.py setup
    python main.py pft &lt;pft&gt; filter-preview gpp &lt;window_size&gt;
    python main.py pft &lt;pft&gt; filter         gpp &lt;window_size&gt;
    python main.py pft &lt;pft&gt; plot-gpp &lt;driver&gt;
    python main.py pft &lt;pft&gt; tune-gpp
    python main.py pft &lt;pft&gt; filter-preview reco &lt;window_size&gt;
    python main.py pft &lt;pft&gt; filter         reco &lt;window_size&gt;
    python main.py pft &lt;pft&gt; plot-reco &lt;driver&gt;
    python main.py pft &lt;pft&gt; tune-reco

Can optionally filter flux tower data for all PFTs:

    python main.py setup --reset
    python main.py filter-all gpp &lt;window_size&gt;
    python main.py filter-all reco &lt;window_size&gt;

**See the docstring on the CLI in this module for more information.**

Possible improvements:

- Replace parameter vectors with a
    `pyl4c.apps.calibration.ModelParameters` instance.
- Tower HDF5 file has upper-case field names (e.g., &#34;APAR&#34;) while
    driver HDF5 file has lower-case field names (e.g., &#34;par&#34;)
&#39;&#39;&#39;

import csv
import datetime
import itertools
import json
import os
import pickle
import h5py
import numpy as np
import pyl4c
from collections import Counter
from functools import partial
from scipy import signal
from matplotlib import pyplot
from pyl4c import pft_selector, suppress_warnings
from pyl4c.data.fixtures import PFT, restore_bplut
from pyl4c.science import arrhenius, climatology365
from pyl4c.stats import linear_constraint, detrend, rmsd
from pyl4c.lib.cli import ProgressBar
from pyl4c.apps.calibration import BPLUT, OPT_BOUNDS, GenericOptimization, cbar, report_fit_stats, solve_least_squares

CONFIG = os.path.join(os.path.dirname(pyl4c.__file__), &#39;data/files/config_calibration.json&#39;)

class CLI(object):
    &#39;&#39;&#39;
    Command line interface for calibrating L4C.

    To plot the response function of, e.g., Tmin, with (optional) suggested
    parameters (lower, upper bounds):

        python main.py pft &lt;pft&gt; plot-gpp &lt;driver&gt; [xmin, xmax]

    To optimize all of the GPP parameters:

        python main.py pft &lt;pft&gt; tune-gpp

    To optimize some of the GPP parameters, keeping named parameters fixed:

        python main.py pft &lt;pft&gt; tune-gpp --fixed=&#34;(LUE,ft0)&#34;

    To optimize GPP with the best match for previous calibrations:

        python main.py pft &lt;pft&gt; tune-gpp --end=&#34;2014-12-31&#34;

    To optimize GPP, first setting the initial value of a parameter:

        python main.py pft &lt;pft&gt; set &lt;param&gt; &lt;value&gt; tune-gpp

    Parameters
    ----------
    config : str
        Path to a configuration JSON file, which describes the file paths
        for calibration datasets
    pft : int
        The numeric code of the PFT to calibrate
    start : int
        (Optional) The numeric index making the start of a time series subset
        to use; if not provided, entire time series (in dataset) is used
    end : int
        (Optional) The numeric index making the end of a time series subset
        to use; if not provided, entire time series (in dataset) is used
    debug : bool
    use_legacy_pft : bool
        (Optional) True to use the L4C Nature Run v7.2 &#34;legacy&#34; PFT map
        (&#34;lc_dom&#34;) for the PFT class assignments of each pixel (Default: True)
    &#39;&#39;&#39;
    _driver_bounds = {&#39;apar&#39;: (2, np.inf)}
    _metadata = {
        &#39;tmin&#39;: {&#39;units&#39;: &#39;deg K&#39;},
        &#39;vpd&#39;: {&#39;units&#39;: &#39;Pa&#39;},
        &#39;smrz&#39;: {&#39;units&#39;: &#39;%&#39;},
        &#39;smsf&#39;: {&#39;units&#39;: &#39;%&#39;},
        &#39;tsoil&#39;: {&#39;units&#39;: &#39;deg K&#39;},
    }
    _parameters = {
        &#39;gpp&#39;: (
            &#39;LUE&#39;, &#39;tmin0&#39;, &#39;tmin1&#39;, &#39;vpd0&#39;, &#39;vpd1&#39;, &#39;smrz0&#39;, &#39;smrz1&#39;, &#39;ft0&#39;
        ),
        &#39;reco&#39;: (
            &#39;CUE&#39;, &#39;tsoil&#39;, &#39;smsf0&#39;, &#39;smsf1&#39;
        )
    }
    _required_drivers = [
        &#39;fpar&#39;, &#39;par&#39;, &#39;smrz&#39;, &#39;smsf&#39;, &#39;tsoil&#39;, &#39;tmin&#39;, &#39;vpd&#39;, &#39;tsurf&#39;
    ]

    def __init__(
            self, config = CONFIG, pft = None, start = None, end = None,
            debug = True, use_legacy_pft = True):
        self._debug = debug
        self._nsites = 0
        self._nsteps = 0
        self._pft = pft
        self._pft_map = None
        self._site_weights = None
        self._time_end = None
        self._time_start = None
        self._use_legacy_pft = use_legacy_pft

        # Read in configuration file to determine file paths
        with open(config, &#39;r&#39;) as file:
            config_data = json.load(file)
        self._path_to_bplut = config_data[&#39;BPLUT_file&#39;]
        self._path_to_drivers = config_data[&#39;drivers_file&#39;]
        self._path_to_scratch = config_data[&#39;scratch_file&#39;]
        self._path_to_towers = config_data[&#39;towers_file&#39;]
        self._check() # Check for required keys in driver data

        # Allow users to specify start and end dates for the time series
        if start is not None or end is not None:
            with h5py.File(self._path_to_drivers, &#39;r&#39;) as hdf:
                time_series = [
                    datetime.datetime(y, m, d).strftime(&#39;%Y-%m-%d&#39;)
                    for y, m, d, _ in hdf[&#39;time&#39;][:].tolist()
                ]
            if start is not None:
                self._time_start = time_series.index(start)
            if end is not None:
                self._time_end = time_series.index(end)

        # Creates the BPLUT store
        self._init_bplut()

        # Read in PFT map
        with h5py.File(self._path_to_drivers, &#39;r&#39;) as hdf:
            self._nsites = hdf[&#39;state/PFT&#39;].shape[0]
            self._nsteps = hdf[&#39;time&#39;].shape[0]
            if self._use_legacy_pft:
                self._pft_map = hdf[&#39;legacy/lc_dom&#39;][:].swapaxes(0, 1)
            else:
                self._pft_map = hdf[&#39;state/PFT&#39;][:]

    @property
    def _is_setup(self):
        return os.path.exists(self._path_to_scratch)

    def _bounds(self, init_params, group, fixed = None, bounds = OPT_BOUNDS):
        &#39;Defines bounds; optionally &#34;fixes&#34; parameters by fixing bounds&#39;
        params = init_params
        if fixed is not None:
            params = [ # If the given parameter is in &#34;fixed&#34;, restrict bounds
                None if self._parameters[group][i] in fixed else init_params[i]
                for i in range(0, len(self._parameters[group]))
            ]
        lower = []
        upper = []
        for i, p in enumerate(params):
            # This is a parameter to be optimized; use default bounds
            if p is not None:
                lower.append(bounds[group][0][i])
                upper.append(bounds[group][1][i])
            else:
                lower.append(init_params[i] - 1e-3)
                upper.append(init_params[i] + 1e-3)
        return (np.array(lower), np.array(upper))

    def _check(self):
        &#39;Checks for all the required keys in the driver dataset&#39;
        msg = &#39;Missing required driver: %s&#39;
        with h5py.File(self._path_to_drivers, &#39;r&#39;) as hdf:
            for key in self._required_drivers:
                assert key in hdf[&#39;drivers&#39;].keys(), msg % key
            assert hdf[&#39;drivers/smsf&#39;][:].max() &gt; 1,\
                &#39;SMSF data may not be in percent saturation units!&#39;
            assert hdf[&#39;drivers/smrz&#39;][:].max() &gt; 1,\
                &#39;SMRZ data may not be in percent saturation units!&#39;

    @suppress_warnings
    def _climatology(self):
        &#39;Computes a 365-day climatology for each driver&#39;
        with h5py.File(self._path_to_drivers, &#39;r&#39;) as hdf:
            time_series = [
                datetime.datetime(y, m, d)
                for y, m, d, _ in hdf[&#39;time&#39;][:].tolist()
            ]
            with h5py.File(self._path_to_scratch, &#39;a&#39;) as target_hdf:
                for key in self._required_drivers:
                    if &#39;climatologies&#39; in target_hdf.keys():
                        if key in target_hdf[&#39;climatologies&#39;].keys():
                            continue # Skip to next

                    if self._debug:
                        print(&#39;Calculating %s climatology...&#39; % key)
                    shp = (365, *hdf[&#39;drivers/%s&#39; % key].shape[1:])
                    target_hdf.create_dataset(
                        &#39;climatologies/%s&#39; % key, shp,
                        dtype = hdf[&#39;drivers/%s&#39; % key].dtype,
                        data = climatology365(
                            hdf[&#39;drivers/%s&#39; % key][:], time_series))

    def _constrain(self, x, driver, coefs = None):
        &#39;Converts a driver x into a multiple on [0, 1].&#39;
        if driver == &#39;tsoil&#39;:
            return arrhenius(x, self.bplut[&#39;tsoil&#39;][0,self._pft])
        # User can provide an M-element array-like
        if coefs is None:
            coefs = self.bplut[driver][:,self._pft].tolist()
        constraint = linear_constraint(coefs[0], coefs[1])
        if driver == &#39;vpd&#39;:
            # VPD mult. declines with increasing VPD, unlike other drivers
            constraint = linear_constraint(coefs[0], coefs[1], &#39;reversed&#39;)
        elif driver == &#39;ft&#39;:
            # FT has a binary response
            constraint = linear_constraint(coefs[0], coefs[1], &#39;binary&#39;)
        return constraint(x)

    def _filter(self, raw, size):
        &#39;Apply a smoothing filter with zero phase offset&#39;
        if size &gt; 1:
            window = np.ones(size) / size
            return np.apply_along_axis(
                lambda x: signal.filtfilt(window, np.ones(1), x), 0, raw)
        else:
            return raw # Or, revert to the raw data

    def _init_bplut(self, labels = None):
        # Create the output BPLUT store; if there&#39;s already a BPLUT table
        #   in the scratch, it will be combined with the initial BPLUT,
        #   overwriting INTITIAL_BPLUT values in favor of the file BPLUT
        self.bplut = BPLUT(
            restore_bplut(self._path_to_bplut), labels = labels,
            hdf5_path = self._path_to_scratch)

    def _ramp(self, x, driver, step = 0.1, coefs = None):
        &#39;Returns a ramp function over the domain of x; returns (domain, ramp)&#39;
        domain = np.arange(np.nanmin(x), np.nanmax(x), step)
        ramp = self._constrain(domain, driver, coefs)
        return (domain, ramp)

    def _report(self, old_params, new_params, labels, title, prec = 2):
        &#39;Prints a report on the updated (optimized) parameters&#39;
        pad = max(len(l) for l in labels) + 1
        fmt_string = &#39;-- {:&lt;%d} {:&gt;%d} [{:&gt;%d}]&#39; % (pad, 5 + prec, 7 + prec)
        print(&#39;%s parameters report, %s (PFT %d):&#39; % (
            title, PFT[self._pft][0], self._pft))
        print((&#39; {:&gt;%d} {:&gt;%d}&#39; % (8 + pad + prec, 8 + prec))\
            .format(&#39;NEW&#39;, &#39;INITIAL&#39;))
        for i, label in enumerate(labels):
            new = (&#39;%%.%df&#39; % prec) % new_params[i] if new_params[i] is not None else &#39;&#39;
            old = (&#39;%%.%df&#39; % prec) % old_params[i]
            print(fmt_string.format((&#39;%s:&#39; % label), new, old))

    @suppress_warnings
    def _report_fit(self, obs, pred, weights, verbose = True):
        &#39;Reports RMSE and unbiased RMSE&#39;
        return report_fit_stats(obs, pred, weights, verbose = verbose)

    @property
    def _sites(self):
        &#39;&#39;&#39;
        For a given PFT class, returns the tower sites, as rank indices, that
        represent that PFT. Exceptions are made according to the L4C
        calibration protocol, e.g., sites with any amount of
        Deciduous Needleleaf (DNF) in their 1-km subgrid are considered to
        represent the DNF PFT class.
        &#39;&#39;&#39;
        return pft_selector(self._pft_map, self._pft)

    def pft(self, pft):
        &#39;&#39;&#39;
        Sets the PFT class for the next calibration step.

        Parameters
        ----------
        pft : int
            The PFT class to use in calibration

        Returns
        -------
        CLI
        &#39;&#39;&#39;
        assert pft in range(1, 9), &#39;Unrecognized PFT class&#39;
        self._pft = pft
        return self

    def filter(self, flux, size = 2):
        &#39;&#39;&#39;
        Filters the tower GPP or RECO flux data. Each time it is called, the
        raw (noisy) tower data is filtered; successive calls with the same
        arguments will only overwrite the filtered tower data.

        Parameters
        ----------
        flux : str
            &#34;gpp&#34; or &#34;reco&#34; for the corresponding tower dataset
        size : int
            Filter window size, in days
        &#39;&#39;&#39;
        assert any(self._sites), &#39;You must select a PFT class&#39;
        with h5py.File(self._path_to_scratch, &#39;a&#39;) as hdf:
            assert flux.upper() in hdf[&#39;tower&#39;].keys(),\
                &#39;Field &#34;tower/%s&#34; not found&#39; % flux.upper()
            # Tower fluxes are duplicated on the last axis, so pick one
            raw = hdf[&#39;tower/%s&#39; % flux.upper()][:,self._sites,0]
            filtered = self._filter(raw, size)
            # Re-duplicate the 1-km subgrid on the last axis
            filtered = filtered[...,np.newaxis].repeat(81, axis = 2)
            hdf[&#39;tower/%s&#39; % flux.upper()][:,self._sites,:] = filtered

    def filter_all(self, flux, size = 2):
        &#39;&#39;&#39;
        Filters the tower GPP or RECO flux data for ALL PFT classes.
        See also: filter().

        Parameters
        ----------
        flux : str
            &#34;gpp&#34; or &#34;reco&#34; for the corresponding tower dataset
        size : int
            Filter window size, in days
        &#39;&#39;&#39;
        with h5py.File(self._path_to_scratch, &#39;a&#39;) as hdf:
            assert flux.upper() in hdf[&#39;tower&#39;].keys(),\
                &#39;Field &#34;tower/%s&#34; not found&#39; % flux.upper()
            # Tower fluxes are duplicated on the last axis, so pick one
            filtered = self._filter(
                hdf[&#39;tower/%s&#39; % flux.upper()][...,0], size)
            # Re-duplicate the 1-km subgrid on the last axis
            filtered = filtered[...,np.newaxis].repeat(81, axis = 2)
            hdf[&#39;tower/%s&#39; % flux.upper()][:] = filtered

    def filter_preview(self, flux, size = 2, seed = 9):
        &#39;&#39;&#39;
        Previews a filter for the tower GPP or RECO data.

        Parameters
        flux : str
            &#34;gpp&#34; or &#34;reco&#34; for the corresponding tower dataset
        size : int
            Filter window size, in days
        seed : int
            Random seed; change to select a different tower site
        &#39;&#39;&#39;
        assert self._sites.any(), &#39;You must select a PFT class&#39;
        with h5py.File(self._path_to_scratch, &#39;r&#39;) as hdf:
            assert flux.upper() in hdf[&#39;tower&#39;].keys(),\
                &#39;Field &#34;%s&#34; not found&#39; % flux.upper()
            x = hdf[&#39;tower/%s&#39; % flux.upper()][:]

        # Get a random tower site matching the current PFT class
        np.random.seed(seed)
        idx = np.random.choice(np.argwhere(self._sites).flatten(), 1)[0]
        x0 = x[:,idx,0]
        x_filt = self._filter(x0, size)
        pyplot.plot(x0, c = &#39;lightsteelblue&#39;)
        pyplot.plot(x_filt, c = &#39;darkorange&#39;)
        pyplot.ylabel(&#39;Tower %s (g C m-2 day-1)&#39; % flux.upper())
        pyplot.title(&#39;Window Size = %d days&#39; % size)
        pyplot.show()

    def plot_gpp(
            self, driver, coefs = None, xlim = None, ylim = None, alpha = 0.1,
            marker = &#39;.&#39;):
        &#39;&#39;&#39;
        Using the current or optimized BPLUT coefficients, plots the GPP ramp
        function for a given driver. NOTE: Values where APAR &lt; 2.0 are not
        shown.

        Parameters
        ----------
        driver : str
            Name of the driver to plot on the horizontal axis
        coefs : list or tuple or numpy.ndarray
            (Optional) array-like, Instead of using what&#39;s in the BPLUT,
            specify the exact parameters, e.g., [tmin0, tmin1]
        xlim : list or tuple
            (Optional) A 2-element sequence: The x-axis limits
        ylim : list or tuple
            (Optional) A 2-element sequence: The x-axis limits
        alpha : float
            (Optional) The alpha value (Default: 0.1)
        marker : str
            (Optional) The marker symbol (Default: &#34;.&#34;)
        &#39;&#39;&#39;
        @suppress_warnings
        def empirical_lue(apar, gpp):
            # Mask low APAR values
            lower, _ = self._driver_bounds.get(&#39;apar&#39;, (0, None))
            apar = np.where(apar &lt; lower, np.nan, apar)
            # Calculate empirical light-use efficiency: GPP/APAR
            return np.where(apar &gt; 0, np.divide(gpp, apar), 0)

        assert self._is_setup, &#39;Must run setup first&#39;
        np.seterr(invalid = &#39;ignore&#39;)
        # Read in GPP and APAR data
        if coefs is not None:
            assert hasattr(coefs, &#39;index&#39;) and not hasattr(coefs, &#39;title&#39;),\
                &#34;Argument --coefs expects a list [values,] with NO spaces&#34;
        assert driver in (&#39;tmin&#39;, &#39;vpd&#39;, &#39;smrz&#39;),\
            &#39;Requested driver &#34;%s&#34; cannot be plotted for GPP&#39; % driver
        with h5py.File(self._path_to_scratch, &#39;r&#39;) as hdf:
            gpp = hdf[&#39;tower/GPP&#39;][:,self._sites,:].mean(axis = 2)
            apar = hdf[&#39;APAR&#39;][:,self._sites,:].mean(axis = 2)

        with h5py.File(self._path_to_drivers, &#39;r&#39;) as hdf:
            # Get the user-specified driver data
            x = hdf[&#39;drivers/%s&#39; % driver][:,self._sites]

        # Update plotting parameters
        lue = empirical_lue(apar, gpp)
        # Mask out negative LUE values and values with APAR&lt;2
        pyplot.scatter(x, np.where(
            np.logical_or(lue == 0, apar &lt; 2), np.nan, lue),
            alpha = alpha, marker = marker)
        a, b = self._ramp(x, driver)
        pyplot.plot(a, b * self.bplut[&#39;LUE&#39;][:,self._pft], &#39;k-&#39;)
        if coefs is not None:
            pyplot.plot(*self._ramp(x, driver, coefs = coefs), &#39;r-&#39;)
        pyplot.xlabel(&#39;%s (%s)&#39; % (driver, self._metadata[driver][&#39;units&#39;]))
        pyplot.ylabel(&#39;GPP/APAR (g C MJ-1 d-1)&#39;)
        if xlim is not None:
            pyplot.xlim(xlim[0], xlim[1])
        if ylim is not None:
            pyplot.ylim(ylim[0], ylim[1])
        pyplot.title(
            &#39;%s (PFT %d): GPP Response to &#34;%s&#34;&#39; % (
                PFT[self._pft][0], self._pft, driver))
        pyplot.show()

    def plot_reco(
            self, driver, coefs = None, q_rh = 75, q_k = 50, xlim = None,
            ylim = None, alpha = 0.1, marker = &#39;.&#39;):
        &#39;&#39;&#39;
        Using the current or optimized BPLUT coefficients, plots the RECO ramp
        function for a given driver. The ramp function is shown on a plot of
        RH/Cbar, which is equivalent to Kmult (as Cbar is an upper quantile of
        the RH/Kmult distribution).

        Parameters
        ----------
        driver : str
            Name of the driver to plot on the horizontal axis
        coefs : list or tuple or numpy.ndarray
            (Optional) array-like, Instead of using what&#39;s in the BPLUT,
            specify the exact parameters, e.g., `[tmin0, tmin1]`
        q_rh : int
            Additional arguments to `pyl4c.apps.calibration.cbar()`
        q_k : int
            Additional arguments to `pyl4c.apps.calibration.cbar()`
        ylim : list or tuple
            (Optional) A 2-element sequence: The x-axis limits
        alpha : float
            (Optional) The alpha value (Default: 0.1)
        marker : str
            (Optional) The marker symbol (Default: &#34;.&#34;)
        &#39;&#39;&#39;
        assert self._is_setup, &#39;Must run setup first&#39;
        assert driver in (&#39;tsoil&#39;, &#39;smsf&#39;),\
            &#39;Requested driver &#34;%s&#34; cannot be plotted for RECO&#39; % driver
        np.seterr(invalid = &#39;ignore&#39;)
        with h5py.File(self._path_to_scratch, &#39;r&#39;) as hdf:
            gpp = hdf[&#39;tower/GPP&#39;][:,self._sites,:].mean(axis = 2)
            reco = hdf[&#39;tower/RECO&#39;][:,self._sites,:].mean(axis = 2)

        with h5py.File(self._path_to_drivers, &#39;r&#39;) as hdf:
            # Get the user-specified driver data
            tsoil = hdf[&#39;drivers/tsoil&#39;][:,self._sites]
            smsf = hdf[&#39;drivers/smsf&#39;][:,self._sites]

        f_smsf = linear_constraint(*self.bplut[&#39;smsf&#39;][:,self._pft])
        k_mult = f_smsf(smsf) * arrhenius(tsoil, self.bplut[&#39;tsoil&#39;][0,self._pft])
        # Calculate RH as (RECO - RA)
        rh = reco - ((1 - self.bplut[&#39;CUE&#39;][0,self._pft]) * gpp)
        # Set negative RH values to zero
        rh = np.where(suppress_warnings(np.less)(rh, 0), 0, rh)
        cbar0 = suppress_warnings(cbar)(rh, k_mult, q_rh, q_k)
        gpp = reco = None

        # Update plotting parameters
        pyplot.scatter( # Plot RH/Cbar against either Tsoil or SMSF
            tsoil if driver == &#39;tsoil&#39; else smsf,
            suppress_warnings(np.divide)(rh, cbar0),
            alpha = alpha, marker = marker)

        if driver == &#39;tsoil&#39;:
            domain = np.arange(tsoil.min(), tsoil.max(), 0.1)
            pyplot.plot(domain,
                arrhenius(domain, self.bplut[&#39;tsoil&#39;][0,self._pft]), &#39;k-&#39;)
        elif driver == &#39;smsf&#39;:
            pyplot.plot(*self._ramp(smsf, driver), &#39;k-&#39;)

        if coefs is not None:
            if driver == &#39;tsoil&#39;:
                pyplot.plot(domain, arrhenius(domain, *coefs), &#39;r-&#39;)
            elif driver == &#39;smsf&#39;:
                pyplot.plot(*self._ramp(smsf, driver, coefs = coefs), &#39;r-&#39;)

        pyplot.xlabel(&#39;%s (%s)&#39; % (driver, self._metadata[driver][&#39;units&#39;]))
        pyplot.ylabel(&#39;RH/Cbar&#39;)
        if xlim is not None:
            pyplot.xlim(xlim[0], xlim[1])
        if ylim is not None:
            pyplot.ylim(ylim[0], ylim[1])
        pyplot.title(
            &#39;%s (PFT %d): RECO Response to &#34;%s&#34;&#39; % (
                PFT[self._pft][0], self._pft, driver))
        pyplot.show()

    def reset(self):
        &#39;&#39;&#39;
        Clears the current BPLUT in the scratch data, wiping out any
        calibrated parameters. Subsequent calibration will then use the
        reference (file) BPLUT for initial values.
        &#39;&#39;&#39;
        with h5py.File(self._path_to_scratch, &#39;a&#39;) as hdf:
            del hdf[&#39;BPLUT&#39;]
        print(&#39;Deleted BPLUT in the scratch file&#39;)

    def set(self, parameter, value):
        &#39;&#39;&#39;
        Sets the named parameter to the given value for the specified PFT
        class. This updates the initial parameters, affecting any subsequent
        optimization.

        Parameters
        ----------
        parameter : str
            Name of the parameter to bet set
        value : int or float
            Value of the named parameter to be set

        Returns
        -------
        CLI
        &#39;&#39;&#39;
        # Update the BPLUT in memory but NOT the file BPLUT (this is temporary)
        self.bplut.update(self._pft, (value,), (parameter,), flush = False)
        return self

    def setup(self, reset = False):
        &#39;&#39;&#39;
        Compute freeze/thaw, copy tower data, calculate site weights, and
        compute a 365-day climatology for each driver.

        Important considerations:
            1) Tower GPP and RECO values &lt;0 are masked;
            2) Tower GPP is masked where APAR is &lt;0.1 MJ m-2 d-1;
            3) Freeze/Thaw status is determiend as &#34;frozen&#34; (0) if the surface
               skin temperature is below 273.15 K, &#34;thawed&#34; (1) otherwise

        Parameters
        ----------
        reset : bool
            True to automatically delete the scratch file
        &#39;&#39;&#39;
        np.seterr(invalid = &#39;ignore&#39;)
        if reset:
            os.remove(self._path_to_scratch)
            print(&#39;Deleted scratch data.&#39;)

        # Open the scratch file
        target_hdf = h5py.File(self._path_to_scratch, &#39;a&#39;)
        # Copy tower flux datasets
        with h5py.File(self._path_to_towers, &#39;r&#39;) as hdf:
            for key in (&#39;GPP&#39;, &#39;RECO&#39;, &#39;NEE&#39;):
                arr = hdf[key][:]
                arr = arr[...,np.newaxis].repeat(81, axis = 2)
                # Mask out negative GPP and RECO values
                if key != &#39;NEE&#39;:
                    arr = np.where(np.less(arr, 0), np.nan, arr)
                target_hdf.create_dataset(
                    &#39;tower/%s&#39; % key, arr.shape, arr.dtype, arr)

        # Read in Tsurf, 9-km grid indices, and PAR + fPAR
        with h5py.File(self._path_to_drivers, &#39;r&#39;) as hdf:
            tsurf = hdf[&#39;drivers/tsurf&#39;][:]
            idx = hdf[&#39;coords/grid_9km_idx&#39;][:].round(0).astype(np.int16)
            # Make conformable PAR array at 1-km scale
            par = hdf[&#39;drivers/par&#39;][:]
            par = par[...,np.newaxis].repeat(81, axis = 2)
            apar = np.multiply(hdf[&#39;drivers/fpar&#39;][:], par)
            par = None

        # Compute freeze/thaw
        target_hdf.create_dataset( # Frozen = 0, Thawed = 1
            &#39;ft&#39;, tsurf.shape, tsurf.dtype, np.where(tsurf &lt;= 273.15, 0, 1))
        tsurf = None
        # Find duplicate (shared) 9-km cells, calculate site weights
        uid = [&#39;%d%d&#39; % (r, c) for r, c in idx.tolist()]
        target_hdf.create_dataset(&#39;site_weights&#39;, (1, self._nsites),
            np.float16, np.array([(1.0 / uid.count(x)) for x in uid]))
        # Copy APAR; screen tower GPP where APAR is low
        gpp = target_hdf[&#39;tower/GPP&#39;][:]
        target_hdf.create_dataset(&#39;APAR&#39;, apar.shape, apar.dtype, apar)
        # With APAR below 0.1, tower GPP is unstable
        target_hdf[&#39;tower/GPP&#39;][:] = np.where(apar &lt; 0.1, np.nan, gpp)
        apar = gpp = None
        # Close the scratch data
        target_hdf.close()
        # Compute climatology
        self._climatology()

    def tune_gpp(
            self, fixed = None, optimize = True, nlopt = True, trials = 1):
        &#39;&#39;&#39;
        Optimizes GPP. The 9-km mean L4C GPP is fit to the tower-observed GPP
        using constrained, non-linear least-squares optimization.

        Parameters
        ----------
        fixed : tuple or list
            Zero or more parameters whose values should be fixed
            (i.e, NOT optimized)
        optimize : bool
            False to only report parameters and their fit statistics instead
            of optimizing (Default: True)
        nlopt : bool
            True to use the nlopt library for optimization (Default: True)
        &#39;&#39;&#39;
        def e_mult(params):
            # Calculate E_mult based on current parameters
            f_tmin = linear_constraint(params[1], params[2])
            f_vpd  = linear_constraint(params[3], params[4], &#39;reversed&#39;)
            f_smrz = linear_constraint(params[5], params[6])
            f_ft   = linear_constraint(params[7], 1.0, &#39;binary&#39;)
            tmin, vpd, smrz, ft = drivers # Unpack global &#34;drivers&#34;
            e = f_tmin(tmin) * f_vpd(vpd) * f_smrz(smrz) * f_ft(ft)
            return e[...,np.newaxis]

        def gpp(params):
            # Calculate GPP based on the provided BPLUT parameters
            return apar * params[0] * e_mult(params) # Global &#34;apar&#34;

        def residuals(params):
            # Objective function: Difference between tower GPP and L4C GPP
            gpp0 = gpp(params).mean(axis = 2)
            diff = np.subtract(gpp_tower, gpp0) # Global &#34;gpp_tower&#34;
            # Multiply by the tower weights
            return (weights * diff)[~np.isnan(diff)] # Global &#34;weights&#34;

        assert self._is_setup, &#39;Must run setup first&#39;
        # Compile the initial parameters for optimization, based on current
        #   BPLUT; they are: lue, tmin0, tmin1, vpd0, vpd1, smrz0, smrz1, ft0
        if fixed is not None:
            # In case a single parameter name is passed, wrap in a list
            fixed = [fixed] if hasattr(fixed, &#39;title&#39;) else fixed
            assert all(p in self._parameters[&#39;gpp&#39;] for p in fixed),\
                &#39;Arguments to &#34;fixed&#34; should be in: [%s]&#39; % &#39;, &#39;.join(self._parameters[&#39;gpp&#39;])
        init_params = [self.bplut[&#39;LUE&#39;][0,self._pft]]
        for field in (&#39;tmin&#39;, &#39;vpd&#39;, &#39;smrz&#39;, &#39;ft&#39;):
            init_params.extend(self.bplut[field][:,self._pft].tolist())
        init_params.pop() # Remove FT upper limit (it is fixed at 1.0)

        # Read in data, with optional subsetting of the time axis
        t0 = self._time_start if self._time_start is not None else 0
        t1 = self._time_end if self._time_end is not None else self._nsteps
        with h5py.File(self._path_to_drivers, &#39;r&#39;) as hdf:
            drivers = []
            for field in (&#39;tmin&#39;, &#39;vpd&#39;, &#39;smrz&#39;):
                drivers.append(hdf[&#39;drivers/%s&#39; % field][t0:t1][:,self._sites])

        with h5py.File(self._path_to_scratch, &#39;r&#39;) as hdf:
            drivers.append(hdf[&#39;ft&#39;][t0:t1][:,self._sites])
            apar = hdf[&#39;APAR&#39;][t0:t1][:,self._sites,:]
            gpp_tower = hdf[&#39;tower/GPP&#39;][t0:t1][:,self._sites,:].mean(axis = 2)
            weights = hdf[&#39;site_weights&#39;][:][:,self._sites]

        # L4C drivers should have no NaNs, based on how they were sourced;
        #   BUT this is not the case for fPAR, which does have NaNs; not sure
        #   why I would have ever asserted it doesn&#39;t
        # assert np.all(~np.isnan(apar)), &#39;Unexpected NaNs in APAR&#39;
        for arr in drivers:
            assert np.all(~np.isnan(arr)), &#39;Unexpected NaNs&#39;

        # Get bounds for the parameter search
        bounds = self._bounds(init_params, &#39;gpp&#39;, fixed)
        params = []
        params0 = []
        scores = []
        param_space = np.linspace(bounds[0], bounds[1], 100)
        for t in range(0, trials):
            # If multiple trials, randomize the initial parameter values
            #   and score the model in each trial
            if trials &gt; 1:
                p = param_space.shape[1] # Number of parameters
                idx = np.random.randint(0, param_space.shape[0], p)
                init_params = param_space[idx,np.arange(0, p)]
                params0.append(init_params)
            if optimize and not nlopt:
                # Apply constrained, non-linear least-squares optimization
                print(&#39;Solving...&#39;)
                solution = solve_least_squares(
                    residuals, init_params, labels = self._parameters[&#39;gpp&#39;],
                    bounds = self._bounds(init_params, &#39;gpp&#39;, fixed),
                    loss = &#39;arctan&#39;)
                fitted = solution.x.tolist()
                print(solution.message)
            elif optimize and nlopt:
                opt = GenericOptimization(residuals, bounds,
                    step_size = (0.01, 0.2, 0.2, 1, 1, 0.1, 0.1, 0.01))
                fitted = opt.solve(init_params)
            else:
                fitted = [None for i in range(0, len(init_params))]
            # Record the found solution and its goodness-of-fit score
            params.append(fitted)
            _, rmse_score, _, _ = self._report_fit(
                gpp_tower,
                gpp(fitted if optimize else init_params).mean(axis = 2),
                weights, verbose = False)
            print(&#39;[%s/%s] RMSE score of last trial: %.3f&#39; % (
                str(t + 1).zfill(2), str(trials).zfill(2), rmse_score))
            scores.append(rmse_score)

        # Select the fit params with the best score
        if trials &gt; 1:
            fitted = params[np.argmin(scores)]
            init_params = params0[np.argmin(scores)]
        # Generate and print a report, update the BPLUT parameters
        self._report(
            init_params, fitted, self._parameters[&#39;gpp&#39;], &#39;GPP Optimization&#39;)
        self._report_fit(
            gpp_tower, gpp(fitted if optimize else init_params).mean(axis = 2),
            weights)
        if optimize:
            self.bplut.update(self._pft, fitted, self._parameters[&#39;gpp&#39;])

    def tune_reco(
            self, q_rh = 75, q_k = 50, fixed = None, optimize = True,
            nlopt = True, trials = 1):
        &#39;&#39;&#39;
        Optimizes RECO. The 9-km mean L4C RECO is fit to the tower-observed
        RECO using constrained, non-linear least-squares optimization.
        Considerations:
            1) Negative RH values (i.e., NPP &gt; RECO) are set to zero.

        Parameters
        ----------
        q_rh : int
            The percentile of RH/Kmult to use in calculating Cbar
        q_k : int
            The percentile of Kmult below which RH/Kmult values are masked
        fixed : tuple or list
            Zero or more parameters whose values should be fixed
            (i.e, NOT optimized)
        optimize : bool
            False to only report parameters and their fit statistics instead
            of optimizing (Default: True)
        nlopt : bool
            True to use the nlopt library for optimization (Default: True)
        trials : int
            Number of searches of the parameter space to perform; if &gt;1,
            initial parameters are randomized for each trial
        &#39;&#39;&#39;
        def k_mult(params):
            # Calculate K_mult based on current parameters
            f_tsoil = partial(arrhenius, beta0 = params[1])
            f_smsf  = linear_constraint(params[2], params[3])
            tsoil, smsf = drivers # Unpack global &#34;drivers&#34;
            return f_tsoil(tsoil) * f_smsf(smsf)

        @suppress_warnings
        def reco(params):
            # Calculate RH as (RECO - RA) or (RECO - (faut * GPP));
            #   globals &#34;reco_tower&#34;, &#34;gpp_tower&#34;
            ra = ((1 - params[0]) * gpp_tower)
            rh = reco_tower - ra
            rh = np.where(rh &lt; 0, 0, rh) # Mask out negative RH values
            # Compute Cbar with globals &#34;q_rh&#34; and &#34;q_k&#34;
            kmult0 = k_mult(params)
            cbar0 = cbar(rh, kmult0, q_rh, q_k)
            return ra + (kmult0 * cbar0)

        def residuals(params):
            # Objective function: Difference between tower RECO and L4C RECO
            reco0 = reco(params)
            diff = np.subtract(reco_tower, reco0) # Global &#34;reco_tower&#34;
            missing = np.logical_or(np.isnan(reco_tower), np.isnan(reco0))
            # Multiply by the tower weights
            return (weights * diff)[~missing] # Global &#34;weights&#34;

        assert self._is_setup, &#39;Must run setup first&#39;
        assert q_rh &gt;= 0 and q_rh &lt;= 100 and q_k &gt;= 0 and q_k &lt;= 100,\
            &#39;Invalid setting for &#34;q_rh&#34; or &#34;q_k&#34; parameters&#39;
        if fixed is not None:
            assert all(p in self._parameters[&#39;reco&#39;] for p in fixed),\
                &#39;Arguments to &#34;fixed&#34; should be in: [%s]&#39; % &#39;, &#39;.join(self._parameters[&#39;reco&#39;])
        init_params = [self.bplut[&#39;CUE&#39;][0,self._pft]]
        for field in (&#39;tsoil&#39;, &#39;smsf&#39;):
            init_params.extend(self.bplut[field][:,self._pft].tolist())

        # Read in data, with optional subsetting of the time axis
        t0 = self._time_start if self._time_start is not None else 0
        t1 = self._time_end if self._time_end is not None else self._nsteps
        with h5py.File(self._path_to_drivers, &#39;r&#39;) as hdf:
            drivers = [
                hdf[&#39;drivers/%s&#39; % field][t0:t1][:,self._sites]
                for field in (&#39;tsoil&#39;, &#39;smsf&#39;)
            ]
        with h5py.File(self._path_to_scratch, &#39;r&#39;) as hdf:
            gpp_tower = hdf[&#39;tower/GPP&#39;][t0:t1][:,self._sites,:].mean(axis = 2)
            reco_tower = hdf[&#39;tower/RECO&#39;][t0:t1][:,self._sites,:].mean(axis = 2)
            weights = hdf[&#39;site_weights&#39;][:,self._sites]

        # L4C drivers should have no NaNs, based on how they were sourced
        for arr in drivers:
            assert np.all(~np.isnan(arr)), &#39;Unexpected NaNs&#39;

        # Get bounds for the parameter search
        bounds = self._bounds(init_params, &#39;reco&#39;, fixed)
        params = []
        params0 = []
        scores = []
        param_space = np.linspace(bounds[0], bounds[1], 100)
        for t in range(0, trials):
            # If multiple trials, randomize the initial parameter values
            #   and score the model in each trial
            if trials &gt; 1:
                p = param_space.shape[1] # Number of parameters
                idx = np.random.randint(0, param_space.shape[0], p)
                init_params = param_space[idx,np.arange(0, p)]
                params0.append(init_params)
            if optimize and not nlopt:
                # Apply constrained, non-linear least-squares optimization
                solution = solve_least_squares(
                    residuals, init_params, labels = self._parameters[&#39;reco&#39;],
                    bounds = bounds, loss = &#39;arctan&#39;)
                fitted = solution.x.tolist()
                message = solution.message
            elif optimize and nlopt:
                opt = GenericOptimization(residuals, bounds,
                    step_size = (0.01, 1, 0.1, 0.1))
                fitted = opt.solve(init_params)
                message = &#39;Success&#39;
            else:
                fitted = [None for i in range(0, len(init_params))]
            # Record the found solution and its goodness-of-fit score
            params.append(fitted)
            _, rmse_score, _, _ = self._report_fit(
                reco_tower, reco(fitted if optimize else init_params),
                weights, verbose = False)
            print(&#39;[%s/%s] RMSE score of last trial: %.3f&#39; % (
                str(t + 1).zfill(2), str(trials).zfill(2), rmse_score))
            scores.append(rmse_score)

        # Select the fit params with the best score
        if trials &gt; 1:
            fitted = params[np.argmin(scores)]
            init_params = params0[np.argmin(scores)]
        # Generate and print a report, update the BPLUT parameters
        self._report(
            init_params, fitted, self._parameters[&#39;reco&#39;], &#39;RECO Optimization&#39;)
        self._report_fit(
            reco_tower, reco(fitted if optimize else init_params), weights)
        if optimize:
            self.bplut.update(self._pft, fitted, self._parameters[&#39;reco&#39;])


if __name__ == &#39;__main__&#39;:
    import fire
    fire.Fire(CLI)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="pyl4c.apps.calibration.main.CLI"><code class="flex name class">
<span>class <span class="ident">CLI</span></span>
<span>(</span><span>config='/usr/local/dev/pyl4c/pyl4c/data/files/config_calibration.json', pft=None, start=None, end=None, debug=True, use_legacy_pft=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Command line interface for calibrating L4C.</p>
<p>To plot the response function of, e.g., Tmin, with (optional) suggested
parameters (lower, upper bounds):</p>
<pre><code>python main.py pft &lt;pft&gt; plot-gpp &lt;driver&gt; [xmin, xmax]
</code></pre>
<p>To optimize all of the GPP parameters:</p>
<pre><code>python main.py pft &lt;pft&gt; tune-gpp
</code></pre>
<p>To optimize some of the GPP parameters, keeping named parameters fixed:</p>
<pre><code>python main.py pft &lt;pft&gt; tune-gpp --fixed="(LUE,ft0)"
</code></pre>
<p>To optimize GPP with the best match for previous calibrations:</p>
<pre><code>python main.py pft &lt;pft&gt; tune-gpp --end="2014-12-31"
</code></pre>
<p>To optimize GPP, first setting the initial value of a parameter:</p>
<pre><code>python main.py pft &lt;pft&gt; set &lt;param&gt; &lt;value&gt; tune-gpp
</code></pre>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>config</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to a configuration JSON file, which describes the file paths
for calibration datasets</dd>
<dt><strong><code>pft</code></strong> :&ensp;<code>int</code></dt>
<dd>The numeric code of the PFT to calibrate</dd>
<dt><strong><code>start</code></strong> :&ensp;<code>int</code></dt>
<dd>(Optional) The numeric index making the start of a time series subset
to use; if not provided, entire time series (in dataset) is used</dd>
<dt><strong><code>end</code></strong> :&ensp;<code>int</code></dt>
<dd>(Optional) The numeric index making the end of a time series subset
to use; if not provided, entire time series (in dataset) is used</dd>
<dt><strong><code>debug</code></strong> :&ensp;<code>bool</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>use_legacy_pft</code></strong> :&ensp;<code>bool</code></dt>
<dd>(Optional) True to use the L4C Nature Run v7.2 "legacy" PFT map
("lc_dom") for the PFT class assignments of each pixel (Default: True)</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class CLI(object):
    &#39;&#39;&#39;
    Command line interface for calibrating L4C.

    To plot the response function of, e.g., Tmin, with (optional) suggested
    parameters (lower, upper bounds):

        python main.py pft &lt;pft&gt; plot-gpp &lt;driver&gt; [xmin, xmax]

    To optimize all of the GPP parameters:

        python main.py pft &lt;pft&gt; tune-gpp

    To optimize some of the GPP parameters, keeping named parameters fixed:

        python main.py pft &lt;pft&gt; tune-gpp --fixed=&#34;(LUE,ft0)&#34;

    To optimize GPP with the best match for previous calibrations:

        python main.py pft &lt;pft&gt; tune-gpp --end=&#34;2014-12-31&#34;

    To optimize GPP, first setting the initial value of a parameter:

        python main.py pft &lt;pft&gt; set &lt;param&gt; &lt;value&gt; tune-gpp

    Parameters
    ----------
    config : str
        Path to a configuration JSON file, which describes the file paths
        for calibration datasets
    pft : int
        The numeric code of the PFT to calibrate
    start : int
        (Optional) The numeric index making the start of a time series subset
        to use; if not provided, entire time series (in dataset) is used
    end : int
        (Optional) The numeric index making the end of a time series subset
        to use; if not provided, entire time series (in dataset) is used
    debug : bool
    use_legacy_pft : bool
        (Optional) True to use the L4C Nature Run v7.2 &#34;legacy&#34; PFT map
        (&#34;lc_dom&#34;) for the PFT class assignments of each pixel (Default: True)
    &#39;&#39;&#39;
    _driver_bounds = {&#39;apar&#39;: (2, np.inf)}
    _metadata = {
        &#39;tmin&#39;: {&#39;units&#39;: &#39;deg K&#39;},
        &#39;vpd&#39;: {&#39;units&#39;: &#39;Pa&#39;},
        &#39;smrz&#39;: {&#39;units&#39;: &#39;%&#39;},
        &#39;smsf&#39;: {&#39;units&#39;: &#39;%&#39;},
        &#39;tsoil&#39;: {&#39;units&#39;: &#39;deg K&#39;},
    }
    _parameters = {
        &#39;gpp&#39;: (
            &#39;LUE&#39;, &#39;tmin0&#39;, &#39;tmin1&#39;, &#39;vpd0&#39;, &#39;vpd1&#39;, &#39;smrz0&#39;, &#39;smrz1&#39;, &#39;ft0&#39;
        ),
        &#39;reco&#39;: (
            &#39;CUE&#39;, &#39;tsoil&#39;, &#39;smsf0&#39;, &#39;smsf1&#39;
        )
    }
    _required_drivers = [
        &#39;fpar&#39;, &#39;par&#39;, &#39;smrz&#39;, &#39;smsf&#39;, &#39;tsoil&#39;, &#39;tmin&#39;, &#39;vpd&#39;, &#39;tsurf&#39;
    ]

    def __init__(
            self, config = CONFIG, pft = None, start = None, end = None,
            debug = True, use_legacy_pft = True):
        self._debug = debug
        self._nsites = 0
        self._nsteps = 0
        self._pft = pft
        self._pft_map = None
        self._site_weights = None
        self._time_end = None
        self._time_start = None
        self._use_legacy_pft = use_legacy_pft

        # Read in configuration file to determine file paths
        with open(config, &#39;r&#39;) as file:
            config_data = json.load(file)
        self._path_to_bplut = config_data[&#39;BPLUT_file&#39;]
        self._path_to_drivers = config_data[&#39;drivers_file&#39;]
        self._path_to_scratch = config_data[&#39;scratch_file&#39;]
        self._path_to_towers = config_data[&#39;towers_file&#39;]
        self._check() # Check for required keys in driver data

        # Allow users to specify start and end dates for the time series
        if start is not None or end is not None:
            with h5py.File(self._path_to_drivers, &#39;r&#39;) as hdf:
                time_series = [
                    datetime.datetime(y, m, d).strftime(&#39;%Y-%m-%d&#39;)
                    for y, m, d, _ in hdf[&#39;time&#39;][:].tolist()
                ]
            if start is not None:
                self._time_start = time_series.index(start)
            if end is not None:
                self._time_end = time_series.index(end)

        # Creates the BPLUT store
        self._init_bplut()

        # Read in PFT map
        with h5py.File(self._path_to_drivers, &#39;r&#39;) as hdf:
            self._nsites = hdf[&#39;state/PFT&#39;].shape[0]
            self._nsteps = hdf[&#39;time&#39;].shape[0]
            if self._use_legacy_pft:
                self._pft_map = hdf[&#39;legacy/lc_dom&#39;][:].swapaxes(0, 1)
            else:
                self._pft_map = hdf[&#39;state/PFT&#39;][:]

    @property
    def _is_setup(self):
        return os.path.exists(self._path_to_scratch)

    def _bounds(self, init_params, group, fixed = None, bounds = OPT_BOUNDS):
        &#39;Defines bounds; optionally &#34;fixes&#34; parameters by fixing bounds&#39;
        params = init_params
        if fixed is not None:
            params = [ # If the given parameter is in &#34;fixed&#34;, restrict bounds
                None if self._parameters[group][i] in fixed else init_params[i]
                for i in range(0, len(self._parameters[group]))
            ]
        lower = []
        upper = []
        for i, p in enumerate(params):
            # This is a parameter to be optimized; use default bounds
            if p is not None:
                lower.append(bounds[group][0][i])
                upper.append(bounds[group][1][i])
            else:
                lower.append(init_params[i] - 1e-3)
                upper.append(init_params[i] + 1e-3)
        return (np.array(lower), np.array(upper))

    def _check(self):
        &#39;Checks for all the required keys in the driver dataset&#39;
        msg = &#39;Missing required driver: %s&#39;
        with h5py.File(self._path_to_drivers, &#39;r&#39;) as hdf:
            for key in self._required_drivers:
                assert key in hdf[&#39;drivers&#39;].keys(), msg % key
            assert hdf[&#39;drivers/smsf&#39;][:].max() &gt; 1,\
                &#39;SMSF data may not be in percent saturation units!&#39;
            assert hdf[&#39;drivers/smrz&#39;][:].max() &gt; 1,\
                &#39;SMRZ data may not be in percent saturation units!&#39;

    @suppress_warnings
    def _climatology(self):
        &#39;Computes a 365-day climatology for each driver&#39;
        with h5py.File(self._path_to_drivers, &#39;r&#39;) as hdf:
            time_series = [
                datetime.datetime(y, m, d)
                for y, m, d, _ in hdf[&#39;time&#39;][:].tolist()
            ]
            with h5py.File(self._path_to_scratch, &#39;a&#39;) as target_hdf:
                for key in self._required_drivers:
                    if &#39;climatologies&#39; in target_hdf.keys():
                        if key in target_hdf[&#39;climatologies&#39;].keys():
                            continue # Skip to next

                    if self._debug:
                        print(&#39;Calculating %s climatology...&#39; % key)
                    shp = (365, *hdf[&#39;drivers/%s&#39; % key].shape[1:])
                    target_hdf.create_dataset(
                        &#39;climatologies/%s&#39; % key, shp,
                        dtype = hdf[&#39;drivers/%s&#39; % key].dtype,
                        data = climatology365(
                            hdf[&#39;drivers/%s&#39; % key][:], time_series))

    def _constrain(self, x, driver, coefs = None):
        &#39;Converts a driver x into a multiple on [0, 1].&#39;
        if driver == &#39;tsoil&#39;:
            return arrhenius(x, self.bplut[&#39;tsoil&#39;][0,self._pft])
        # User can provide an M-element array-like
        if coefs is None:
            coefs = self.bplut[driver][:,self._pft].tolist()
        constraint = linear_constraint(coefs[0], coefs[1])
        if driver == &#39;vpd&#39;:
            # VPD mult. declines with increasing VPD, unlike other drivers
            constraint = linear_constraint(coefs[0], coefs[1], &#39;reversed&#39;)
        elif driver == &#39;ft&#39;:
            # FT has a binary response
            constraint = linear_constraint(coefs[0], coefs[1], &#39;binary&#39;)
        return constraint(x)

    def _filter(self, raw, size):
        &#39;Apply a smoothing filter with zero phase offset&#39;
        if size &gt; 1:
            window = np.ones(size) / size
            return np.apply_along_axis(
                lambda x: signal.filtfilt(window, np.ones(1), x), 0, raw)
        else:
            return raw # Or, revert to the raw data

    def _init_bplut(self, labels = None):
        # Create the output BPLUT store; if there&#39;s already a BPLUT table
        #   in the scratch, it will be combined with the initial BPLUT,
        #   overwriting INTITIAL_BPLUT values in favor of the file BPLUT
        self.bplut = BPLUT(
            restore_bplut(self._path_to_bplut), labels = labels,
            hdf5_path = self._path_to_scratch)

    def _ramp(self, x, driver, step = 0.1, coefs = None):
        &#39;Returns a ramp function over the domain of x; returns (domain, ramp)&#39;
        domain = np.arange(np.nanmin(x), np.nanmax(x), step)
        ramp = self._constrain(domain, driver, coefs)
        return (domain, ramp)

    def _report(self, old_params, new_params, labels, title, prec = 2):
        &#39;Prints a report on the updated (optimized) parameters&#39;
        pad = max(len(l) for l in labels) + 1
        fmt_string = &#39;-- {:&lt;%d} {:&gt;%d} [{:&gt;%d}]&#39; % (pad, 5 + prec, 7 + prec)
        print(&#39;%s parameters report, %s (PFT %d):&#39; % (
            title, PFT[self._pft][0], self._pft))
        print((&#39; {:&gt;%d} {:&gt;%d}&#39; % (8 + pad + prec, 8 + prec))\
            .format(&#39;NEW&#39;, &#39;INITIAL&#39;))
        for i, label in enumerate(labels):
            new = (&#39;%%.%df&#39; % prec) % new_params[i] if new_params[i] is not None else &#39;&#39;
            old = (&#39;%%.%df&#39; % prec) % old_params[i]
            print(fmt_string.format((&#39;%s:&#39; % label), new, old))

    @suppress_warnings
    def _report_fit(self, obs, pred, weights, verbose = True):
        &#39;Reports RMSE and unbiased RMSE&#39;
        return report_fit_stats(obs, pred, weights, verbose = verbose)

    @property
    def _sites(self):
        &#39;&#39;&#39;
        For a given PFT class, returns the tower sites, as rank indices, that
        represent that PFT. Exceptions are made according to the L4C
        calibration protocol, e.g., sites with any amount of
        Deciduous Needleleaf (DNF) in their 1-km subgrid are considered to
        represent the DNF PFT class.
        &#39;&#39;&#39;
        return pft_selector(self._pft_map, self._pft)

    def pft(self, pft):
        &#39;&#39;&#39;
        Sets the PFT class for the next calibration step.

        Parameters
        ----------
        pft : int
            The PFT class to use in calibration

        Returns
        -------
        CLI
        &#39;&#39;&#39;
        assert pft in range(1, 9), &#39;Unrecognized PFT class&#39;
        self._pft = pft
        return self

    def filter(self, flux, size = 2):
        &#39;&#39;&#39;
        Filters the tower GPP or RECO flux data. Each time it is called, the
        raw (noisy) tower data is filtered; successive calls with the same
        arguments will only overwrite the filtered tower data.

        Parameters
        ----------
        flux : str
            &#34;gpp&#34; or &#34;reco&#34; for the corresponding tower dataset
        size : int
            Filter window size, in days
        &#39;&#39;&#39;
        assert any(self._sites), &#39;You must select a PFT class&#39;
        with h5py.File(self._path_to_scratch, &#39;a&#39;) as hdf:
            assert flux.upper() in hdf[&#39;tower&#39;].keys(),\
                &#39;Field &#34;tower/%s&#34; not found&#39; % flux.upper()
            # Tower fluxes are duplicated on the last axis, so pick one
            raw = hdf[&#39;tower/%s&#39; % flux.upper()][:,self._sites,0]
            filtered = self._filter(raw, size)
            # Re-duplicate the 1-km subgrid on the last axis
            filtered = filtered[...,np.newaxis].repeat(81, axis = 2)
            hdf[&#39;tower/%s&#39; % flux.upper()][:,self._sites,:] = filtered

    def filter_all(self, flux, size = 2):
        &#39;&#39;&#39;
        Filters the tower GPP or RECO flux data for ALL PFT classes.
        See also: filter().

        Parameters
        ----------
        flux : str
            &#34;gpp&#34; or &#34;reco&#34; for the corresponding tower dataset
        size : int
            Filter window size, in days
        &#39;&#39;&#39;
        with h5py.File(self._path_to_scratch, &#39;a&#39;) as hdf:
            assert flux.upper() in hdf[&#39;tower&#39;].keys(),\
                &#39;Field &#34;tower/%s&#34; not found&#39; % flux.upper()
            # Tower fluxes are duplicated on the last axis, so pick one
            filtered = self._filter(
                hdf[&#39;tower/%s&#39; % flux.upper()][...,0], size)
            # Re-duplicate the 1-km subgrid on the last axis
            filtered = filtered[...,np.newaxis].repeat(81, axis = 2)
            hdf[&#39;tower/%s&#39; % flux.upper()][:] = filtered

    def filter_preview(self, flux, size = 2, seed = 9):
        &#39;&#39;&#39;
        Previews a filter for the tower GPP or RECO data.

        Parameters
        flux : str
            &#34;gpp&#34; or &#34;reco&#34; for the corresponding tower dataset
        size : int
            Filter window size, in days
        seed : int
            Random seed; change to select a different tower site
        &#39;&#39;&#39;
        assert self._sites.any(), &#39;You must select a PFT class&#39;
        with h5py.File(self._path_to_scratch, &#39;r&#39;) as hdf:
            assert flux.upper() in hdf[&#39;tower&#39;].keys(),\
                &#39;Field &#34;%s&#34; not found&#39; % flux.upper()
            x = hdf[&#39;tower/%s&#39; % flux.upper()][:]

        # Get a random tower site matching the current PFT class
        np.random.seed(seed)
        idx = np.random.choice(np.argwhere(self._sites).flatten(), 1)[0]
        x0 = x[:,idx,0]
        x_filt = self._filter(x0, size)
        pyplot.plot(x0, c = &#39;lightsteelblue&#39;)
        pyplot.plot(x_filt, c = &#39;darkorange&#39;)
        pyplot.ylabel(&#39;Tower %s (g C m-2 day-1)&#39; % flux.upper())
        pyplot.title(&#39;Window Size = %d days&#39; % size)
        pyplot.show()

    def plot_gpp(
            self, driver, coefs = None, xlim = None, ylim = None, alpha = 0.1,
            marker = &#39;.&#39;):
        &#39;&#39;&#39;
        Using the current or optimized BPLUT coefficients, plots the GPP ramp
        function for a given driver. NOTE: Values where APAR &lt; 2.0 are not
        shown.

        Parameters
        ----------
        driver : str
            Name of the driver to plot on the horizontal axis
        coefs : list or tuple or numpy.ndarray
            (Optional) array-like, Instead of using what&#39;s in the BPLUT,
            specify the exact parameters, e.g., [tmin0, tmin1]
        xlim : list or tuple
            (Optional) A 2-element sequence: The x-axis limits
        ylim : list or tuple
            (Optional) A 2-element sequence: The x-axis limits
        alpha : float
            (Optional) The alpha value (Default: 0.1)
        marker : str
            (Optional) The marker symbol (Default: &#34;.&#34;)
        &#39;&#39;&#39;
        @suppress_warnings
        def empirical_lue(apar, gpp):
            # Mask low APAR values
            lower, _ = self._driver_bounds.get(&#39;apar&#39;, (0, None))
            apar = np.where(apar &lt; lower, np.nan, apar)
            # Calculate empirical light-use efficiency: GPP/APAR
            return np.where(apar &gt; 0, np.divide(gpp, apar), 0)

        assert self._is_setup, &#39;Must run setup first&#39;
        np.seterr(invalid = &#39;ignore&#39;)
        # Read in GPP and APAR data
        if coefs is not None:
            assert hasattr(coefs, &#39;index&#39;) and not hasattr(coefs, &#39;title&#39;),\
                &#34;Argument --coefs expects a list [values,] with NO spaces&#34;
        assert driver in (&#39;tmin&#39;, &#39;vpd&#39;, &#39;smrz&#39;),\
            &#39;Requested driver &#34;%s&#34; cannot be plotted for GPP&#39; % driver
        with h5py.File(self._path_to_scratch, &#39;r&#39;) as hdf:
            gpp = hdf[&#39;tower/GPP&#39;][:,self._sites,:].mean(axis = 2)
            apar = hdf[&#39;APAR&#39;][:,self._sites,:].mean(axis = 2)

        with h5py.File(self._path_to_drivers, &#39;r&#39;) as hdf:
            # Get the user-specified driver data
            x = hdf[&#39;drivers/%s&#39; % driver][:,self._sites]

        # Update plotting parameters
        lue = empirical_lue(apar, gpp)
        # Mask out negative LUE values and values with APAR&lt;2
        pyplot.scatter(x, np.where(
            np.logical_or(lue == 0, apar &lt; 2), np.nan, lue),
            alpha = alpha, marker = marker)
        a, b = self._ramp(x, driver)
        pyplot.plot(a, b * self.bplut[&#39;LUE&#39;][:,self._pft], &#39;k-&#39;)
        if coefs is not None:
            pyplot.plot(*self._ramp(x, driver, coefs = coefs), &#39;r-&#39;)
        pyplot.xlabel(&#39;%s (%s)&#39; % (driver, self._metadata[driver][&#39;units&#39;]))
        pyplot.ylabel(&#39;GPP/APAR (g C MJ-1 d-1)&#39;)
        if xlim is not None:
            pyplot.xlim(xlim[0], xlim[1])
        if ylim is not None:
            pyplot.ylim(ylim[0], ylim[1])
        pyplot.title(
            &#39;%s (PFT %d): GPP Response to &#34;%s&#34;&#39; % (
                PFT[self._pft][0], self._pft, driver))
        pyplot.show()

    def plot_reco(
            self, driver, coefs = None, q_rh = 75, q_k = 50, xlim = None,
            ylim = None, alpha = 0.1, marker = &#39;.&#39;):
        &#39;&#39;&#39;
        Using the current or optimized BPLUT coefficients, plots the RECO ramp
        function for a given driver. The ramp function is shown on a plot of
        RH/Cbar, which is equivalent to Kmult (as Cbar is an upper quantile of
        the RH/Kmult distribution).

        Parameters
        ----------
        driver : str
            Name of the driver to plot on the horizontal axis
        coefs : list or tuple or numpy.ndarray
            (Optional) array-like, Instead of using what&#39;s in the BPLUT,
            specify the exact parameters, e.g., `[tmin0, tmin1]`
        q_rh : int
            Additional arguments to `pyl4c.apps.calibration.cbar()`
        q_k : int
            Additional arguments to `pyl4c.apps.calibration.cbar()`
        ylim : list or tuple
            (Optional) A 2-element sequence: The x-axis limits
        alpha : float
            (Optional) The alpha value (Default: 0.1)
        marker : str
            (Optional) The marker symbol (Default: &#34;.&#34;)
        &#39;&#39;&#39;
        assert self._is_setup, &#39;Must run setup first&#39;
        assert driver in (&#39;tsoil&#39;, &#39;smsf&#39;),\
            &#39;Requested driver &#34;%s&#34; cannot be plotted for RECO&#39; % driver
        np.seterr(invalid = &#39;ignore&#39;)
        with h5py.File(self._path_to_scratch, &#39;r&#39;) as hdf:
            gpp = hdf[&#39;tower/GPP&#39;][:,self._sites,:].mean(axis = 2)
            reco = hdf[&#39;tower/RECO&#39;][:,self._sites,:].mean(axis = 2)

        with h5py.File(self._path_to_drivers, &#39;r&#39;) as hdf:
            # Get the user-specified driver data
            tsoil = hdf[&#39;drivers/tsoil&#39;][:,self._sites]
            smsf = hdf[&#39;drivers/smsf&#39;][:,self._sites]

        f_smsf = linear_constraint(*self.bplut[&#39;smsf&#39;][:,self._pft])
        k_mult = f_smsf(smsf) * arrhenius(tsoil, self.bplut[&#39;tsoil&#39;][0,self._pft])
        # Calculate RH as (RECO - RA)
        rh = reco - ((1 - self.bplut[&#39;CUE&#39;][0,self._pft]) * gpp)
        # Set negative RH values to zero
        rh = np.where(suppress_warnings(np.less)(rh, 0), 0, rh)
        cbar0 = suppress_warnings(cbar)(rh, k_mult, q_rh, q_k)
        gpp = reco = None

        # Update plotting parameters
        pyplot.scatter( # Plot RH/Cbar against either Tsoil or SMSF
            tsoil if driver == &#39;tsoil&#39; else smsf,
            suppress_warnings(np.divide)(rh, cbar0),
            alpha = alpha, marker = marker)

        if driver == &#39;tsoil&#39;:
            domain = np.arange(tsoil.min(), tsoil.max(), 0.1)
            pyplot.plot(domain,
                arrhenius(domain, self.bplut[&#39;tsoil&#39;][0,self._pft]), &#39;k-&#39;)
        elif driver == &#39;smsf&#39;:
            pyplot.plot(*self._ramp(smsf, driver), &#39;k-&#39;)

        if coefs is not None:
            if driver == &#39;tsoil&#39;:
                pyplot.plot(domain, arrhenius(domain, *coefs), &#39;r-&#39;)
            elif driver == &#39;smsf&#39;:
                pyplot.plot(*self._ramp(smsf, driver, coefs = coefs), &#39;r-&#39;)

        pyplot.xlabel(&#39;%s (%s)&#39; % (driver, self._metadata[driver][&#39;units&#39;]))
        pyplot.ylabel(&#39;RH/Cbar&#39;)
        if xlim is not None:
            pyplot.xlim(xlim[0], xlim[1])
        if ylim is not None:
            pyplot.ylim(ylim[0], ylim[1])
        pyplot.title(
            &#39;%s (PFT %d): RECO Response to &#34;%s&#34;&#39; % (
                PFT[self._pft][0], self._pft, driver))
        pyplot.show()

    def reset(self):
        &#39;&#39;&#39;
        Clears the current BPLUT in the scratch data, wiping out any
        calibrated parameters. Subsequent calibration will then use the
        reference (file) BPLUT for initial values.
        &#39;&#39;&#39;
        with h5py.File(self._path_to_scratch, &#39;a&#39;) as hdf:
            del hdf[&#39;BPLUT&#39;]
        print(&#39;Deleted BPLUT in the scratch file&#39;)

    def set(self, parameter, value):
        &#39;&#39;&#39;
        Sets the named parameter to the given value for the specified PFT
        class. This updates the initial parameters, affecting any subsequent
        optimization.

        Parameters
        ----------
        parameter : str
            Name of the parameter to bet set
        value : int or float
            Value of the named parameter to be set

        Returns
        -------
        CLI
        &#39;&#39;&#39;
        # Update the BPLUT in memory but NOT the file BPLUT (this is temporary)
        self.bplut.update(self._pft, (value,), (parameter,), flush = False)
        return self

    def setup(self, reset = False):
        &#39;&#39;&#39;
        Compute freeze/thaw, copy tower data, calculate site weights, and
        compute a 365-day climatology for each driver.

        Important considerations:
            1) Tower GPP and RECO values &lt;0 are masked;
            2) Tower GPP is masked where APAR is &lt;0.1 MJ m-2 d-1;
            3) Freeze/Thaw status is determiend as &#34;frozen&#34; (0) if the surface
               skin temperature is below 273.15 K, &#34;thawed&#34; (1) otherwise

        Parameters
        ----------
        reset : bool
            True to automatically delete the scratch file
        &#39;&#39;&#39;
        np.seterr(invalid = &#39;ignore&#39;)
        if reset:
            os.remove(self._path_to_scratch)
            print(&#39;Deleted scratch data.&#39;)

        # Open the scratch file
        target_hdf = h5py.File(self._path_to_scratch, &#39;a&#39;)
        # Copy tower flux datasets
        with h5py.File(self._path_to_towers, &#39;r&#39;) as hdf:
            for key in (&#39;GPP&#39;, &#39;RECO&#39;, &#39;NEE&#39;):
                arr = hdf[key][:]
                arr = arr[...,np.newaxis].repeat(81, axis = 2)
                # Mask out negative GPP and RECO values
                if key != &#39;NEE&#39;:
                    arr = np.where(np.less(arr, 0), np.nan, arr)
                target_hdf.create_dataset(
                    &#39;tower/%s&#39; % key, arr.shape, arr.dtype, arr)

        # Read in Tsurf, 9-km grid indices, and PAR + fPAR
        with h5py.File(self._path_to_drivers, &#39;r&#39;) as hdf:
            tsurf = hdf[&#39;drivers/tsurf&#39;][:]
            idx = hdf[&#39;coords/grid_9km_idx&#39;][:].round(0).astype(np.int16)
            # Make conformable PAR array at 1-km scale
            par = hdf[&#39;drivers/par&#39;][:]
            par = par[...,np.newaxis].repeat(81, axis = 2)
            apar = np.multiply(hdf[&#39;drivers/fpar&#39;][:], par)
            par = None

        # Compute freeze/thaw
        target_hdf.create_dataset( # Frozen = 0, Thawed = 1
            &#39;ft&#39;, tsurf.shape, tsurf.dtype, np.where(tsurf &lt;= 273.15, 0, 1))
        tsurf = None
        # Find duplicate (shared) 9-km cells, calculate site weights
        uid = [&#39;%d%d&#39; % (r, c) for r, c in idx.tolist()]
        target_hdf.create_dataset(&#39;site_weights&#39;, (1, self._nsites),
            np.float16, np.array([(1.0 / uid.count(x)) for x in uid]))
        # Copy APAR; screen tower GPP where APAR is low
        gpp = target_hdf[&#39;tower/GPP&#39;][:]
        target_hdf.create_dataset(&#39;APAR&#39;, apar.shape, apar.dtype, apar)
        # With APAR below 0.1, tower GPP is unstable
        target_hdf[&#39;tower/GPP&#39;][:] = np.where(apar &lt; 0.1, np.nan, gpp)
        apar = gpp = None
        # Close the scratch data
        target_hdf.close()
        # Compute climatology
        self._climatology()

    def tune_gpp(
            self, fixed = None, optimize = True, nlopt = True, trials = 1):
        &#39;&#39;&#39;
        Optimizes GPP. The 9-km mean L4C GPP is fit to the tower-observed GPP
        using constrained, non-linear least-squares optimization.

        Parameters
        ----------
        fixed : tuple or list
            Zero or more parameters whose values should be fixed
            (i.e, NOT optimized)
        optimize : bool
            False to only report parameters and their fit statistics instead
            of optimizing (Default: True)
        nlopt : bool
            True to use the nlopt library for optimization (Default: True)
        &#39;&#39;&#39;
        def e_mult(params):
            # Calculate E_mult based on current parameters
            f_tmin = linear_constraint(params[1], params[2])
            f_vpd  = linear_constraint(params[3], params[4], &#39;reversed&#39;)
            f_smrz = linear_constraint(params[5], params[6])
            f_ft   = linear_constraint(params[7], 1.0, &#39;binary&#39;)
            tmin, vpd, smrz, ft = drivers # Unpack global &#34;drivers&#34;
            e = f_tmin(tmin) * f_vpd(vpd) * f_smrz(smrz) * f_ft(ft)
            return e[...,np.newaxis]

        def gpp(params):
            # Calculate GPP based on the provided BPLUT parameters
            return apar * params[0] * e_mult(params) # Global &#34;apar&#34;

        def residuals(params):
            # Objective function: Difference between tower GPP and L4C GPP
            gpp0 = gpp(params).mean(axis = 2)
            diff = np.subtract(gpp_tower, gpp0) # Global &#34;gpp_tower&#34;
            # Multiply by the tower weights
            return (weights * diff)[~np.isnan(diff)] # Global &#34;weights&#34;

        assert self._is_setup, &#39;Must run setup first&#39;
        # Compile the initial parameters for optimization, based on current
        #   BPLUT; they are: lue, tmin0, tmin1, vpd0, vpd1, smrz0, smrz1, ft0
        if fixed is not None:
            # In case a single parameter name is passed, wrap in a list
            fixed = [fixed] if hasattr(fixed, &#39;title&#39;) else fixed
            assert all(p in self._parameters[&#39;gpp&#39;] for p in fixed),\
                &#39;Arguments to &#34;fixed&#34; should be in: [%s]&#39; % &#39;, &#39;.join(self._parameters[&#39;gpp&#39;])
        init_params = [self.bplut[&#39;LUE&#39;][0,self._pft]]
        for field in (&#39;tmin&#39;, &#39;vpd&#39;, &#39;smrz&#39;, &#39;ft&#39;):
            init_params.extend(self.bplut[field][:,self._pft].tolist())
        init_params.pop() # Remove FT upper limit (it is fixed at 1.0)

        # Read in data, with optional subsetting of the time axis
        t0 = self._time_start if self._time_start is not None else 0
        t1 = self._time_end if self._time_end is not None else self._nsteps
        with h5py.File(self._path_to_drivers, &#39;r&#39;) as hdf:
            drivers = []
            for field in (&#39;tmin&#39;, &#39;vpd&#39;, &#39;smrz&#39;):
                drivers.append(hdf[&#39;drivers/%s&#39; % field][t0:t1][:,self._sites])

        with h5py.File(self._path_to_scratch, &#39;r&#39;) as hdf:
            drivers.append(hdf[&#39;ft&#39;][t0:t1][:,self._sites])
            apar = hdf[&#39;APAR&#39;][t0:t1][:,self._sites,:]
            gpp_tower = hdf[&#39;tower/GPP&#39;][t0:t1][:,self._sites,:].mean(axis = 2)
            weights = hdf[&#39;site_weights&#39;][:][:,self._sites]

        # L4C drivers should have no NaNs, based on how they were sourced;
        #   BUT this is not the case for fPAR, which does have NaNs; not sure
        #   why I would have ever asserted it doesn&#39;t
        # assert np.all(~np.isnan(apar)), &#39;Unexpected NaNs in APAR&#39;
        for arr in drivers:
            assert np.all(~np.isnan(arr)), &#39;Unexpected NaNs&#39;

        # Get bounds for the parameter search
        bounds = self._bounds(init_params, &#39;gpp&#39;, fixed)
        params = []
        params0 = []
        scores = []
        param_space = np.linspace(bounds[0], bounds[1], 100)
        for t in range(0, trials):
            # If multiple trials, randomize the initial parameter values
            #   and score the model in each trial
            if trials &gt; 1:
                p = param_space.shape[1] # Number of parameters
                idx = np.random.randint(0, param_space.shape[0], p)
                init_params = param_space[idx,np.arange(0, p)]
                params0.append(init_params)
            if optimize and not nlopt:
                # Apply constrained, non-linear least-squares optimization
                print(&#39;Solving...&#39;)
                solution = solve_least_squares(
                    residuals, init_params, labels = self._parameters[&#39;gpp&#39;],
                    bounds = self._bounds(init_params, &#39;gpp&#39;, fixed),
                    loss = &#39;arctan&#39;)
                fitted = solution.x.tolist()
                print(solution.message)
            elif optimize and nlopt:
                opt = GenericOptimization(residuals, bounds,
                    step_size = (0.01, 0.2, 0.2, 1, 1, 0.1, 0.1, 0.01))
                fitted = opt.solve(init_params)
            else:
                fitted = [None for i in range(0, len(init_params))]
            # Record the found solution and its goodness-of-fit score
            params.append(fitted)
            _, rmse_score, _, _ = self._report_fit(
                gpp_tower,
                gpp(fitted if optimize else init_params).mean(axis = 2),
                weights, verbose = False)
            print(&#39;[%s/%s] RMSE score of last trial: %.3f&#39; % (
                str(t + 1).zfill(2), str(trials).zfill(2), rmse_score))
            scores.append(rmse_score)

        # Select the fit params with the best score
        if trials &gt; 1:
            fitted = params[np.argmin(scores)]
            init_params = params0[np.argmin(scores)]
        # Generate and print a report, update the BPLUT parameters
        self._report(
            init_params, fitted, self._parameters[&#39;gpp&#39;], &#39;GPP Optimization&#39;)
        self._report_fit(
            gpp_tower, gpp(fitted if optimize else init_params).mean(axis = 2),
            weights)
        if optimize:
            self.bplut.update(self._pft, fitted, self._parameters[&#39;gpp&#39;])

    def tune_reco(
            self, q_rh = 75, q_k = 50, fixed = None, optimize = True,
            nlopt = True, trials = 1):
        &#39;&#39;&#39;
        Optimizes RECO. The 9-km mean L4C RECO is fit to the tower-observed
        RECO using constrained, non-linear least-squares optimization.
        Considerations:
            1) Negative RH values (i.e., NPP &gt; RECO) are set to zero.

        Parameters
        ----------
        q_rh : int
            The percentile of RH/Kmult to use in calculating Cbar
        q_k : int
            The percentile of Kmult below which RH/Kmult values are masked
        fixed : tuple or list
            Zero or more parameters whose values should be fixed
            (i.e, NOT optimized)
        optimize : bool
            False to only report parameters and their fit statistics instead
            of optimizing (Default: True)
        nlopt : bool
            True to use the nlopt library for optimization (Default: True)
        trials : int
            Number of searches of the parameter space to perform; if &gt;1,
            initial parameters are randomized for each trial
        &#39;&#39;&#39;
        def k_mult(params):
            # Calculate K_mult based on current parameters
            f_tsoil = partial(arrhenius, beta0 = params[1])
            f_smsf  = linear_constraint(params[2], params[3])
            tsoil, smsf = drivers # Unpack global &#34;drivers&#34;
            return f_tsoil(tsoil) * f_smsf(smsf)

        @suppress_warnings
        def reco(params):
            # Calculate RH as (RECO - RA) or (RECO - (faut * GPP));
            #   globals &#34;reco_tower&#34;, &#34;gpp_tower&#34;
            ra = ((1 - params[0]) * gpp_tower)
            rh = reco_tower - ra
            rh = np.where(rh &lt; 0, 0, rh) # Mask out negative RH values
            # Compute Cbar with globals &#34;q_rh&#34; and &#34;q_k&#34;
            kmult0 = k_mult(params)
            cbar0 = cbar(rh, kmult0, q_rh, q_k)
            return ra + (kmult0 * cbar0)

        def residuals(params):
            # Objective function: Difference between tower RECO and L4C RECO
            reco0 = reco(params)
            diff = np.subtract(reco_tower, reco0) # Global &#34;reco_tower&#34;
            missing = np.logical_or(np.isnan(reco_tower), np.isnan(reco0))
            # Multiply by the tower weights
            return (weights * diff)[~missing] # Global &#34;weights&#34;

        assert self._is_setup, &#39;Must run setup first&#39;
        assert q_rh &gt;= 0 and q_rh &lt;= 100 and q_k &gt;= 0 and q_k &lt;= 100,\
            &#39;Invalid setting for &#34;q_rh&#34; or &#34;q_k&#34; parameters&#39;
        if fixed is not None:
            assert all(p in self._parameters[&#39;reco&#39;] for p in fixed),\
                &#39;Arguments to &#34;fixed&#34; should be in: [%s]&#39; % &#39;, &#39;.join(self._parameters[&#39;reco&#39;])
        init_params = [self.bplut[&#39;CUE&#39;][0,self._pft]]
        for field in (&#39;tsoil&#39;, &#39;smsf&#39;):
            init_params.extend(self.bplut[field][:,self._pft].tolist())

        # Read in data, with optional subsetting of the time axis
        t0 = self._time_start if self._time_start is not None else 0
        t1 = self._time_end if self._time_end is not None else self._nsteps
        with h5py.File(self._path_to_drivers, &#39;r&#39;) as hdf:
            drivers = [
                hdf[&#39;drivers/%s&#39; % field][t0:t1][:,self._sites]
                for field in (&#39;tsoil&#39;, &#39;smsf&#39;)
            ]
        with h5py.File(self._path_to_scratch, &#39;r&#39;) as hdf:
            gpp_tower = hdf[&#39;tower/GPP&#39;][t0:t1][:,self._sites,:].mean(axis = 2)
            reco_tower = hdf[&#39;tower/RECO&#39;][t0:t1][:,self._sites,:].mean(axis = 2)
            weights = hdf[&#39;site_weights&#39;][:,self._sites]

        # L4C drivers should have no NaNs, based on how they were sourced
        for arr in drivers:
            assert np.all(~np.isnan(arr)), &#39;Unexpected NaNs&#39;

        # Get bounds for the parameter search
        bounds = self._bounds(init_params, &#39;reco&#39;, fixed)
        params = []
        params0 = []
        scores = []
        param_space = np.linspace(bounds[0], bounds[1], 100)
        for t in range(0, trials):
            # If multiple trials, randomize the initial parameter values
            #   and score the model in each trial
            if trials &gt; 1:
                p = param_space.shape[1] # Number of parameters
                idx = np.random.randint(0, param_space.shape[0], p)
                init_params = param_space[idx,np.arange(0, p)]
                params0.append(init_params)
            if optimize and not nlopt:
                # Apply constrained, non-linear least-squares optimization
                solution = solve_least_squares(
                    residuals, init_params, labels = self._parameters[&#39;reco&#39;],
                    bounds = bounds, loss = &#39;arctan&#39;)
                fitted = solution.x.tolist()
                message = solution.message
            elif optimize and nlopt:
                opt = GenericOptimization(residuals, bounds,
                    step_size = (0.01, 1, 0.1, 0.1))
                fitted = opt.solve(init_params)
                message = &#39;Success&#39;
            else:
                fitted = [None for i in range(0, len(init_params))]
            # Record the found solution and its goodness-of-fit score
            params.append(fitted)
            _, rmse_score, _, _ = self._report_fit(
                reco_tower, reco(fitted if optimize else init_params),
                weights, verbose = False)
            print(&#39;[%s/%s] RMSE score of last trial: %.3f&#39; % (
                str(t + 1).zfill(2), str(trials).zfill(2), rmse_score))
            scores.append(rmse_score)

        # Select the fit params with the best score
        if trials &gt; 1:
            fitted = params[np.argmin(scores)]
            init_params = params0[np.argmin(scores)]
        # Generate and print a report, update the BPLUT parameters
        self._report(
            init_params, fitted, self._parameters[&#39;reco&#39;], &#39;RECO Optimization&#39;)
        self._report_fit(
            reco_tower, reco(fitted if optimize else init_params), weights)
        if optimize:
            self.bplut.update(self._pft, fitted, self._parameters[&#39;reco&#39;])</code></pre>
</details>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="pyl4c.apps.calibration.extensions.hydrology.StratifiedSoilCalibrationCLI" href="extensions/hydrology.html#pyl4c.apps.calibration.extensions.hydrology.StratifiedSoilCalibrationCLI">StratifiedSoilCalibrationCLI</a></li>
<li><a title="pyl4c.apps.calibration.extensions.phenology.PhenologyCalibrationCLI" href="extensions/phenology.html#pyl4c.apps.calibration.extensions.phenology.PhenologyCalibrationCLI">PhenologyCalibrationCLI</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="pyl4c.apps.calibration.main.CLI.filter"><code class="name flex">
<span>def <span class="ident">filter</span></span>(<span>self, flux, size=2)</span>
</code></dt>
<dd>
<div class="desc"><p>Filters the tower GPP or RECO flux data. Each time it is called, the
raw (noisy) tower data is filtered; successive calls with the same
arguments will only overwrite the filtered tower data.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>flux</code></strong> :&ensp;<code>str</code></dt>
<dd>"gpp" or "reco" for the corresponding tower dataset</dd>
<dt><strong><code>size</code></strong> :&ensp;<code>int</code></dt>
<dd>Filter window size, in days</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def filter(self, flux, size = 2):
    &#39;&#39;&#39;
    Filters the tower GPP or RECO flux data. Each time it is called, the
    raw (noisy) tower data is filtered; successive calls with the same
    arguments will only overwrite the filtered tower data.

    Parameters
    ----------
    flux : str
        &#34;gpp&#34; or &#34;reco&#34; for the corresponding tower dataset
    size : int
        Filter window size, in days
    &#39;&#39;&#39;
    assert any(self._sites), &#39;You must select a PFT class&#39;
    with h5py.File(self._path_to_scratch, &#39;a&#39;) as hdf:
        assert flux.upper() in hdf[&#39;tower&#39;].keys(),\
            &#39;Field &#34;tower/%s&#34; not found&#39; % flux.upper()
        # Tower fluxes are duplicated on the last axis, so pick one
        raw = hdf[&#39;tower/%s&#39; % flux.upper()][:,self._sites,0]
        filtered = self._filter(raw, size)
        # Re-duplicate the 1-km subgrid on the last axis
        filtered = filtered[...,np.newaxis].repeat(81, axis = 2)
        hdf[&#39;tower/%s&#39; % flux.upper()][:,self._sites,:] = filtered</code></pre>
</details>
</dd>
<dt id="pyl4c.apps.calibration.main.CLI.filter_all"><code class="name flex">
<span>def <span class="ident">filter_all</span></span>(<span>self, flux, size=2)</span>
</code></dt>
<dd>
<div class="desc"><p>Filters the tower GPP or RECO flux data for ALL PFT classes.
See also: filter().</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>flux</code></strong> :&ensp;<code>str</code></dt>
<dd>"gpp" or "reco" for the corresponding tower dataset</dd>
<dt><strong><code>size</code></strong> :&ensp;<code>int</code></dt>
<dd>Filter window size, in days</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def filter_all(self, flux, size = 2):
    &#39;&#39;&#39;
    Filters the tower GPP or RECO flux data for ALL PFT classes.
    See also: filter().

    Parameters
    ----------
    flux : str
        &#34;gpp&#34; or &#34;reco&#34; for the corresponding tower dataset
    size : int
        Filter window size, in days
    &#39;&#39;&#39;
    with h5py.File(self._path_to_scratch, &#39;a&#39;) as hdf:
        assert flux.upper() in hdf[&#39;tower&#39;].keys(),\
            &#39;Field &#34;tower/%s&#34; not found&#39; % flux.upper()
        # Tower fluxes are duplicated on the last axis, so pick one
        filtered = self._filter(
            hdf[&#39;tower/%s&#39; % flux.upper()][...,0], size)
        # Re-duplicate the 1-km subgrid on the last axis
        filtered = filtered[...,np.newaxis].repeat(81, axis = 2)
        hdf[&#39;tower/%s&#39; % flux.upper()][:] = filtered</code></pre>
</details>
</dd>
<dt id="pyl4c.apps.calibration.main.CLI.filter_preview"><code class="name flex">
<span>def <span class="ident">filter_preview</span></span>(<span>self, flux, size=2, seed=9)</span>
</code></dt>
<dd>
<div class="desc"><p>Previews a filter for the tower GPP or RECO data.</p>
<p>Parameters
flux : str
"gpp" or "reco" for the corresponding tower dataset
size : int
Filter window size, in days
seed : int
Random seed; change to select a different tower site</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def filter_preview(self, flux, size = 2, seed = 9):
    &#39;&#39;&#39;
    Previews a filter for the tower GPP or RECO data.

    Parameters
    flux : str
        &#34;gpp&#34; or &#34;reco&#34; for the corresponding tower dataset
    size : int
        Filter window size, in days
    seed : int
        Random seed; change to select a different tower site
    &#39;&#39;&#39;
    assert self._sites.any(), &#39;You must select a PFT class&#39;
    with h5py.File(self._path_to_scratch, &#39;r&#39;) as hdf:
        assert flux.upper() in hdf[&#39;tower&#39;].keys(),\
            &#39;Field &#34;%s&#34; not found&#39; % flux.upper()
        x = hdf[&#39;tower/%s&#39; % flux.upper()][:]

    # Get a random tower site matching the current PFT class
    np.random.seed(seed)
    idx = np.random.choice(np.argwhere(self._sites).flatten(), 1)[0]
    x0 = x[:,idx,0]
    x_filt = self._filter(x0, size)
    pyplot.plot(x0, c = &#39;lightsteelblue&#39;)
    pyplot.plot(x_filt, c = &#39;darkorange&#39;)
    pyplot.ylabel(&#39;Tower %s (g C m-2 day-1)&#39; % flux.upper())
    pyplot.title(&#39;Window Size = %d days&#39; % size)
    pyplot.show()</code></pre>
</details>
</dd>
<dt id="pyl4c.apps.calibration.main.CLI.pft"><code class="name flex">
<span>def <span class="ident">pft</span></span>(<span>self, pft)</span>
</code></dt>
<dd>
<div class="desc"><p>Sets the PFT class for the next calibration step.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>pft</code></strong> :&ensp;<code>int</code></dt>
<dd>The PFT class to use in calibration</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyl4c.apps.calibration.main.CLI" href="#pyl4c.apps.calibration.main.CLI">CLI</a></code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pft(self, pft):
    &#39;&#39;&#39;
    Sets the PFT class for the next calibration step.

    Parameters
    ----------
    pft : int
        The PFT class to use in calibration

    Returns
    -------
    CLI
    &#39;&#39;&#39;
    assert pft in range(1, 9), &#39;Unrecognized PFT class&#39;
    self._pft = pft
    return self</code></pre>
</details>
</dd>
<dt id="pyl4c.apps.calibration.main.CLI.plot_gpp"><code class="name flex">
<span>def <span class="ident">plot_gpp</span></span>(<span>self, driver, coefs=None, xlim=None, ylim=None, alpha=0.1, marker='.')</span>
</code></dt>
<dd>
<div class="desc"><p>Using the current or optimized BPLUT coefficients, plots the GPP ramp
function for a given driver. NOTE: Values where APAR &lt; 2.0 are not
shown.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>driver</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of the driver to plot on the horizontal axis</dd>
<dt><strong><code>coefs</code></strong> :&ensp;<code>list</code> or <code>tuple</code> or <code>numpy.ndarray</code></dt>
<dd>(Optional) array-like, Instead of using what's in the BPLUT,
specify the exact parameters, e.g., [tmin0, tmin1]</dd>
<dt><strong><code>xlim</code></strong> :&ensp;<code>list</code> or <code>tuple</code></dt>
<dd>(Optional) A 2-element sequence: The x-axis limits</dd>
<dt><strong><code>ylim</code></strong> :&ensp;<code>list</code> or <code>tuple</code></dt>
<dd>(Optional) A 2-element sequence: The x-axis limits</dd>
<dt><strong><code>alpha</code></strong> :&ensp;<code>float</code></dt>
<dd>(Optional) The alpha value (Default: 0.1)</dd>
<dt><strong><code>marker</code></strong> :&ensp;<code>str</code></dt>
<dd>(Optional) The marker symbol (Default: ".")</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_gpp(
        self, driver, coefs = None, xlim = None, ylim = None, alpha = 0.1,
        marker = &#39;.&#39;):
    &#39;&#39;&#39;
    Using the current or optimized BPLUT coefficients, plots the GPP ramp
    function for a given driver. NOTE: Values where APAR &lt; 2.0 are not
    shown.

    Parameters
    ----------
    driver : str
        Name of the driver to plot on the horizontal axis
    coefs : list or tuple or numpy.ndarray
        (Optional) array-like, Instead of using what&#39;s in the BPLUT,
        specify the exact parameters, e.g., [tmin0, tmin1]
    xlim : list or tuple
        (Optional) A 2-element sequence: The x-axis limits
    ylim : list or tuple
        (Optional) A 2-element sequence: The x-axis limits
    alpha : float
        (Optional) The alpha value (Default: 0.1)
    marker : str
        (Optional) The marker symbol (Default: &#34;.&#34;)
    &#39;&#39;&#39;
    @suppress_warnings
    def empirical_lue(apar, gpp):
        # Mask low APAR values
        lower, _ = self._driver_bounds.get(&#39;apar&#39;, (0, None))
        apar = np.where(apar &lt; lower, np.nan, apar)
        # Calculate empirical light-use efficiency: GPP/APAR
        return np.where(apar &gt; 0, np.divide(gpp, apar), 0)

    assert self._is_setup, &#39;Must run setup first&#39;
    np.seterr(invalid = &#39;ignore&#39;)
    # Read in GPP and APAR data
    if coefs is not None:
        assert hasattr(coefs, &#39;index&#39;) and not hasattr(coefs, &#39;title&#39;),\
            &#34;Argument --coefs expects a list [values,] with NO spaces&#34;
    assert driver in (&#39;tmin&#39;, &#39;vpd&#39;, &#39;smrz&#39;),\
        &#39;Requested driver &#34;%s&#34; cannot be plotted for GPP&#39; % driver
    with h5py.File(self._path_to_scratch, &#39;r&#39;) as hdf:
        gpp = hdf[&#39;tower/GPP&#39;][:,self._sites,:].mean(axis = 2)
        apar = hdf[&#39;APAR&#39;][:,self._sites,:].mean(axis = 2)

    with h5py.File(self._path_to_drivers, &#39;r&#39;) as hdf:
        # Get the user-specified driver data
        x = hdf[&#39;drivers/%s&#39; % driver][:,self._sites]

    # Update plotting parameters
    lue = empirical_lue(apar, gpp)
    # Mask out negative LUE values and values with APAR&lt;2
    pyplot.scatter(x, np.where(
        np.logical_or(lue == 0, apar &lt; 2), np.nan, lue),
        alpha = alpha, marker = marker)
    a, b = self._ramp(x, driver)
    pyplot.plot(a, b * self.bplut[&#39;LUE&#39;][:,self._pft], &#39;k-&#39;)
    if coefs is not None:
        pyplot.plot(*self._ramp(x, driver, coefs = coefs), &#39;r-&#39;)
    pyplot.xlabel(&#39;%s (%s)&#39; % (driver, self._metadata[driver][&#39;units&#39;]))
    pyplot.ylabel(&#39;GPP/APAR (g C MJ-1 d-1)&#39;)
    if xlim is not None:
        pyplot.xlim(xlim[0], xlim[1])
    if ylim is not None:
        pyplot.ylim(ylim[0], ylim[1])
    pyplot.title(
        &#39;%s (PFT %d): GPP Response to &#34;%s&#34;&#39; % (
            PFT[self._pft][0], self._pft, driver))
    pyplot.show()</code></pre>
</details>
</dd>
<dt id="pyl4c.apps.calibration.main.CLI.plot_reco"><code class="name flex">
<span>def <span class="ident">plot_reco</span></span>(<span>self, driver, coefs=None, q_rh=75, q_k=50, xlim=None, ylim=None, alpha=0.1, marker='.')</span>
</code></dt>
<dd>
<div class="desc"><p>Using the current or optimized BPLUT coefficients, plots the RECO ramp
function for a given driver. The ramp function is shown on a plot of
RH/Cbar, which is equivalent to Kmult (as Cbar is an upper quantile of
the RH/Kmult distribution).</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>driver</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of the driver to plot on the horizontal axis</dd>
<dt><strong><code>coefs</code></strong> :&ensp;<code>list</code> or <code>tuple</code> or <code>numpy.ndarray</code></dt>
<dd>(Optional) array-like, Instead of using what's in the BPLUT,
specify the exact parameters, e.g., <code>[tmin0, tmin1]</code></dd>
<dt><strong><code>q_rh</code></strong> :&ensp;<code>int</code></dt>
<dd>Additional arguments to <code><a title="pyl4c.apps.calibration.cbar" href="index.html#pyl4c.apps.calibration.cbar">cbar()</a></code></dd>
<dt><strong><code>q_k</code></strong> :&ensp;<code>int</code></dt>
<dd>Additional arguments to <code><a title="pyl4c.apps.calibration.cbar" href="index.html#pyl4c.apps.calibration.cbar">cbar()</a></code></dd>
<dt><strong><code>ylim</code></strong> :&ensp;<code>list</code> or <code>tuple</code></dt>
<dd>(Optional) A 2-element sequence: The x-axis limits</dd>
<dt><strong><code>alpha</code></strong> :&ensp;<code>float</code></dt>
<dd>(Optional) The alpha value (Default: 0.1)</dd>
<dt><strong><code>marker</code></strong> :&ensp;<code>str</code></dt>
<dd>(Optional) The marker symbol (Default: ".")</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_reco(
        self, driver, coefs = None, q_rh = 75, q_k = 50, xlim = None,
        ylim = None, alpha = 0.1, marker = &#39;.&#39;):
    &#39;&#39;&#39;
    Using the current or optimized BPLUT coefficients, plots the RECO ramp
    function for a given driver. The ramp function is shown on a plot of
    RH/Cbar, which is equivalent to Kmult (as Cbar is an upper quantile of
    the RH/Kmult distribution).

    Parameters
    ----------
    driver : str
        Name of the driver to plot on the horizontal axis
    coefs : list or tuple or numpy.ndarray
        (Optional) array-like, Instead of using what&#39;s in the BPLUT,
        specify the exact parameters, e.g., `[tmin0, tmin1]`
    q_rh : int
        Additional arguments to `pyl4c.apps.calibration.cbar()`
    q_k : int
        Additional arguments to `pyl4c.apps.calibration.cbar()`
    ylim : list or tuple
        (Optional) A 2-element sequence: The x-axis limits
    alpha : float
        (Optional) The alpha value (Default: 0.1)
    marker : str
        (Optional) The marker symbol (Default: &#34;.&#34;)
    &#39;&#39;&#39;
    assert self._is_setup, &#39;Must run setup first&#39;
    assert driver in (&#39;tsoil&#39;, &#39;smsf&#39;),\
        &#39;Requested driver &#34;%s&#34; cannot be plotted for RECO&#39; % driver
    np.seterr(invalid = &#39;ignore&#39;)
    with h5py.File(self._path_to_scratch, &#39;r&#39;) as hdf:
        gpp = hdf[&#39;tower/GPP&#39;][:,self._sites,:].mean(axis = 2)
        reco = hdf[&#39;tower/RECO&#39;][:,self._sites,:].mean(axis = 2)

    with h5py.File(self._path_to_drivers, &#39;r&#39;) as hdf:
        # Get the user-specified driver data
        tsoil = hdf[&#39;drivers/tsoil&#39;][:,self._sites]
        smsf = hdf[&#39;drivers/smsf&#39;][:,self._sites]

    f_smsf = linear_constraint(*self.bplut[&#39;smsf&#39;][:,self._pft])
    k_mult = f_smsf(smsf) * arrhenius(tsoil, self.bplut[&#39;tsoil&#39;][0,self._pft])
    # Calculate RH as (RECO - RA)
    rh = reco - ((1 - self.bplut[&#39;CUE&#39;][0,self._pft]) * gpp)
    # Set negative RH values to zero
    rh = np.where(suppress_warnings(np.less)(rh, 0), 0, rh)
    cbar0 = suppress_warnings(cbar)(rh, k_mult, q_rh, q_k)
    gpp = reco = None

    # Update plotting parameters
    pyplot.scatter( # Plot RH/Cbar against either Tsoil or SMSF
        tsoil if driver == &#39;tsoil&#39; else smsf,
        suppress_warnings(np.divide)(rh, cbar0),
        alpha = alpha, marker = marker)

    if driver == &#39;tsoil&#39;:
        domain = np.arange(tsoil.min(), tsoil.max(), 0.1)
        pyplot.plot(domain,
            arrhenius(domain, self.bplut[&#39;tsoil&#39;][0,self._pft]), &#39;k-&#39;)
    elif driver == &#39;smsf&#39;:
        pyplot.plot(*self._ramp(smsf, driver), &#39;k-&#39;)

    if coefs is not None:
        if driver == &#39;tsoil&#39;:
            pyplot.plot(domain, arrhenius(domain, *coefs), &#39;r-&#39;)
        elif driver == &#39;smsf&#39;:
            pyplot.plot(*self._ramp(smsf, driver, coefs = coefs), &#39;r-&#39;)

    pyplot.xlabel(&#39;%s (%s)&#39; % (driver, self._metadata[driver][&#39;units&#39;]))
    pyplot.ylabel(&#39;RH/Cbar&#39;)
    if xlim is not None:
        pyplot.xlim(xlim[0], xlim[1])
    if ylim is not None:
        pyplot.ylim(ylim[0], ylim[1])
    pyplot.title(
        &#39;%s (PFT %d): RECO Response to &#34;%s&#34;&#39; % (
            PFT[self._pft][0], self._pft, driver))
    pyplot.show()</code></pre>
</details>
</dd>
<dt id="pyl4c.apps.calibration.main.CLI.reset"><code class="name flex">
<span>def <span class="ident">reset</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Clears the current BPLUT in the scratch data, wiping out any
calibrated parameters. Subsequent calibration will then use the
reference (file) BPLUT for initial values.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reset(self):
    &#39;&#39;&#39;
    Clears the current BPLUT in the scratch data, wiping out any
    calibrated parameters. Subsequent calibration will then use the
    reference (file) BPLUT for initial values.
    &#39;&#39;&#39;
    with h5py.File(self._path_to_scratch, &#39;a&#39;) as hdf:
        del hdf[&#39;BPLUT&#39;]
    print(&#39;Deleted BPLUT in the scratch file&#39;)</code></pre>
</details>
</dd>
<dt id="pyl4c.apps.calibration.main.CLI.set"><code class="name flex">
<span>def <span class="ident">set</span></span>(<span>self, parameter, value)</span>
</code></dt>
<dd>
<div class="desc"><p>Sets the named parameter to the given value for the specified PFT
class. This updates the initial parameters, affecting any subsequent
optimization.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>parameter</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of the parameter to bet set</dd>
<dt><strong><code>value</code></strong> :&ensp;<code>int</code> or <code>float</code></dt>
<dd>Value of the named parameter to be set</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pyl4c.apps.calibration.main.CLI" href="#pyl4c.apps.calibration.main.CLI">CLI</a></code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set(self, parameter, value):
    &#39;&#39;&#39;
    Sets the named parameter to the given value for the specified PFT
    class. This updates the initial parameters, affecting any subsequent
    optimization.

    Parameters
    ----------
    parameter : str
        Name of the parameter to bet set
    value : int or float
        Value of the named parameter to be set

    Returns
    -------
    CLI
    &#39;&#39;&#39;
    # Update the BPLUT in memory but NOT the file BPLUT (this is temporary)
    self.bplut.update(self._pft, (value,), (parameter,), flush = False)
    return self</code></pre>
</details>
</dd>
<dt id="pyl4c.apps.calibration.main.CLI.setup"><code class="name flex">
<span>def <span class="ident">setup</span></span>(<span>self, reset=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute freeze/thaw, copy tower data, calculate site weights, and
compute a 365-day climatology for each driver.</p>
<p>Important considerations:
1) Tower GPP and RECO values &lt;0 are masked;
2) Tower GPP is masked where APAR is &lt;0.1 MJ m-2 d-1;
3) Freeze/Thaw status is determiend as "frozen" (0) if the surface
skin temperature is below 273.15 K, "thawed" (1) otherwise</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>reset</code></strong> :&ensp;<code>bool</code></dt>
<dd>True to automatically delete the scratch file</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def setup(self, reset = False):
    &#39;&#39;&#39;
    Compute freeze/thaw, copy tower data, calculate site weights, and
    compute a 365-day climatology for each driver.

    Important considerations:
        1) Tower GPP and RECO values &lt;0 are masked;
        2) Tower GPP is masked where APAR is &lt;0.1 MJ m-2 d-1;
        3) Freeze/Thaw status is determiend as &#34;frozen&#34; (0) if the surface
           skin temperature is below 273.15 K, &#34;thawed&#34; (1) otherwise

    Parameters
    ----------
    reset : bool
        True to automatically delete the scratch file
    &#39;&#39;&#39;
    np.seterr(invalid = &#39;ignore&#39;)
    if reset:
        os.remove(self._path_to_scratch)
        print(&#39;Deleted scratch data.&#39;)

    # Open the scratch file
    target_hdf = h5py.File(self._path_to_scratch, &#39;a&#39;)
    # Copy tower flux datasets
    with h5py.File(self._path_to_towers, &#39;r&#39;) as hdf:
        for key in (&#39;GPP&#39;, &#39;RECO&#39;, &#39;NEE&#39;):
            arr = hdf[key][:]
            arr = arr[...,np.newaxis].repeat(81, axis = 2)
            # Mask out negative GPP and RECO values
            if key != &#39;NEE&#39;:
                arr = np.where(np.less(arr, 0), np.nan, arr)
            target_hdf.create_dataset(
                &#39;tower/%s&#39; % key, arr.shape, arr.dtype, arr)

    # Read in Tsurf, 9-km grid indices, and PAR + fPAR
    with h5py.File(self._path_to_drivers, &#39;r&#39;) as hdf:
        tsurf = hdf[&#39;drivers/tsurf&#39;][:]
        idx = hdf[&#39;coords/grid_9km_idx&#39;][:].round(0).astype(np.int16)
        # Make conformable PAR array at 1-km scale
        par = hdf[&#39;drivers/par&#39;][:]
        par = par[...,np.newaxis].repeat(81, axis = 2)
        apar = np.multiply(hdf[&#39;drivers/fpar&#39;][:], par)
        par = None

    # Compute freeze/thaw
    target_hdf.create_dataset( # Frozen = 0, Thawed = 1
        &#39;ft&#39;, tsurf.shape, tsurf.dtype, np.where(tsurf &lt;= 273.15, 0, 1))
    tsurf = None
    # Find duplicate (shared) 9-km cells, calculate site weights
    uid = [&#39;%d%d&#39; % (r, c) for r, c in idx.tolist()]
    target_hdf.create_dataset(&#39;site_weights&#39;, (1, self._nsites),
        np.float16, np.array([(1.0 / uid.count(x)) for x in uid]))
    # Copy APAR; screen tower GPP where APAR is low
    gpp = target_hdf[&#39;tower/GPP&#39;][:]
    target_hdf.create_dataset(&#39;APAR&#39;, apar.shape, apar.dtype, apar)
    # With APAR below 0.1, tower GPP is unstable
    target_hdf[&#39;tower/GPP&#39;][:] = np.where(apar &lt; 0.1, np.nan, gpp)
    apar = gpp = None
    # Close the scratch data
    target_hdf.close()
    # Compute climatology
    self._climatology()</code></pre>
</details>
</dd>
<dt id="pyl4c.apps.calibration.main.CLI.tune_gpp"><code class="name flex">
<span>def <span class="ident">tune_gpp</span></span>(<span>self, fixed=None, optimize=True, nlopt=True, trials=1)</span>
</code></dt>
<dd>
<div class="desc"><p>Optimizes GPP. The 9-km mean L4C GPP is fit to the tower-observed GPP
using constrained, non-linear least-squares optimization.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>fixed</code></strong> :&ensp;<code>tuple</code> or <code>list</code></dt>
<dd>Zero or more parameters whose values should be fixed
(i.e, NOT optimized)</dd>
<dt><strong><code>optimize</code></strong> :&ensp;<code>bool</code></dt>
<dd>False to only report parameters and their fit statistics instead
of optimizing (Default: True)</dd>
<dt><strong><code>nlopt</code></strong> :&ensp;<code>bool</code></dt>
<dd>True to use the nlopt library for optimization (Default: True)</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def tune_gpp(
        self, fixed = None, optimize = True, nlopt = True, trials = 1):
    &#39;&#39;&#39;
    Optimizes GPP. The 9-km mean L4C GPP is fit to the tower-observed GPP
    using constrained, non-linear least-squares optimization.

    Parameters
    ----------
    fixed : tuple or list
        Zero or more parameters whose values should be fixed
        (i.e, NOT optimized)
    optimize : bool
        False to only report parameters and their fit statistics instead
        of optimizing (Default: True)
    nlopt : bool
        True to use the nlopt library for optimization (Default: True)
    &#39;&#39;&#39;
    def e_mult(params):
        # Calculate E_mult based on current parameters
        f_tmin = linear_constraint(params[1], params[2])
        f_vpd  = linear_constraint(params[3], params[4], &#39;reversed&#39;)
        f_smrz = linear_constraint(params[5], params[6])
        f_ft   = linear_constraint(params[7], 1.0, &#39;binary&#39;)
        tmin, vpd, smrz, ft = drivers # Unpack global &#34;drivers&#34;
        e = f_tmin(tmin) * f_vpd(vpd) * f_smrz(smrz) * f_ft(ft)
        return e[...,np.newaxis]

    def gpp(params):
        # Calculate GPP based on the provided BPLUT parameters
        return apar * params[0] * e_mult(params) # Global &#34;apar&#34;

    def residuals(params):
        # Objective function: Difference between tower GPP and L4C GPP
        gpp0 = gpp(params).mean(axis = 2)
        diff = np.subtract(gpp_tower, gpp0) # Global &#34;gpp_tower&#34;
        # Multiply by the tower weights
        return (weights * diff)[~np.isnan(diff)] # Global &#34;weights&#34;

    assert self._is_setup, &#39;Must run setup first&#39;
    # Compile the initial parameters for optimization, based on current
    #   BPLUT; they are: lue, tmin0, tmin1, vpd0, vpd1, smrz0, smrz1, ft0
    if fixed is not None:
        # In case a single parameter name is passed, wrap in a list
        fixed = [fixed] if hasattr(fixed, &#39;title&#39;) else fixed
        assert all(p in self._parameters[&#39;gpp&#39;] for p in fixed),\
            &#39;Arguments to &#34;fixed&#34; should be in: [%s]&#39; % &#39;, &#39;.join(self._parameters[&#39;gpp&#39;])
    init_params = [self.bplut[&#39;LUE&#39;][0,self._pft]]
    for field in (&#39;tmin&#39;, &#39;vpd&#39;, &#39;smrz&#39;, &#39;ft&#39;):
        init_params.extend(self.bplut[field][:,self._pft].tolist())
    init_params.pop() # Remove FT upper limit (it is fixed at 1.0)

    # Read in data, with optional subsetting of the time axis
    t0 = self._time_start if self._time_start is not None else 0
    t1 = self._time_end if self._time_end is not None else self._nsteps
    with h5py.File(self._path_to_drivers, &#39;r&#39;) as hdf:
        drivers = []
        for field in (&#39;tmin&#39;, &#39;vpd&#39;, &#39;smrz&#39;):
            drivers.append(hdf[&#39;drivers/%s&#39; % field][t0:t1][:,self._sites])

    with h5py.File(self._path_to_scratch, &#39;r&#39;) as hdf:
        drivers.append(hdf[&#39;ft&#39;][t0:t1][:,self._sites])
        apar = hdf[&#39;APAR&#39;][t0:t1][:,self._sites,:]
        gpp_tower = hdf[&#39;tower/GPP&#39;][t0:t1][:,self._sites,:].mean(axis = 2)
        weights = hdf[&#39;site_weights&#39;][:][:,self._sites]

    # L4C drivers should have no NaNs, based on how they were sourced;
    #   BUT this is not the case for fPAR, which does have NaNs; not sure
    #   why I would have ever asserted it doesn&#39;t
    # assert np.all(~np.isnan(apar)), &#39;Unexpected NaNs in APAR&#39;
    for arr in drivers:
        assert np.all(~np.isnan(arr)), &#39;Unexpected NaNs&#39;

    # Get bounds for the parameter search
    bounds = self._bounds(init_params, &#39;gpp&#39;, fixed)
    params = []
    params0 = []
    scores = []
    param_space = np.linspace(bounds[0], bounds[1], 100)
    for t in range(0, trials):
        # If multiple trials, randomize the initial parameter values
        #   and score the model in each trial
        if trials &gt; 1:
            p = param_space.shape[1] # Number of parameters
            idx = np.random.randint(0, param_space.shape[0], p)
            init_params = param_space[idx,np.arange(0, p)]
            params0.append(init_params)
        if optimize and not nlopt:
            # Apply constrained, non-linear least-squares optimization
            print(&#39;Solving...&#39;)
            solution = solve_least_squares(
                residuals, init_params, labels = self._parameters[&#39;gpp&#39;],
                bounds = self._bounds(init_params, &#39;gpp&#39;, fixed),
                loss = &#39;arctan&#39;)
            fitted = solution.x.tolist()
            print(solution.message)
        elif optimize and nlopt:
            opt = GenericOptimization(residuals, bounds,
                step_size = (0.01, 0.2, 0.2, 1, 1, 0.1, 0.1, 0.01))
            fitted = opt.solve(init_params)
        else:
            fitted = [None for i in range(0, len(init_params))]
        # Record the found solution and its goodness-of-fit score
        params.append(fitted)
        _, rmse_score, _, _ = self._report_fit(
            gpp_tower,
            gpp(fitted if optimize else init_params).mean(axis = 2),
            weights, verbose = False)
        print(&#39;[%s/%s] RMSE score of last trial: %.3f&#39; % (
            str(t + 1).zfill(2), str(trials).zfill(2), rmse_score))
        scores.append(rmse_score)

    # Select the fit params with the best score
    if trials &gt; 1:
        fitted = params[np.argmin(scores)]
        init_params = params0[np.argmin(scores)]
    # Generate and print a report, update the BPLUT parameters
    self._report(
        init_params, fitted, self._parameters[&#39;gpp&#39;], &#39;GPP Optimization&#39;)
    self._report_fit(
        gpp_tower, gpp(fitted if optimize else init_params).mean(axis = 2),
        weights)
    if optimize:
        self.bplut.update(self._pft, fitted, self._parameters[&#39;gpp&#39;])</code></pre>
</details>
</dd>
<dt id="pyl4c.apps.calibration.main.CLI.tune_reco"><code class="name flex">
<span>def <span class="ident">tune_reco</span></span>(<span>self, q_rh=75, q_k=50, fixed=None, optimize=True, nlopt=True, trials=1)</span>
</code></dt>
<dd>
<div class="desc"><p>Optimizes RECO. The 9-km mean L4C RECO is fit to the tower-observed
RECO using constrained, non-linear least-squares optimization.</p>
<h2 id="considerations">Considerations</h2>
<p>1) Negative RH values (i.e., NPP &gt; RECO) are set to zero.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>q_rh</code></strong> :&ensp;<code>int</code></dt>
<dd>The percentile of RH/Kmult to use in calculating Cbar</dd>
<dt><strong><code>q_k</code></strong> :&ensp;<code>int</code></dt>
<dd>The percentile of Kmult below which RH/Kmult values are masked</dd>
<dt><strong><code>fixed</code></strong> :&ensp;<code>tuple</code> or <code>list</code></dt>
<dd>Zero or more parameters whose values should be fixed
(i.e, NOT optimized)</dd>
<dt><strong><code>optimize</code></strong> :&ensp;<code>bool</code></dt>
<dd>False to only report parameters and their fit statistics instead
of optimizing (Default: True)</dd>
<dt><strong><code>nlopt</code></strong> :&ensp;<code>bool</code></dt>
<dd>True to use the nlopt library for optimization (Default: True)</dd>
<dt><strong><code>trials</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of searches of the parameter space to perform; if &gt;1,
initial parameters are randomized for each trial</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def tune_reco(
        self, q_rh = 75, q_k = 50, fixed = None, optimize = True,
        nlopt = True, trials = 1):
    &#39;&#39;&#39;
    Optimizes RECO. The 9-km mean L4C RECO is fit to the tower-observed
    RECO using constrained, non-linear least-squares optimization.
    Considerations:
        1) Negative RH values (i.e., NPP &gt; RECO) are set to zero.

    Parameters
    ----------
    q_rh : int
        The percentile of RH/Kmult to use in calculating Cbar
    q_k : int
        The percentile of Kmult below which RH/Kmult values are masked
    fixed : tuple or list
        Zero or more parameters whose values should be fixed
        (i.e, NOT optimized)
    optimize : bool
        False to only report parameters and their fit statistics instead
        of optimizing (Default: True)
    nlopt : bool
        True to use the nlopt library for optimization (Default: True)
    trials : int
        Number of searches of the parameter space to perform; if &gt;1,
        initial parameters are randomized for each trial
    &#39;&#39;&#39;
    def k_mult(params):
        # Calculate K_mult based on current parameters
        f_tsoil = partial(arrhenius, beta0 = params[1])
        f_smsf  = linear_constraint(params[2], params[3])
        tsoil, smsf = drivers # Unpack global &#34;drivers&#34;
        return f_tsoil(tsoil) * f_smsf(smsf)

    @suppress_warnings
    def reco(params):
        # Calculate RH as (RECO - RA) or (RECO - (faut * GPP));
        #   globals &#34;reco_tower&#34;, &#34;gpp_tower&#34;
        ra = ((1 - params[0]) * gpp_tower)
        rh = reco_tower - ra
        rh = np.where(rh &lt; 0, 0, rh) # Mask out negative RH values
        # Compute Cbar with globals &#34;q_rh&#34; and &#34;q_k&#34;
        kmult0 = k_mult(params)
        cbar0 = cbar(rh, kmult0, q_rh, q_k)
        return ra + (kmult0 * cbar0)

    def residuals(params):
        # Objective function: Difference between tower RECO and L4C RECO
        reco0 = reco(params)
        diff = np.subtract(reco_tower, reco0) # Global &#34;reco_tower&#34;
        missing = np.logical_or(np.isnan(reco_tower), np.isnan(reco0))
        # Multiply by the tower weights
        return (weights * diff)[~missing] # Global &#34;weights&#34;

    assert self._is_setup, &#39;Must run setup first&#39;
    assert q_rh &gt;= 0 and q_rh &lt;= 100 and q_k &gt;= 0 and q_k &lt;= 100,\
        &#39;Invalid setting for &#34;q_rh&#34; or &#34;q_k&#34; parameters&#39;
    if fixed is not None:
        assert all(p in self._parameters[&#39;reco&#39;] for p in fixed),\
            &#39;Arguments to &#34;fixed&#34; should be in: [%s]&#39; % &#39;, &#39;.join(self._parameters[&#39;reco&#39;])
    init_params = [self.bplut[&#39;CUE&#39;][0,self._pft]]
    for field in (&#39;tsoil&#39;, &#39;smsf&#39;):
        init_params.extend(self.bplut[field][:,self._pft].tolist())

    # Read in data, with optional subsetting of the time axis
    t0 = self._time_start if self._time_start is not None else 0
    t1 = self._time_end if self._time_end is not None else self._nsteps
    with h5py.File(self._path_to_drivers, &#39;r&#39;) as hdf:
        drivers = [
            hdf[&#39;drivers/%s&#39; % field][t0:t1][:,self._sites]
            for field in (&#39;tsoil&#39;, &#39;smsf&#39;)
        ]
    with h5py.File(self._path_to_scratch, &#39;r&#39;) as hdf:
        gpp_tower = hdf[&#39;tower/GPP&#39;][t0:t1][:,self._sites,:].mean(axis = 2)
        reco_tower = hdf[&#39;tower/RECO&#39;][t0:t1][:,self._sites,:].mean(axis = 2)
        weights = hdf[&#39;site_weights&#39;][:,self._sites]

    # L4C drivers should have no NaNs, based on how they were sourced
    for arr in drivers:
        assert np.all(~np.isnan(arr)), &#39;Unexpected NaNs&#39;

    # Get bounds for the parameter search
    bounds = self._bounds(init_params, &#39;reco&#39;, fixed)
    params = []
    params0 = []
    scores = []
    param_space = np.linspace(bounds[0], bounds[1], 100)
    for t in range(0, trials):
        # If multiple trials, randomize the initial parameter values
        #   and score the model in each trial
        if trials &gt; 1:
            p = param_space.shape[1] # Number of parameters
            idx = np.random.randint(0, param_space.shape[0], p)
            init_params = param_space[idx,np.arange(0, p)]
            params0.append(init_params)
        if optimize and not nlopt:
            # Apply constrained, non-linear least-squares optimization
            solution = solve_least_squares(
                residuals, init_params, labels = self._parameters[&#39;reco&#39;],
                bounds = bounds, loss = &#39;arctan&#39;)
            fitted = solution.x.tolist()
            message = solution.message
        elif optimize and nlopt:
            opt = GenericOptimization(residuals, bounds,
                step_size = (0.01, 1, 0.1, 0.1))
            fitted = opt.solve(init_params)
            message = &#39;Success&#39;
        else:
            fitted = [None for i in range(0, len(init_params))]
        # Record the found solution and its goodness-of-fit score
        params.append(fitted)
        _, rmse_score, _, _ = self._report_fit(
            reco_tower, reco(fitted if optimize else init_params),
            weights, verbose = False)
        print(&#39;[%s/%s] RMSE score of last trial: %.3f&#39; % (
            str(t + 1).zfill(2), str(trials).zfill(2), rmse_score))
        scores.append(rmse_score)

    # Select the fit params with the best score
    if trials &gt; 1:
        fitted = params[np.argmin(scores)]
        init_params = params0[np.argmin(scores)]
    # Generate and print a report, update the BPLUT parameters
    self._report(
        init_params, fitted, self._parameters[&#39;reco&#39;], &#39;RECO Optimization&#39;)
    self._report_fit(
        reco_tower, reco(fitted if optimize else init_params), weights)
    if optimize:
        self.bplut.update(self._pft, fitted, self._parameters[&#39;reco&#39;])</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<header>
<a class="homelink" rel="home" title="SMAP Mission Homepage" href="https://smap.jpl.nasa.gov/">
<img src="https://arthur-e.github.io/pyl4c/templates/images/logo_SMAP.jpg" alt="">
</a>
</header>
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="pyl4c.apps.calibration" href="index.html">pyl4c.apps.calibration</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="pyl4c.apps.calibration.main.CLI" href="#pyl4c.apps.calibration.main.CLI">CLI</a></code></h4>
<ul class="two-column">
<li><code><a title="pyl4c.apps.calibration.main.CLI.filter" href="#pyl4c.apps.calibration.main.CLI.filter">filter</a></code></li>
<li><code><a title="pyl4c.apps.calibration.main.CLI.filter_all" href="#pyl4c.apps.calibration.main.CLI.filter_all">filter_all</a></code></li>
<li><code><a title="pyl4c.apps.calibration.main.CLI.filter_preview" href="#pyl4c.apps.calibration.main.CLI.filter_preview">filter_preview</a></code></li>
<li><code><a title="pyl4c.apps.calibration.main.CLI.pft" href="#pyl4c.apps.calibration.main.CLI.pft">pft</a></code></li>
<li><code><a title="pyl4c.apps.calibration.main.CLI.plot_gpp" href="#pyl4c.apps.calibration.main.CLI.plot_gpp">plot_gpp</a></code></li>
<li><code><a title="pyl4c.apps.calibration.main.CLI.plot_reco" href="#pyl4c.apps.calibration.main.CLI.plot_reco">plot_reco</a></code></li>
<li><code><a title="pyl4c.apps.calibration.main.CLI.reset" href="#pyl4c.apps.calibration.main.CLI.reset">reset</a></code></li>
<li><code><a title="pyl4c.apps.calibration.main.CLI.set" href="#pyl4c.apps.calibration.main.CLI.set">set</a></code></li>
<li><code><a title="pyl4c.apps.calibration.main.CLI.setup" href="#pyl4c.apps.calibration.main.CLI.setup">setup</a></code></li>
<li><code><a title="pyl4c.apps.calibration.main.CLI.tune_gpp" href="#pyl4c.apps.calibration.main.CLI.tune_gpp">tune_gpp</a></code></li>
<li><code><a title="pyl4c.apps.calibration.main.CLI.tune_reco" href="#pyl4c.apps.calibration.main.CLI.tune_reco">tune_reco</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>